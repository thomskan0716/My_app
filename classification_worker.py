"""
ES: Worker para ejecutar anÃ¡lisis de clasificaciÃ³n (bunrui kaiseki) en un thread separado.
EN: Worker to run classification analysis (bunrui kaiseki) in a separate thread.
JA: åˆ†é¡è§£æï¼ˆbunrui kaisekiï¼‰ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã€‚

ES: Ejecuta Run_pipeline_ver3.3_20250914.py.
EN: Runs Run_pipeline_ver3.3_20250914.py.
JA: Run_pipeline_ver3.3_20250914.py ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
"""
import sys
import os
import subprocess
import pandas as pd
import json
import time
import threading
import re
import shutil
from pathlib import Path
from PySide6.QtCore import QThread, Signal, QMetaObject, Qt


class ClassificationWorker(QThread):
    """ES: Worker que ejecuta el anÃ¡lisis de clasificaciÃ³n en un thread separado
    EN: Worker that runs the classification analysis in a separate thread
    JA: åˆ†é¡è§£æã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼
    """
    
    # ES: SeÃ±ales para comunicaciÃ³n con la GUI | EN: Signals for GUI communication | JA: GUIé€šä¿¡ç”¨ã‚·ã‚°ãƒŠãƒ«
    progress_updated = Signal(int, str)  # (value, message)
    status_updated = Signal(str)  # message
    finished = Signal(dict)  # results dict
    error = Signal(str)  # error message
    console_output = Signal(str)  # console output (for IDE/terminal)
    file_selection_requested = Signal(str)  # (initial_path) - request file selection
    
    def __init__(self, filtered_df, project_folder, parent=None, config_values=None, selected_brush=None, selected_material=None, selected_wire_length=None):
        """
        ES: Inicializa el worker.
        EN: Initialize the worker.
        JA: ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚
        
        Parameters
        ----------
        filtered_df : pd.DataFrame
            ES: DataFrame con los datos filtrados
            EN: DataFrame containing filtered data
            JA: ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        project_folder : str
            ES: Carpeta base del proyecto
            EN: Project base folder
            JA: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ™ãƒ¼ã‚¹ãƒ•ã‚©ãƒ«ãƒ€
        parent : QWidget, optional
            ES: Widget padre
            EN: Parent widget
            JA: è¦ªã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        config_values : dict, optional
            ES: Valores de configuraciÃ³n del diÃ¡logo
            EN: Configuration values from the dialog
            JA: ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‹ã‚‰ã®è¨­å®šå€¤
        selected_brush : str, optional
            ES: Tipo de cepillo seleccionado (A11, A21, o A32) para Prediction_input.xlsx
            EN: Selected brush type (A11, A21, or A32) for Prediction_input.xlsx
            JA: Prediction_input.xlsx ç”¨ã«é¸æŠã—ãŸãƒ–ãƒ©ã‚·ã‚¿ã‚¤ãƒ—ï¼ˆA11/A21/A32ï¼‰
        selected_material : str, optional
            ES: Material seleccionado (Steel, Alum) para Prediction_input.xlsx
            EN: Selected material (Steel, Alum) for Prediction_input.xlsx
            JA: Prediction_input.xlsx ç”¨ã«é¸æŠã—ãŸææ–™ï¼ˆSteel/Alumï¼‰
        selected_wire_length : int, optional
            ES: Longitud de alambre seleccionada (30-75mm) para Prediction_input.xlsx
            EN: Selected wire length (30â€“75mm) for Prediction_input.xlsx
            JA: Prediction_input.xlsx ç”¨ã«é¸æŠã—ãŸç·šæé•·ï¼ˆ30â€“75mmï¼‰
        """
        super().__init__(parent)
        self.filtered_df = filtered_df
        self.project_folder = project_folder
        self.config_values = config_values or {}
        self.selected_brush = selected_brush or "A13"  # Default: A13
        self.selected_material = selected_material or "Steel"  # Default: Steel
        self.selected_wire_length = selected_wire_length or 75  # Default: 75
        self.output_folder = None
        self._cancelled = False
        self._current_process = None
        self._json_reader_stop = threading.Event()
        self._stop_reading = None
        self._selected_file_path = None  # Selected file path (set by the user)
        self._file_selection_event = threading.Event()  # File-selection synchronization event
        
        # ES: Estado del progreso para parsing (similar a nonlinear_worker) | EN: Parsing progress state (similar to nonlinear_worker) | JA: ãƒ‘ãƒ¼ã‚¹é€²æ—çŠ¶æ…‹ï¼ˆnonlinear_workerã¨åŒæ§˜ï¼‰
        self.current_fold = 0
        self.total_folds = self.config_values.get('OUTER_SPLITS', 10)
        self.current_trial = 0
        self.total_trials = self.config_values.get('N_TRIALS_INNER', 50)
        self.current_model = 0
        self.total_models = len(self.config_values.get('MODELS_TO_USE', ['lightgbm']))
        
        # ES: Estados de tareas | EN: Task states | JA: ã‚¿ã‚¹ã‚¯çŠ¶æ…‹
        self.model_comparison_completed = False
        self.multiobjective_completed = False
        self.dcv_training = False
        self.prediction_completed = False
        self.evaluation_completed = False
        self.current_task = 'initialization'  # initialization, model_comparison, multiobjective, dcv, prediction, evaluation
    
    def cancel(self):
        """ES: Cancela la ejecuciÃ³n del anÃ¡lisis
        EN: Cancel the analysis execution
        JA: è§£æå®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        """
        self._cancelled = True
        if self._current_process:
            try:
                self._current_process.terminate()
                self._current_process.wait(timeout=5)
            except:
                try:
                    self._current_process.kill()
                except:
                    pass
        self._json_reader_stop.set()
    
    def run(self):
        """ES: Ejecuta el anÃ¡lisis de clasificaciÃ³n
        EN: Run the classification analysis
        JA: åˆ†é¡è§£æã‚’å®Ÿè¡Œ
        """
        start_time = time.time()
        
        try:
            # ES: Verificar si es carga de carpeta existente | EN: Check if loading an existing folder | JA: æ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€èª­ã¿è¾¼ã¿ã‹ç¢ºèª
            load_existing = self.config_values.get('load_existing', False)
            selected_folder_path = self.config_values.get('selected_folder_path', '')
            
            if load_existing and selected_folder_path:
                # ES: Cargar carpeta existente sin ejecutar anÃ¡lisis | EN: Load existing folder without running analysis | JA: è§£æã›ãšæ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’èª­ã¿è¾¼ã¿
                self.status_updated.emit("ğŸ“ æ—¢å­˜çµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")
                self.progress_updated.emit(50, "æ—¢å­˜çµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")
                
                # ES: Usar la carpeta seleccionada como output_folder | EN: Use selected folder as output_folder | JA: é¸æŠãƒ•ã‚©ãƒ«ãƒ€ã‚’ output_folder ã«è¨­å®š
                self.output_folder = selected_folder_path
                
                # ES: Buscar resultados generados | EN: Find generated results | JA: ç”Ÿæˆã•ã‚ŒãŸçµæœã‚’æ¢ç´¢
                results = self._find_results()
                
                # ES: Emitir resultados como carga existente | EN: Emit results as an existing-load run | JA: æ—¢å­˜èª­ã¿è¾¼ã¿ã¨ã—ã¦çµæœã‚’é€ä¿¡
                results_existing = {
                    'output_folder': self.output_folder,
                    'analysis_duration': 0,  # No duration for existing analysis
                    'project_folder': self.config_values.get('project_folder', self.project_folder),
                    'load_existing': True,
                    'existing_folder_path': selected_folder_path,
                    'result_folders': results.get('result_folders', []),
                    'graph_paths': results.get('graph_paths', []),
                    'model_files': results.get('model_files', []),
                    'evaluation_files': results.get('evaluation_files', [])
                }
                
                self.progress_updated.emit(100, "æ—¢å­˜çµæœèª­ã¿è¾¼ã¿å®Œäº†")
                self.status_updated.emit("âœ… æ—¢å­˜çµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                
                # ES: Emitir finished para que la GUI muestre los resultados existentes | EN: Emit finished so the GUI can show existing results | JA: GUIè¡¨ç¤ºã®ãŸã‚ finished ã‚’é€ä¿¡
                self.finished.emit(results_existing)
                return
            
            # ES: Verificar cancelaciÃ³n | EN: Check cancellation | JA: ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
            if self._cancelled:
                return
            
            # ES: Crear carpeta de salida 05_åˆ†é¡ | EN: Create output folder 05_åˆ†é¡ | JA: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ 05_åˆ†é¡ ã‚’ä½œæˆ
            self.status_updated.emit("ğŸ“ Creando carpeta de salida...")
            classification_folder = os.path.join(self.project_folder, "05_åˆ†é¡")
            os.makedirs(classification_folder, exist_ok=True)
            
            # ES: Crear subcarpeta con timestamp (carpeta de salida directa) | EN: Create timestamp subfolder (direct output folder) | JA: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆç›´æ¥ã®å‡ºåŠ›å…ˆï¼‰ã‚’ä½œæˆ
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.output_folder = os.path.join(classification_folder, f"åˆ†é¡è§£æçµæœ_{timestamp}")
            os.makedirs(self.output_folder, exist_ok=True)
            
            # ES: No copiar ml_modules ni Run_pipeline; usar los del .venv directamente | EN: Do not copy ml_modules/Run_pipeline; use the ones from .venv | JA: ml_modules/Run_pipeline ã¯ã‚³ãƒ”ãƒ¼ã›ãš .venv ã®ã‚‚ã®ã‚’ä½¿ç”¨
            # ES: Buscar ml_modules en .venv | EN: Locate ml_modules in .venv | JA: .venv å†…ã® ml_modules ã‚’æ¢ç´¢
            script_dir = Path(__file__).parent.absolute()
            venv_ml_modules = script_dir / "ml_modules"
            
            # ES: Si no estÃ¡ en el directorio del script, buscar en el directorio padre (.venv) | EN: If not in the script dir, search parent dir (.venv) | JA: ã‚¹ã‚¯ãƒªãƒ—ãƒˆç›´ä¸‹ã«ãªã‘ã‚Œã°è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆ.venvï¼‰ã‚’æ¢ç´¢
            if not venv_ml_modules.exists() or not (venv_ml_modules / "models_cls.py").exists():
                venv_ml_modules = script_dir.parent / "ml_modules"
            
            # ES: Verificar que ml_modules existe | EN: Verify ml_modules exists | JA: ml_modules ã®å­˜åœ¨ç¢ºèª
            if not venv_ml_modules.exists() or not (venv_ml_modules / "models_cls.py").exists():
                self.error.emit(f"âŒ ml_modules ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {venv_ml_modules}")
                return
            
            print(f"âœ… ml_modules ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ: {venv_ml_modules}")
            
            # ES: Buscar Run_pipeline_ver3.3_20250914.py en .venv | EN: Locate Run_pipeline_ver3.3_20250914.py in .venv | JA: .venv å†…ã® Run_pipeline_ver3.3_20250914.py ã‚’æ¢ç´¢
            venv_pipeline_script = script_dir / "Run_pipeline_ver3.3_20250914.py"
            if not venv_pipeline_script.exists():
                venv_pipeline_script = script_dir.parent / "Run_pipeline_ver3.3_20250914.py"
            
            if not venv_pipeline_script.exists():
                self.error.emit(f"âŒ Run_pipeline_ver3.3_20250914.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {venv_pipeline_script}")
                return
            
            print(f"âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¦‹ã¤ã‘ã¾ã—ãŸ: {venv_pipeline_script}")
            
            # ES: Crear carpeta 00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ en la carpeta de salida | EN: Create 00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ under output folder | JA: å‡ºåŠ›å…ˆã« 00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ã‚’ä½œæˆ
            data_folder = os.path.join(self.output_folder, "00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
            os.makedirs(data_folder, exist_ok=True)
            
            # ES: Guardar datos filtrados en 00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | EN: Save filtered data into 00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | JA: ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ 00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ã«ä¿å­˜
            self.status_updated.emit("ğŸ’¾ Guardando datos filtrados...")
            # ES: Usar fecha actual para el nombre del archivo | EN: Use current date for the filename | JA: ãƒ•ã‚¡ã‚¤ãƒ«åã«ç¾åœ¨æ—¥ä»˜ã‚’ä½¿ç”¨
            from datetime import datetime
            date_str = datetime.now().strftime("%Y%m%d")
            input_filename = f"{date_str}_ç·å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx"
            input_file = os.path.join(data_folder, input_filename)
            self.filtered_df.to_excel(input_file, index=False)
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {input_file}")
            
            # ES: Guardar el nombre del archivo para usarlo en la configuraciÃ³n | EN: Store the filename for config generation | JA: è¨­å®šç”Ÿæˆã®ãŸã‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿æŒ
            self.input_filename = input_filename
            
            # ES: Buscar y procesar archivo æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx del proyecto | EN: Find and process project's æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx | JA: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsxã‚’æ¢ç´¢ãƒ»å‡¦ç†
            self.status_updated.emit("ğŸ“‹ Procesando archivo de predicciÃ³n...")
            predict_input_file = self._create_prediction_input_file(data_folder)
            if not predict_input_file:
                self.error.emit("âŒ Prediction_input.xlsx ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return
            
            print(f"âœ… äºˆæ¸¬ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {predict_input_file}")
            
            # ES: Verificar cancelaciÃ³n | EN: Check cancellation | JA: ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
            if self._cancelled:
                return
            
            # ES: Crear archivo de configuraciÃ³n temporal en la carpeta de salida | EN: Create temporary config file in the output folder | JA: å‡ºåŠ›å…ˆã«ä¸€æ™‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            self.status_updated.emit("âš™ï¸ Creando configuraciÃ³n temporal...")
            # ES: El archivo de configuraciÃ³n se guarda directamente en output_folder/config_cls.py
            # EN: The config file is saved directly to output_folder/config_cls.py
            # JP: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯ output_folder/config_cls.py ã«ç›´æ¥ä¿å­˜ã•ã‚Œã‚‹
            config_file = self._create_temp_config()
            
            if config_file and os.path.exists(config_file):
                print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {config_file}")
            
            # ES: Usar el script original del .venv (no copiado) | EN: Use the original .venv script (not copied) | JA: .venv ã®å…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ï¼ˆã‚³ãƒ”ãƒ¼ã—ãªã„ï¼‰
            pipeline_script = str(venv_pipeline_script)
            
            # ES: Verificar cancelaciÃ³n | EN: Check cancellation | JA: ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
            if self._cancelled:
                return
            
            # ES: Ejecutar el pipeline | EN: Run the pipeline | JA: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
            self.status_updated.emit("ğŸ”§ Ejecutando pipeline de clasificaciÃ³n...")
            self.progress_updated.emit(20, "Pipelineå®Ÿè¡Œä¸­...")
            
            success = self._run_pipeline(pipeline_script, self.output_folder, config_file)
            
            if self._cancelled:
                return
            
            if not success:
                self.error.emit("âŒ Error ejecutando el pipeline de clasificaciÃ³n")
                return
            
            # ES: Buscar resultados generados | EN: Find generated results | JA: ç”Ÿæˆã•ã‚ŒãŸçµæœã‚’æ¢ç´¢
            self.status_updated.emit("ğŸ“Š Buscando resultados...")
            results = self._find_results()
            
            # ES: Calcular tiempo total | EN: Compute total time | JA: ç·æ™‚é–“ã‚’è¨ˆç®—
            end_time = time.time()
            analysis_duration = end_time - start_time
            
            results['output_folder'] = self.output_folder
            results['analysis_duration'] = analysis_duration
            results['project_folder'] = self.project_folder
            results['load_existing'] = False  # Not an existing-load; it's a new analysis
            
            self.progress_updated.emit(100, "åˆ†æå®Œäº†")
            self.status_updated.emit("âœ… åˆ†é¡åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            
            self.finished.emit(results)
            
        except Exception as e:
            import traceback
            error_msg = f"âŒ Error en anÃ¡lisis de clasificaciÃ³n: {str(e)}\n{traceback.format_exc()}"
            print(error_msg)
            self.error.emit(error_msg)
    
    def _create_temp_config(self):
        """ES: Crea un archivo de configuraciÃ³n temporal basado en config_values
        EN: Create a temporary config file from config_values
        JA: config_values ã‹ã‚‰ä¸€æ™‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        # ES: El pipeline busca config_cls.py en ml_modules, asÃ­ que creamos
        # EN: The pipeline looks for config_cls.py in ml_modules, so we create
        # JP: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ml_moduleså†…ã®config_cls.pyã‚’æ¢ã™ãŸã‚ã€ä½œæˆã™ã‚‹
        # ES: un 99_ml_modules en la carpeta de salida solo con config_cls.py
        # EN: a 99_ml_modules folder under the output folder containing only config_cls.py
        # JP: å‡ºåŠ›å…ˆã«config_cls.pyã ã‘å…¥ã£ãŸ99_ml_modulesã‚’ä½œã‚‹
        ml_modules_dst = Path(self.output_folder) / "99_ml_modules"
        ml_modules_dst.mkdir(parents=True, exist_ok=True)
        
        config_file = ml_modules_dst / "config_cls.py"
        
        # ES: Crear carpeta 99_-----------------
        # EN: Create folder 99_-----------------
        # JP: 99_----------------- ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        separator_folder = Path(self.output_folder) / "99_-----------------"
        separator_folder.mkdir(parents=True, exist_ok=True)
        
        # ES: TambiÃ©n crear ml_modules como symlink a 99_ml_modules para compatibilidad con el pipeline
        # EN: Also create ml_modules as a symlink to 99_ml_modules for pipeline compatibility
        # JP: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³äº’æ›ã®ãŸã‚ã€ml_modulesã‚’99_ml_modulesã¸ã®ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã¨ã—ã¦ä½œæˆã™ã‚‹
        # ES: El pipeline busca BASE / "ml_modules", asÃ­ que necesitamos crear este symlink
        # EN: The pipeline looks for BASE / "ml_modules", so we need this symlink
        # JP: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯BASE / \"ml_modules\"ã‚’å‚ç…§ã™ã‚‹ãŸã‚ã€ã“ã®ãƒªãƒ³ã‚¯ãŒå¿…è¦
        ml_modules_alias = Path(self.output_folder) / "ml_modules"
        if not ml_modules_alias.exists():
            try:
                # ES: En Windows, intentar crear symlink (puede requerir privilegios)
                # EN: On Windows, try to create a symlink (may require privileges)
                # JP: Windowsã§ã¯ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆã‚’è©¦ã™ï¼ˆæ¨©é™ãŒå¿…è¦ãªå ´åˆã‚ã‚Šï¼‰
                if hasattr(os, 'symlink'):
                    os.symlink("99_ml_modules", ml_modules_alias, target_is_directory=True)
                    print(f"âœ… ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ: {ml_modules_alias} -> 99_ml_modules")
                else:
                    # ES: Si no hay symlink, copiar solo config_cls.py a ml_modules tambiÃ©n
                    # EN: If symlinks are not available, also copy only config_cls.py into ml_modules
                    # JP: ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä¸å¯ãªã‚‰ã€ml_modulesã«ã‚‚config_cls.pyã ã‘ã‚³ãƒ”ãƒ¼ã™ã‚‹
                    ml_modules_fallback = Path(self.output_folder) / "ml_modules"
                    ml_modules_fallback.mkdir(parents=True, exist_ok=True)
                    import shutil
                    shutil.copy2(config_file, ml_modules_fallback / "config_cls.py")
                    print(f"âœ… äº’æ›æ€§ã®ãŸã‚ config_cls.py ã‚‚ ml_modules ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ")
            except Exception as e:
                # ES: Si falla el symlink, copiar solo config_cls.py
                # EN: If creating the symlink fails, copy only config_cls.py
                # JP: ãƒªãƒ³ã‚¯ä½œæˆã«å¤±æ•—ã—ãŸå ´åˆã¯config_cls.pyã®ã¿ã‚³ãƒ”ãƒ¼ã™ã‚‹
                ml_modules_fallback = Path(self.output_folder) / "ml_modules"
                ml_modules_fallback.mkdir(parents=True, exist_ok=True)
                import shutil
                shutil.copy2(config_file, ml_modules_fallback / "config_cls.py")
                print(f"âš ï¸ ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’ä½œæˆã§ãã¾ã›ã‚“ã€‚config_cls.py ã‚’ ml_modules ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã™: {e}")
        
        # ES: Leer el archivo config_cls.py original como plantilla
        # EN: Read the original config_cls.py as a template
        # JP: å…ƒã®config_cls.pyã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ã—ã¦èª­ã¿è¾¼ã‚€
        config_cls_path = self._find_config_cls()
        config_content = ""
        
        if config_cls_path and os.path.exists(config_cls_path):
            with open(config_cls_path, 'r', encoding='utf-8') as f:
                config_content = f.read()
        
        # ES: Si no se encuentra, crear uno bÃ¡sico
        # EN: If it's not found, create a basic one
        # JP: è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯åŸºæœ¬ç‰ˆã‚’ä½œæˆã™ã‚‹
        if not config_content:
            config_content = self._get_default_config_content()
        
        # ES: Modificar los valores segÃºn config_values
        # EN: Modify values according to config_values
        # JP: config_valuesã«å¾“ã£ã¦å€¤ã‚’å¤‰æ›´ã™ã‚‹
        modified_content = self._modify_config_content(config_content, self.config_values)
        
        # ES: Escribir archivo temporal
        # EN: Write temporary file
        # JP: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        
        print(f"âœ… ä¸€æ™‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {config_file}")
        return str(config_file)
    
    def _find_config_cls(self):
        """Busca el archivo config_cls.py"""
        potential_paths = [
            Path(__file__).parent / "ml_modules" / "config_cls.py",
            Path(__file__).parent.parent / "ml_modules" / "config_cls.py",
            Path.cwd() / "ml_modules" / "config_cls.py",
        ]
        
        for path in potential_paths:
            if path.exists():
                return str(path)
        
        return None
    
    def _get_default_config_content(self):
        """Retorna contenido por defecto de config_cls.py"""
        return '''from __future__ import annotations
from typing import List, Tuple, Dict, Optional, Literal, Union, Set
import numpy as np

class ConfigCLS:
    """ES: ConfiguraciÃ³n temporal para clasificaciÃ³n
    EN: Temporary configuration for classification
    JA: åˆ†é¡ç”¨ã®ä¸€æ™‚è¨­å®š"""
    pass
'''
    
    def _modify_config_content(self, content, config_values):
        """ES: Modifica el contenido de config_cls.py segÃºn config_values
        EN: Modify config_cls.py content according to config_values
        JA: config_values ã«å¾“ã„ config_cls.py ã®å†…å®¹ã‚’å¤‰æ›´"""
        # ES: Esta funciÃ³n modifica los valores en el contenido del archivo
        # EN: This function modifies values in the file content
        # JP: ã“ã®é–¢æ•°ã¯ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹å†…ã®å€¤ã‚’å¤‰æ›´ã™ã‚‹
        # ES: Por simplicidad, crearemos un archivo que sobrescriba los valores
        # EN: For simplicity, we generate content that overwrites the values
        # JP: å˜ç´”åŒ–ã®ãŸã‚ã€å€¤ã‚’ä¸Šæ›¸ãã™ã‚‹å†…å®¹ã‚’ç”Ÿæˆã™ã‚‹
        
        modifications = []
        
        # CaracterÃ­sticas
        if 'ALLOWED_FEATURES' in config_values:
            features_str = ', '.join([f"'{f}'" for f in sorted(config_values['ALLOWED_FEATURES'])])
            modifications.append(f"    ALLOWED_FEATURES: Set[str] = set([{features_str}])")
        
        if 'MUST_KEEP_FEATURES' in config_values:
            features_str = ', '.join([f"'{f}'" for f in sorted(config_values['MUST_KEEP_FEATURES'])])
            modifications.append(f"    MUST_KEEP_FEATURES: Set[str] = set([{features_str}])")
        
        if 'CONTINUOUS_FEATURES' in config_values:
            features_str = ', '.join([f"'{f}'" for f in config_values['CONTINUOUS_FEATURES']])
            modifications.append(f"    CONTINUOUS_FEATURES = [{features_str}]")
        
        if 'DISCRETE_FEATURES' in config_values:
            features_str = ', '.join([f"'{f}'" for f in config_values['DISCRETE_FEATURES']])
            modifications.append(f"    DISCRETE_FEATURES = [{features_str}]")
        
        if 'BINARY_FEATURES' in config_values:
            features_str = ', '.join([f"'{f}'" for f in config_values['BINARY_FEATURES']])
            modifications.append(f"    BINARY_FEATURES = [{features_str}]")
        
        if 'INTEGER_FEATURES' in config_values:
            features_str = ', '.join([f"'{f}'" for f in config_values['INTEGER_FEATURES']])
            modifications.append(f"    INTEGER_FEATURES = [{features_str}]")
        
        # Modelos
        if 'MODELS_TO_USE' in config_values:
            models_str = ', '.join([f'"{m}"' for m in config_values['MODELS_TO_USE']])
            modifications.append(f"    MODELS_TO_USE: List[str] = [{models_str}]")
        
        if 'COMPARE_MODELS' in config_values:
            modifications.append(f"    COMPARE_MODELS: bool = {config_values['COMPARE_MODELS']}")
        
        if 'MODEL_COMPARISON_CV_SPLITS' in config_values:
            modifications.append(f"    MODEL_COMPARISON_CV_SPLITS: int = {config_values['MODEL_COMPARISON_CV_SPLITS']}")
        
        if 'MODEL_COMPARISON_SCORING' in config_values:
            modifications.append(f"    MODEL_COMPARISON_SCORING: str = '{config_values['MODEL_COMPARISON_SCORING']}'")
        
        # OptimizaciÃ³n multiobjetivo
        if 'N_TRIALS_MULTI_OBJECTIVE' in config_values:
            modifications.append(f"    N_TRIALS_MULTI_OBJECTIVE: int = {config_values['N_TRIALS_MULTI_OBJECTIVE']}")
        
        if 'FP_WEIGHT' in config_values:
            modifications.append(f"    FP_WEIGHT: float = {config_values['FP_WEIGHT']}")
        
        if 'COVERAGE_WEIGHT' in config_values:
            modifications.append(f"    COVERAGE_WEIGHT: float = {config_values['COVERAGE_WEIGHT']}")
        
        if 'AUC_WEIGHT' in config_values:
            modifications.append(f"    AUC_WEIGHT: float = {config_values['AUC_WEIGHT']}")
        
        if 'NP_ALPHA_RANGE' in config_values:
            min_val, max_val = config_values['NP_ALPHA_RANGE']
            modifications.append(f"    NP_ALPHA_RANGE: Tuple[float, float] = ({min_val}, {max_val})")
        
        # DCV
        if 'OUTER_SPLITS' in config_values:
            modifications.append(f"    OUTER_SPLITS: int = {config_values['OUTER_SPLITS']}")
        
        if 'INNER_SPLITS' in config_values:
            modifications.append(f"    INNER_SPLITS: int = {config_values['INNER_SPLITS']}")
        
        if 'RANDOM_STATE' in config_values:
            modifications.append(f"    RANDOM_STATE: int = {config_values['RANDOM_STATE']}")
        
        if 'N_TRIALS_INNER' in config_values:
            modifications.append(f"    N_TRIALS_INNER: int = {config_values['N_TRIALS_INNER']}")
        
        if 'USE_INNER_NOISE' in config_values:
            modifications.append(f"    USE_INNER_NOISE: bool = {config_values['USE_INNER_NOISE']}")
        
        if 'NOISE_PPM' in config_values:
            modifications.append(f"    NOISE_PPM: int = {config_values['NOISE_PPM']}")
        
        if 'NOISE_RATIO' in config_values:
            modifications.append(f"    NOISE_RATIO: float = {config_values['NOISE_RATIO']}")
        
        # Umbrales
        if 'NP_ALPHA' in config_values:
            modifications.append(f"    NP_ALPHA: float = {config_values['NP_ALPHA']}")
        
        if 'USE_UPPER_CI_ADJUST' in config_values:
            modifications.append(f"    USE_UPPER_CI_ADJUST: bool = {config_values['USE_UPPER_CI_ADJUST']}")
        
        if 'CI_METHOD' in config_values:
            modifications.append(f"    CI_METHOD: Literal['wilson', 'normal', 'jeffreys'] = '{config_values['CI_METHOD']}'")
        
        if 'CI_CONFIDENCE' in config_values:
            modifications.append(f"    CI_CONFIDENCE: float = {config_values['CI_CONFIDENCE']}")
        
        if 'TAU_NEG_FALLBACK_RATIO' in config_values:
            modifications.append(f"    TAU_NEG_FALLBACK_RATIO: float = {config_values['TAU_NEG_FALLBACK_RATIO']}")
        
        # EvaluaciÃ³n
        if 'FINAL_EVALUATION_CV_SPLITS' in config_values:
            modifications.append(f"    FINAL_EVALUATION_CV_SPLITS: int = {config_values['FINAL_EVALUATION_CV_SPLITS']}")
        
        if 'FINAL_EVALUATION_SHUFFLE' in config_values:
            modifications.append(f"    FINAL_EVALUATION_SHUFFLE: bool = {config_values['FINAL_EVALUATION_SHUFFLE']}")
        
        if 'FINAL_EVALUATION_RANDOM_STATE' in config_values:
            modifications.append(f"    FINAL_EVALUATION_RANDOM_STATE: int = {config_values['FINAL_EVALUATION_RANDOM_STATE']}")
        
        if 'HOLDOUT_TEST_SIZE' in config_values:
            modifications.append(f"    HOLDOUT_TEST_SIZE: float = {config_values['HOLDOUT_TEST_SIZE']}")
        
        if 'HOLDOUT_STRATIFY' in config_values:
            modifications.append(f"    HOLDOUT_STRATIFY: bool = {config_values['HOLDOUT_STRATIFY']}")
        
        if 'HOLDOUT_RANDOM_STATE' in config_values:
            modifications.append(f"    HOLDOUT_RANDOM_STATE: int = {config_values['HOLDOUT_RANDOM_STATE']}")
        
        if 'GRAY_ZONE_MIN_WIDTH' in config_values:
            modifications.append(f"    GRAY_ZONE_MIN_WIDTH: float = {config_values['GRAY_ZONE_MIN_WIDTH']}")
        
        if 'GRAY_ZONE_MAX_WIDTH' in config_values:
            modifications.append(f"    GRAY_ZONE_MAX_WIDTH: float = {config_values['GRAY_ZONE_MAX_WIDTH']}")
        
        # Actualizar rutas de salida (relativas al directorio de trabajo)
        # El pipeline espera DATA_FOLDER = "00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ" (carpeta que creamos)
        # ES: Usar el nombre del archivo con fecha actual
        # EN: Use a filename with the current date
        # JP: ç¾åœ¨æ—¥ä»˜ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨ã™ã‚‹
        input_filename = getattr(self, 'input_filename', None)
        if not input_filename:
            from datetime import datetime
            date_str = datetime.now().strftime("%Y%m%d")
            input_filename = f"{date_str}_ç·å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx"
        
        modifications.append(f'    DATA_FOLDER: str = "00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"')
        modifications.append(f'    INPUT_FILE: str = "{input_filename}"')
        modifications.append(f'    PREDICT_INPUT_FILE: str = "Prediction_input.xlsx"')
        # ES: Cambiar PARENT_FOLDER_TEMPLATE a "." para que no cree carpeta intermedia
        # EN: Set PARENT_FOLDER_TEMPLATE to \".\" so it does not create an intermediate folder
        # JP: ä¸­é–“ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œã‚‰ãªã„ã‚ˆã†PARENT_FOLDER_TEMPLATEã‚’\".\"ã«ã™ã‚‹
        modifications.append(f'    PARENT_FOLDER_TEMPLATE: str = "."')
        
        # ES: Crear contenido final
        # EN: Build final content
        # JP: æœ€çµ‚å†…å®¹ã‚’ç”Ÿæˆ
        # ES: Reemplazar valores existentes en lugar de solo agregar
        # EN: Replace existing values instead of only appending
        # JP: è¿½è¨˜ã ã‘ã§ãªãæ—¢å­˜å€¤ã‚’ç½®æ›ã™ã‚‹
        final_content = content
        
        # Reemplazar DATA_FOLDER si existe
        import re
        # ES: Buscar y reemplazar DATA_FOLDER
        # EN: Find and replace DATA_FOLDER
        # JP: DATA_FOLDERã‚’æ¤œç´¢ã—ã¦ç½®æ›
        final_content = re.sub(
            r'(\s+DATA_FOLDER:\s*str\s*=\s*)"[^"]*"',
            r'\1"00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"',
            final_content
        )
        
        # ES: Reemplazar INPUT_FILE si existe (usar el nombre del archivo con fecha actual)
        # EN: Replace INPUT_FILE if it exists (use the current-date filename)
        # JP: INPUT_FILEãŒã‚ã‚Œã°ç½®æ›ï¼ˆç¾åœ¨æ—¥ä»˜ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨ï¼‰
        input_filename = getattr(self, 'input_filename', None)
        if not input_filename:
            from datetime import datetime
            date_str = datetime.now().strftime("%Y%m%d")
            input_filename = f"{date_str}_ç·å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx"
        
        final_content = re.sub(
            r'(\s+INPUT_FILE:\s*str\s*=\s*)"[^"]*"',
            f'\\1"{input_filename}"',
            final_content
        )
        
        # Reemplazar PREDICT_INPUT_FILE si existe
        final_content = re.sub(
            r'(\s+PREDICT_INPUT_FILE:\s*str\s*=\s*)"[^"]*"',
            r'\1"Prediction_input.xlsx"',
            final_content
        )
        
        # ES: Reemplazar PARENT_FOLDER_TEMPLATE para que no cree carpeta intermedia
        # EN: Replace PARENT_FOLDER_TEMPLATE so it does not create an intermediate folder
        # JP: ä¸­é–“ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œã‚‰ãªã„ã‚ˆã†PARENT_FOLDER_TEMPLATEã‚’ç½®æ›
        final_content = re.sub(
            r'(\s+PARENT_FOLDER_TEMPLATE:\s*str\s*=\s*)"[^"]*"',
            r'\1"."',
            final_content
        )
        
        # ES: Reemplazar PARENT_FOLDER_TEMPLATE para que no cree carpeta intermedia
        # EN: Replace PARENT_FOLDER_TEMPLATE so it does not create an intermediate folder
        # JP: ä¸­é–“ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œã‚‰ãªã„ã‚ˆã†PARENT_FOLDER_TEMPLATEã‚’ç½®æ›
        final_content = re.sub(
            r'(\s+PARENT_FOLDER_TEMPLATE:\s*str\s*=\s*)"[^"]*"',
            r'\1"."',
            final_content
        )
        
        # ES: Agregar modificaciones al final de la clase
        # EN: Append modifications at the end of the class
        # JP: ã‚¯ãƒ©ã‚¹æœ«å°¾ã«å¤‰æ›´ã‚’è¿½åŠ 
        if "class ConfigCLS:" in final_content:
            # Insertar modificaciones antes del Ãºltimo mÃ©todo o al final de la clase
            # ES: Buscar el Ãºltimo @classmethod o mÃ©todo y agregar antes
            # EN: Find the last @classmethod or method and insert before it
            # JP: æœ€å¾Œã®@classmethod/ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ¢ã—ã€ãã®å‰ã«æŒ¿å…¥ã™ã‚‹
            lines = final_content.split('\n')
            insert_pos = len(lines)
            
            # ES: Buscar el final de la clase (Ãºltima lÃ­nea antes de una lÃ­nea vacÃ­a o fuera de la clase)
            # EN: Find the end of the class (last line before a blank line or leaving the class)
            # JP: ã‚¯ãƒ©ã‚¹çµ‚ç«¯ã‚’æ¢ã™ï¼ˆç©ºè¡Œ/ã‚¯ãƒ©ã‚¹å¤–ã«å‡ºã‚‹ç›´å‰ã®æœ€çµ‚è¡Œï¼‰
            for i in range(len(lines) - 1, -1, -1):
                if lines[i].strip().startswith('@classmethod') or lines[i].strip().startswith('def '):
                    # Encontrar el final de este mÃ©todo
                    j = i + 1
                    indent_level = len(lines[i]) - len(lines[i].lstrip())
                    while j < len(lines):
                        if lines[j].strip() and not lines[j].startswith(' ' * (indent_level + 1)) and not lines[j].startswith('\t'):
                            if not lines[j].strip().startswith('#'):
                                insert_pos = j
                                break
                        j += 1
                    break
            
            # Insertar modificaciones
            modifications_text = "\n    # === Modificaciones temporales ===\n"
            for mod in modifications:
                modifications_text += "    " + mod + "\n"
            
            lines.insert(insert_pos, modifications_text)
            final_content = '\n'.join(lines)
        else:
            # ES: Si no hay clase, crear una bÃ¡sica
            # EN: If there is no class, create a basic one
            # JP: ã‚¯ãƒ©ã‚¹ãŒç„¡ã„å ´åˆã¯åŸºæœ¬ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆã™ã‚‹
            final_content += "\n\n# === Modificaciones temporales ===\n"
            for mod in modifications:
                final_content += mod + "\n"
        
        return final_content
    
    def _create_prediction_input_file(self, data_folder):
        """
        Crea el archivo Prediction_input.xlsx basado en el archivo æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx del proyecto
        Agrega las columnas A11, A21, A32 segÃºn la selecciÃ³n del usuario
        Si no encuentra el archivo, pide al usuario que lo seleccione manualmente
        """
        try:
            # Buscar archivo æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx en la carpeta del proyecto
            project_path = Path(self.project_folder)
            
            # Buscar archivo con patrÃ³n *_æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx
            unexperimented_files = list(project_path.glob("*_æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx"))
            
            unexperimented_file = None
            
            if not unexperimented_files:
                # ES: No se encontrÃ³ el archivo; pedir al usuario que lo seleccione
                # EN: File not found; ask the user to select it
                # JP: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é¸æŠã—ã¦ã‚‚ã‚‰ã†
                self.console_output.emit(f"âš ï¸ *_æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {project_path}")
                self.status_updated.emit("ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠå¾…ã¡...")
                
                # Resetear variables de selecciÃ³n
                self._selected_file_path = None
                self._file_selection_event.clear()
                
                # Emitir seÃ±al para que la GUI muestre el diÃ¡logo
                self.file_selection_requested.emit(str(project_path))
                
                # ES: Esperar a que el usuario seleccione el archivo (mÃ¡ximo 5 minutos)
                # EN: Wait for the user to select a file (max 5 minutes)
                # JP: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã‚’å¾…ã¤ï¼ˆæœ€å¤§5åˆ†ï¼‰
                max_wait = 300  # 5 minutos en segundos
                if self._file_selection_event.wait(timeout=max_wait):
                    # ES: El usuario seleccionÃ³ un archivo
                    # EN: User selected a file
                    # JP: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ãŸ
                    if self._selected_file_path:
                        unexperimented_file = Path(self._selected_file_path)
                        print(f"ğŸ“‹ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸãƒ•ã‚¡ã‚¤ãƒ«: {unexperimented_file}")
                    else:
                        self.error.emit("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                        return None
                else:
                    # ES: Timeout: el usuario no seleccionÃ³ el archivo a tiempo
                    # EN: Timeout: user did not select a file in time
                    # JP: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ™‚é–“å†…ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ãªã‹ã£ãŸ
                    self.error.emit("âŒ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
                    return None
            else:
                # ES: Usar el primer archivo encontrado
                # EN: Use the first found file
                # JP: è¦‹ã¤ã‹ã£ãŸæœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹
                unexperimented_file = unexperimented_files[0]
                print(f"ğŸ“‹ æœªå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ: {unexperimented_file}")
            
            # ES: Leer el archivo
            # EN: Read the file
            # JP: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
            self.status_updated.emit("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
            df_predict = pd.read_excel(unexperimented_file)
            
            # ES: Validar que el archivo tiene las columnas necesarias
            # EN: Validate that the file contains the required columns
            # JP: å¿…è¦ãªåˆ—ãŒã‚ã‚‹ã‹æ¤œè¨¼ã™ã‚‹
            required_columns = ['å›è»¢é€Ÿåº¦', 'é€ã‚Šé€Ÿåº¦', 'UPã‚«ãƒƒãƒˆ', 'åˆ‡è¾¼é‡', 'çªå‡ºé‡', 'è¼‰ã›ç‡', 'ãƒ‘ã‚¹æ•°']
            missing_columns = [col for col in required_columns if col not in df_predict.columns]
            
            if missing_columns:
                error_msg = (
                    f"âŒ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“:\n\n"
                    f"ä¸è¶³ã—ã¦ã„ã‚‹åˆ—: {', '.join(missing_columns)}\n\n"
                    f"å¿…è¦ãªåˆ—: {', '.join(required_columns)}\n\n"
                    f"ãƒ•ã‚¡ã‚¤ãƒ«: {unexperimented_file}"
                )
                self.error.emit(error_msg)
                return None
            
            # ES: Validar que el archivo tiene al menos una fila de datos
            # EN: Validate that the file has at least one data row
            # JP: å°‘ãªãã¨ã‚‚1è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹æ¤œè¨¼ã™ã‚‹
            if len(df_predict) == 0:
                self.error.emit(f"âŒ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“: {unexperimented_file}")
                return None
            
            print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚åˆ—: {list(df_predict.columns)}")
            print(f"âœ… è¡Œæ•°: {len(df_predict)}")
            
            # ES: Agregar columnas A13, A11, A21, A32
            # EN: Add columns A13, A11, A21, A32
            # JP: A13/A11/A21/A32åˆ—ã‚’è¿½åŠ 
            # La columna seleccionada serÃ¡ 1, las otras 0
            # A13 debe estar en la primera posiciÃ³n (columna A)
            df_predict['A13'] = 0
            df_predict['A11'] = 0
            df_predict['A21'] = 0
            df_predict['A32'] = 0
            
            # Establecer la columna seleccionada en 1
            if self.selected_brush == "A13":
                df_predict['A13'] = 1
            elif self.selected_brush == "A11":
                df_predict['A11'] = 1
            elif self.selected_brush == "A21":
                df_predict['A21'] = 1
            elif self.selected_brush == "A32":
                df_predict['A32'] = 1
            
            # Agregar columnas ææ–™ y ç·šæé•· con los valores seleccionados
            df_predict['ææ–™'] = self.selected_material
            df_predict['ç·šæé•·'] = self.selected_wire_length
            
            # Reordenar columnas para que A13 estÃ© primero (columna A)
            # Obtener todas las columnas
            all_columns = list(df_predict.columns)
            # Remover A13, A11, A21, A32, ææ–™, ç·šæé•· de la lista
            brush_columns = ['A13', 'A11', 'A21', 'A32']
            param_columns = ['ææ–™', 'ç·šæé•·']
            other_columns = [col for col in all_columns if col not in brush_columns + param_columns]
            # Crear nuevo orden: A13 primero, luego A11, A21, A32, luego ææ–™, ç·šæé•·, luego el resto
            new_column_order = brush_columns + param_columns + other_columns
            # Reordenar DataFrame
            df_predict = df_predict[new_column_order]
            
            # Guardar como Prediction_input.xlsx en 00_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
            output_file = os.path.join(data_folder, "Prediction_input.xlsx")
            df_predict.to_excel(output_file, index=False)
            
            return output_file
            
        except Exception as e:
            self.console_output.emit(f"âŒ Prediction_input.xlsx ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def _find_pipeline_script(self):
        """Busca el archivo Run_pipeline_ver3.3_20250914.py en .venv"""
        script_dir = Path(__file__).parent.absolute()
        potential_paths = [
            script_dir / "Run_pipeline_ver3.3_20250914.py",
            script_dir.parent / "Run_pipeline_ver3.3_20250914.py",
        ]
        
        for path in potential_paths:
            if path.exists():
                return str(path)
        
        return None
    
    def _run_pipeline(self, script_path, working_dir, config_file):
        """ES: Ejecuta el pipeline de clasificaciÃ³n
        EN: Run the classification pipeline
        JA: åˆ†é¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ"""
        try:
            # Configurar variables de entorno
            env = os.environ.copy()
            env["OMP_NUM_THREADS"] = "1"
            env["MKL_NUM_THREADS"] = "1"
            env["OPENBLAS_NUM_THREADS"] = "1"
            env["NUMEXPR_NUM_THREADS"] = "1"
            env["MPLBACKEND"] = "Agg"
            env["QT_QPA_PLATFORM"] = "offscreen"
            env["KMP_DUPLICATE_LIB_OK"] = "TRUE"
            
            # ES: Buscar ml_modules en .venv (no copiado)
            # EN: Locate ml_modules in .venv (not copied)
            # JP: .venvå†…ã®ml_modulesã‚’æ¢ã™ï¼ˆã‚³ãƒ”ãƒ¼ã—ãªã„ï¼‰
            script_dir = Path(__file__).parent.absolute()
            venv_ml_modules = script_dir / "ml_modules"
            if not venv_ml_modules.exists() or not (venv_ml_modules / "models_cls.py").exists():
                venv_ml_modules = script_dir.parent / "ml_modules"
            
            if venv_ml_modules.exists():
                env["ML_MODULES_PATH"] = str(venv_ml_modules)
            
            # Configurar PYTHONPATH
            # El pipeline se ejecuta desde working_dir
            # BASE = Path("./") en el script se refiere al directorio de trabajo actual
            python_paths = []
            
            # 1. 99_ml_modules dentro de working_dir (PRIMERO) - donde estÃ¡ config_cls.py modificado
            # El pipeline busca config_cls desde ml_modules, asÃ­ que esto debe tener prioridad
            ml_modules_in_workdir = Path(working_dir) / "99_ml_modules"
            if ml_modules_in_workdir.exists():
                python_paths.append(str(ml_modules_in_workdir))
            
            # ES: TambiÃ©n crear un symlink o alias ml_modules -> 99_ml_modules para compatibilidad
            # EN: Also create a symlink/alias ml_modules -> 99_ml_modules for compatibility
            # JP: äº’æ›æ€§ã®ãŸã‚ml_modules -> 99_ml_modulesã®ãƒªãƒ³ã‚¯/ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚‚ä½œæˆã™ã‚‹
            # ES: En Windows, creamos un symlink si es posible; si no, al menos usamos 99_ml_modules en PYTHONPATH
            # EN: On Windows, create a symlink if possible; otherwise at least use 99_ml_modules in PYTHONPATH
            # JP: Windowsã§ã¯å¯èƒ½ãªã‚‰ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã€ä¸å¯ãªã‚‰99_ml_modulesã‚’PYTHONPATHã«å…¥ã‚Œã‚‹
            ml_modules_alias = Path(working_dir) / "ml_modules"
            if not ml_modules_alias.exists() and ml_modules_in_workdir.exists():
                try:
                    # ES: Intentar crear symlink (requiere permisos en Windows)
                    # EN: Try to create a symlink (requires permissions on Windows)
                    # JP: ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆã‚’è©¦ã™ï¼ˆWindowsã§ã¯æ¨©é™ãŒå¿…è¦ï¼‰
                    if hasattr(os, 'symlink'):
                        os.symlink(ml_modules_in_workdir, ml_modules_alias, target_is_directory=True)
                        python_paths.append(str(ml_modules_alias))
                except:
                    # ES: Si falla, al menos agregar 99_ml_modules al path
                    # EN: If it fails, at least add 99_ml_modules to the path
                    # JP: å¤±æ•—ã—ãŸå ´åˆã¯æœ€ä½é™99_ml_modulesã‚’ãƒ‘ã‚¹ã«è¿½åŠ ã™ã‚‹
                    pass
            
            # 2. working_dir - directorio de trabajo actual
            python_paths.append(str(working_dir))
            
            # 3. ml_modules del .venv (para que encuentre models_cls.py, etc.)
            if venv_ml_modules.exists():
                python_paths.append(str(venv_ml_modules))
            
            # 4. Directorio donde estÃ¡ el script del pipeline
            script_dir = Path(script_path).parent
            if script_dir.exists():
                python_paths.append(str(script_dir))
            
            # ES: 6. Agregar site-packages
            # EN: 6. Add site-packages
            # JP: 6. site-packages ã‚’è¿½åŠ 
            import site
            for site_pkg in site.getsitepackages():
                if os.path.exists(site_pkg):
                    python_paths.append(site_pkg)
            
            # ES: 7. Agregar PYTHONPATH existente si hay
            # EN: 7. Add existing PYTHONPATH if present
            # JP: 7. æ—¢å­˜ã®PYTHONPATHãŒã‚ã‚Œã°è¿½åŠ 
            existing_pythonpath = env.get("PYTHONPATH", "")
            if existing_pythonpath:
                python_paths.append(existing_pythonpath)
            
            # Eliminar duplicados manteniendo el orden
            seen = set()
            unique_paths = []
            for path in python_paths:
                if path not in seen:
                    seen.add(path)
                    unique_paths.append(path)
            
            env["PYTHONPATH"] = os.pathsep.join(unique_paths)
            
            # Ejecutar script
            self.console_output.emit(f"ğŸ”§ Ejecutando: {script_path}")
            self.console_output.emit(f"ğŸ“ Directorio de trabajo: {working_dir}")
            self.console_output.emit(f"ğŸ“ PYTHONPATH: {env['PYTHONPATH']}")
            
            # ES: Verificar que config_cls.py existe en 99_ml_modules dentro de working_dir
            # EN: Verify that config_cls.py exists under 99_ml_modules in working_dir
            # JP: working_dirå†…ã®99_ml_modulesã«config_cls.pyãŒã‚ã‚‹ã‹ç¢ºèª
            ml_modules_in_workdir = Path(working_dir) / "99_ml_modules"
            config_check = ml_modules_in_workdir / "config_cls.py"
            if not config_check.exists():
                self.console_output.emit(f"âŒ ã‚¨ãƒ©ãƒ¼: config_cls.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ml_modules_in_workdir}")
                return False
            
            # ES: Verificar que ml_modules del .venv existe
            # EN: Verify that the .venv ml_modules exists
            # JP: .venvå´ã®ml_modulesãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if not venv_ml_modules.exists() or not (venv_ml_modules / "models_cls.py").exists():
                self.console_output.emit(f"âŒ ã‚¨ãƒ©ãƒ¼: ml_modules ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {venv_ml_modules}")
                return False
            
            # Usar el script original del .venv (no copiado)
            script_to_run = script_path
            self.console_output.emit(f"ğŸ“ Usando script del .venv: {script_to_run}")
            
            # ES: Debug: Verificar estructura antes de ejecutar
            # EN: Debug: Check structure before running
            # JP: Debug: å®Ÿè¡Œå‰ã«æ§‹é€ ã‚’ç¢ºèª
            self.console_output.emit(f"ğŸ“‹ Verificando estructura en {working_dir}:")
            workdir_path = Path(working_dir)
            if workdir_path.exists():
                try:
                    for item in workdir_path.iterdir():
                        if item.is_dir():
                            self.console_output.emit(f"  ğŸ“ {item.name}/")
                            if item.name == "ml_modules":
                                try:
                                    for subitem in item.iterdir():
                                        if subitem.is_file():
                                            self.console_output.emit(f"    ğŸ“„ {subitem.name}")
                                except:
                                    pass
                        elif item.is_file():
                            self.console_output.emit(f"  ğŸ“„ {item.name}")
                except Exception as e:
                    self.console_output.emit(f"âš ï¸ Error verificando estructura: {e}")
            
            # Asegurar que working_dir es un string para subprocess
            working_dir_str = str(working_dir) if isinstance(working_dir, Path) else working_dir
            
            # ES: Ejecutar script con Popen para poder leer salida en tiempo real
            # EN: Run the script with Popen so we can read output in real time
            # JP: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å‡ºåŠ›ã‚’èª­ã‚€ãŸã‚Popenã§ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            # IMPORTANTE: cwd debe ser working_dir para que BASE = Path("./") funcione
            process = subprocess.Popen(
                [sys.executable, script_to_run],
                cwd=working_dir_str,  # Ejecutar desde working_dir para que BASE = Path("./") funcione
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8',
                errors='replace',
                bufsize=1  # Line buffered
            )
            
            # ES: Guardar referencia al proceso para poder cancelarlo
            # EN: Store a reference to the process so we can cancel it
            # JP: ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã§ãã‚‹ã‚ˆã†ãƒ—ãƒ­ã‚»ã‚¹å‚ç…§ã‚’ä¿æŒ
            self._current_process = process
            
            # Event para detener los threads de lectura de forma segura
            stop_reading = threading.Event()
            self._stop_reading = stop_reading
            
            # ES: Leer stdout y stderr en tiempo real usando threads
            # EN: Read stdout and stderr in real time using threads
            # JP: ã‚¹ãƒ¬ãƒƒãƒ‰ã§stdout/stderrã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èª­å–
            def read_output(pipe, is_stderr=False):
                try:
                    while not stop_reading.is_set():
                        line = pipe.readline()
                        if not line:  # EOF o pipe cerrado
                            break
                        # Emitir directamente a consola
                        line_clean = line.rstrip('\n\r')
                        if line_clean:
                            prefix = "[STDERR] " if is_stderr else ""
                            self.console_output.emit(f"{prefix}{line_clean}")
                            # Parsear progreso para extraer informaciÃ³n detallada
                            self._parse_progress(line_clean)
                except (ValueError, OSError):
                    # Pipe ya cerrado â€” salir silenciosamente
                    pass
                except Exception:
                    # Cualquier otro error â€” ignorar
                    pass
            
            stdout_thread = threading.Thread(target=read_output, args=(process.stdout, False), daemon=True)
            stderr_thread = threading.Thread(target=read_output, args=(process.stderr, True), daemon=True)
            stdout_thread.start()
            stderr_thread.start()
            
            # Esperar a que termine el proceso o sea cancelado
            # Usar polling para poder cancelar
            while process.poll() is None:
                if self._cancelled:
                    print("ğŸ›‘ å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸­...")
                    self.console_output.emit("ğŸ›‘ å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸­...")
                    try:
                        process.terminate()  # Intentar terminar suavemente
                        # Esperar un poco para que termine (polling)
                        for _ in range(20):  # Esperar hasta 2 segundos (20 * 0.1)
                            if process.poll() is not None:
                                break
                            time.sleep(0.1)
                        
                        # Si aÃºn no terminÃ³, forzar kill
                        if process.poll() is None:
                            print("âš ï¸ ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ã¾ã›ã‚“ã€‚å¼·åˆ¶çµ‚äº†ã—ã¾ã™...")
                            self.console_output.emit("âš ï¸ ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ã¾ã›ã‚“ã€‚å¼·åˆ¶çµ‚äº†ã—ã¾ã™...")
                            process.kill()
                            process.wait()
                    except Exception as e:
                        print(f"âš ï¸ ã‚­ãƒ£ãƒ³ã‚»ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                        try:
                            if process.poll() is None:
                                process.kill()
                                process.wait()
                        except:
                            pass
                    return False
                time.sleep(0.1)  # Wait a bit before checking again
            
            returncode = process.returncode
            
            # ES: Detener los threads de lectura antes de cerrar pipes
            # EN: Stop reader threads before closing pipes
            # JP: ãƒ‘ã‚¤ãƒ—ã‚’é–‰ã˜ã‚‹å‰ã«èª­å–ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢
            stop_reading.set()
            stdout_thread.join(timeout=1.0)  # Esperar mÃ¡ximo 1 segundo
            stderr_thread.join(timeout=1.0)  # Esperar mÃ¡ximo 1 segundo
            
            # ES: Limpiar referencia al proceso
            # EN: Clear process references
            # JP: ãƒ—ãƒ­ã‚»ã‚¹å‚ç…§ã‚’ã‚¯ãƒªã‚¢
            self._current_process = None
            self._stop_reading = None
            
            # ES: Cerrar pipes de forma segura (ya no hay threads leyendo)
            # EN: Close pipes safely (no threads are reading anymore)
            # JP: ãƒ‘ã‚¤ãƒ—ã‚’å®‰å…¨ã«é–‰ã˜ã‚‹ï¼ˆèª­å–ã‚¹ãƒ¬ãƒƒãƒ‰ã¯åœæ­¢æ¸ˆã¿ï¼‰
            try:
                if process.stdout:
                    process.stdout.close()
                if process.stderr:
                    process.stderr.close()
            except:
                pass
            
            if returncode == 0:
                self.console_output.emit(f"âœ… Pipeline ejecutado exitosamente")
                return True
            else:
                self.console_output.emit(f"âŒ Pipeline fallÃ³ con cÃ³digo {returncode}")
                # ES: Intentar leer cualquier salida restante de stderr para ver el error
                # EN: Try to read any remaining stderr output to see the error
                # JP: ã‚¨ãƒ©ãƒ¼ç¢ºèªã®ãŸã‚stderrã®æ®‹ã‚Šå‡ºåŠ›ã‚’èª­ã‚“ã§ã¿ã‚‹
                try:
                    if process.stderr:
                        remaining_stderr = process.stderr.read()
                        if remaining_stderr:
                            for line in remaining_stderr.split('\n'):
                                line_clean = line.rstrip('\n\r')
                                if line_clean:
                                    self.console_output.emit(f"[STDERR] {line_clean}")
                except:
                    pass
                return False
                
        except Exception as e:
            import traceback
            error_msg = f"âŒ Error ejecutando pipeline: {str(e)}\n{traceback.format_exc()}"
            self.console_output.emit(error_msg)
            return False
    
    def _parse_progress(self, line):
        """
        Parsea el output del pipeline para extraer informaciÃ³n de progreso
        y actualizar la barra de progreso con informaciÃ³n detallada
        """
        try:
            # ES: Detectar modelo comparaciÃ³n
            # EN: Detect model comparison
            # JP: ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚’æ¤œå‡º
            if 'ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒè©•ä¾¡' in line or 'ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ' in line:
                self.current_task = 'model_comparison'
                self.progress_updated.emit(5, "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒä¸­...")
                return
            
            if 'é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«' in line or 'æœ€é©ãƒ¢ãƒ‡ãƒ«' in line:
                self.model_comparison_completed = True
                self.progress_updated.emit(10, "ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Œäº†")
                return
            
            # Detectar multi-objective optimization
            if '[Step 1]' in line and 'å¤šç›®çš„æœ€é©åŒ–' in line:
                self.current_task = 'multiobjective'
                self.progress_updated.emit(15, "å¤šç›®çš„æœ€é©åŒ–ä¸­...")
                return
            
            if 'æœ€é©Î±å€¤ç™ºè¦‹' in line or 'å¤šç›®çš„æœ€é©åŒ–' in line and 'å®Œäº†' in line:
                self.multiobjective_completed = True
                self.progress_updated.emit(20, "å¤šç›®çš„æœ€é©åŒ–å®Œäº†")
                return
            
            # Detectar DCVå­¦ç¿’é–‹å§‹
            if '[Step 2]' in line and 'æœ¬å­¦ç¿’' in line:
                self.current_task = 'dcv'
                self.dcv_training = True
                self.progress_updated.emit(25, "DCVå­¦ç¿’é–‹å§‹...")
                return
            
            # Detectar Outer Fold (patrÃ³n: "--- Outer Fold X/Y ---" o similar)
            fold_match = re.search(r'Outer\s+Fold\s+(\d+)/(\d+)', line, re.IGNORECASE)
            if not fold_match:
                fold_match = re.search(r'å¤–å´.*?(\d+)/(\d+)', line)
            if fold_match:
                self.current_fold = int(fold_match.group(1))
                self.total_folds = int(fold_match.group(2))
                # Calcular progreso: 25% (inicio DCV) + (fold/total_folds) * 50% (DCV)
                progress = 25 + int((self.current_fold / self.total_folds) * 50)
                self.progress_updated.emit(progress, f"DCVå­¦ç¿’ä¸­... Fold {self.current_fold}/{self.total_folds}")
                return
            
            # Detectar Inner Fold
            inner_fold_match = re.search(r'Inner\s+Fold\s+(\d+)/(\d+)', line, re.IGNORECASE)
            if inner_fold_match:
                inner_fold = int(inner_fold_match.group(1))
                inner_total = int(inner_fold_match.group(2))
                # Progreso mÃ¡s detallado dentro del fold actual
                fold_progress = 25 + int((self.current_fold / self.total_folds) * 50)
                inner_progress = int((inner_fold / inner_total) * 5)  # 5% por fold interno
                total_progress = fold_progress + inner_progress
                self.progress_updated.emit(total_progress, f"DCVå­¦ç¿’ä¸­... Outer {self.current_fold}/{self.total_folds}, Inner {inner_fold}/{inner_total}")
                return
            
            # Detectar Trial de Optuna
            trial_match = re.search(r'Trial\s+(\d+)', line, re.IGNORECASE)
            if trial_match:
                self.current_trial = int(trial_match.group(1))
                # Actualizar progreso basado en trial
                if self.total_trials > 0:
                    trial_progress = int((self.current_trial / self.total_trials) * 5)  # 5% por trial
                    fold_progress = 25 + int((self.current_fold / self.total_folds) * 50)
                    total_progress = min(75, fold_progress + trial_progress)
                    self.progress_updated.emit(total_progress, f"DCVå­¦ç¿’ä¸­... Fold {self.current_fold}/{self.total_folds}, Trial {self.current_trial}/{self.total_trials}")
                return
            
            # Detectar aprendizaje completado
            if 'å­¦ç¿’å®Œäº†' in line or 'å­¦ç¿’ãŒå®Œäº†' in line:
                self.dcv_training = False
                self.current_task = 'prediction'
                self.progress_updated.emit(75, "å­¦ç¿’å®Œäº†ã€äºˆæ¸¬æº–å‚™ä¸­...")
                return
            
            # ES: Detectar predicciÃ³n
            # EN: Detect prediction
            # JP: äºˆæ¸¬ã‚’æ¤œå‡º
            if 'äºˆæ¸¬å®Ÿè¡Œ' in line or 'äºˆæ¸¬å‡¦ç†é–‹å§‹' in line or 'predict' in line.lower():
                self.current_task = 'prediction'
                self.progress_updated.emit(80, "äºˆæ¸¬å®Ÿè¡Œä¸­...")
                return
            
            if 'äºˆæ¸¬å‡¦ç†å®Œäº†' in line or 'äºˆæ¸¬å®Œäº†' in line:
                self.prediction_completed = True
                self.progress_updated.emit(85, "äºˆæ¸¬å®Œäº†")
                return
            
            # Detectar OOFäºˆæ¸¬åˆ†æ
            if '[OOFäºˆæ¸¬åˆ†æ]' in line or 'OOFäºˆæ¸¬' in line:
                self.current_task = 'evaluation'
                self.progress_updated.emit(86, "OOFäºˆæ¸¬åˆ†æä¸­...")
                return
            
            # Detectar evaluaciÃ³n final
            if '[æœ€çµ‚ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡]' in line or 'å›ºå®šHPè©•ä¾¡' in line or 'è©•ä¾¡ä¸­' in line:
                self.current_task = 'evaluation'
                self.progress_updated.emit(88, "æœ€çµ‚è©•ä¾¡ä¸­...")
                return
            
            # ES: Detectar anÃ¡lisis de caracterÃ­sticas
            # EN: Detect feature analysis
            # JP: ç‰¹å¾´é‡è§£æã‚’æ¤œå‡º
            if '[ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ]' in line or 'ç‰¹å¾´é‡é‡è¦åº¦' in line:
                self.progress_updated.emit(92, "ç‰¹å¾´é‡é‡è¦åº¦åˆ†æä¸­...")
                return
            
            # Detectar diagnÃ³stico
            if 'è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ' in line or 'diagnostic' in line.lower():
                self.progress_updated.emit(95, "è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
                return
            
            # Detectar finalizaciÃ³n
            if 'ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ' in line or 'å‡¦ç†å®Œäº†' in line or 'å®Œäº†ã—ã¾ã—ãŸ' in line:
                self.evaluation_completed = True
                self.progress_updated.emit(98, "å‡¦ç†å®Œäº†...")
                return
            
        except Exception as e:
            # ES: Si hay error en el parsing, no hacer nada (no es crÃ­tico)
            # EN: If parsing fails, do nothing (not critical)
            # JP: ãƒ‘ãƒ¼ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‚ä½•ã‚‚ã—ãªã„ï¼ˆè‡´å‘½çš„ã§ã¯ãªã„ï¼‰
            pass
    
    def _find_results(self):
        """Busca los resultados generados por el pipeline"""
        results = {
            'result_folders': [],
            'graph_paths': [],
            'model_files': [],
            'evaluation_files': []
        }
        
        # ES: El pipeline crea una carpeta con timestamp
        # EN: The pipeline creates a timestamped folder
        # JP: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã™ã‚‹
        # ES: Buscar en el directorio de trabajo
        # EN: Search in the working directory
        # JP: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã§æ¤œç´¢ã™ã‚‹
        if not os.path.exists(self.output_folder):
            return results
        
        # ES: Buscar carpetas de resultados
        # EN: Search for result folders
        # JP: çµæœãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
        for item in os.listdir(self.output_folder):
            item_path = os.path.join(self.output_folder, item)
            if os.path.isdir(item_path):
                # ES: Verificar si es una carpeta de resultados del pipeline
                # EN: Check whether this is a pipeline results folder
                # JP: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµæœãƒ•ã‚©ãƒ«ãƒ€ã‹ç¢ºèªã™ã‚‹
                if "åˆ†é¡è§£æçµæœ" in item or "åˆ†é¡" in item:
                    results['result_folders'].append(item_path)
        
        # ES: Buscar archivos de grÃ¡ficos
        # EN: Search for chart files
        # JP: ã‚°ãƒ©ãƒ•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        for root, dirs, files in os.walk(self.output_folder):
            for file in files:
                if file.endswith(('.png', '.jpg', '.jpeg')):
                    results['graph_paths'].append(os.path.join(root, file))
                elif file.endswith('.pkl'):
                    results['model_files'].append(os.path.join(root, file))
                elif file.endswith(('.xlsx', '.csv', '.json')):
                    if 'evaluation' in file.lower() or 'è©•ä¾¡' in file:
                        results['evaluation_files'].append(os.path.join(root, file))
        
        return results

