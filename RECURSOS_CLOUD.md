# Requisitos de Recursos para Ejecuci√≥n en la Nube

## An√°lisis de la Aplicaci√≥n

Esta aplicaci√≥n Python es un sistema de an√°lisis de regresi√≥n con interfaz gr√°fica (PySide6) que incluye:
- An√°lisis lineal y no lineal
- Modelos de Machine Learning (LightGBM, Random Forest, XGBoost)
- Optimizaci√≥n de hiperpar√°metros con Optuna
- Cross-Validation doble (Outer + Inner splits)
- An√°lisis SHAP para importancia de caracter√≠sticas
- Generaci√≥n de gr√°ficos y visualizaciones

---

## üìä Estimaci√≥n de Recursos

### **Memoria RAM (Recomendada)**

#### **M√≠nimo:**
- **4 GB RAM** - Para ejecuciones b√°sicas con datos peque√±os (< 10,000 filas)
- Solo an√°lisis lineal
- Sin an√°lisis SHAP detallado

#### **Recomendado:**
- **8-16 GB RAM** - Para uso normal con configuraci√≥n por defecto
  - 50 trials de Optuna
  - 10 outer splits + 10 inner splits
  - 2 modelos (Random Forest + LightGBM)
  - 3 targets (variables objetivo)
  - An√°lisis SHAP b√°sico

#### **√ìptimo:**
- **16-32 GB RAM** - Para an√°lisis completos y datos grandes
  - M√∫ltiples modelos simult√°neos
  - An√°lisis SHAP detallado
  - Datos con > 50,000 filas
  - M√∫ltiples proyectos en paralelo

#### **Desglose de Uso de Memoria:**
- **Aplicaci√≥n base (PySide6 GUI)**: ~200-500 MB
- **Librer√≠as (NumPy, Pandas, Scikit-learn)**: ~300-500 MB
- **Modelos ML en memoria**: ~100-500 MB por modelo
- **Datos en memoria**: ~50-200 MB por 10,000 filas (depende de columnas)
- **Optuna (50 trials)**: ~500 MB - 1 GB (acumula historial)
- **Cross-Validation**: ~1-2 GB (m√∫ltiples folds en memoria)
- **SHAP Analysis**: ~500 MB - 2 GB (depende de SHAP_MAX_SAMPLES)
- **Matplotlib/Seaborn**: ~100-300 MB (gr√°ficos en memoria)

**Total estimado (uso normal)**: 3-6 GB RAM

---

### **CPU (Procesador)**

#### **M√≠nimo:**
- **2 cores** - Funcional pero lento
- Tiempo de ejecuci√≥n: 2-4 horas para an√°lisis completo

#### **Recomendado:**
- **4-8 cores** - Balance entre costo y rendimiento
- Tiempo de ejecuci√≥n: 30 minutos - 2 horas para an√°lisis completo
- Permite paralelizaci√≥n de:
  - Optuna trials (si est√° habilitado)
  - Cross-validation folds
  - Modelos m√∫ltiples

#### **√ìptimo:**
- **8-16 cores** - Para an√°lisis r√°pidos y producci√≥n
- Tiempo de ejecuci√≥n: 10-30 minutos para an√°lisis completo
- Mejor aprovechamiento de:
  - LightGBM (paralelizaci√≥n nativa)
  - Random Forest (n_jobs)
  - NumPy/SciPy (BLAS/LAPACK multi-threaded)

#### **Configuraci√≥n de Paralelizaci√≥n:**
- **LightGBM**: Usa m√∫ltiples threads autom√°ticamente
- **Random Forest**: `n_jobs=-1` usa todos los cores disponibles
- **Optuna**: Puede paralelizar trials si se configura
- **NumPy/SciPy**: Usa OpenMP/BLAS multi-threaded (MKL, OpenBLAS)

**Nota**: La aplicaci√≥n usa `ThreadPoolExecutor` para algunas operaciones, pero la mayor√≠a del procesamiento pesado est√° en las librer√≠as de ML que aprovechan m√∫ltiples cores autom√°ticamente.

---

### **Almacenamiento (Disco)**

#### **M√≠nimo:**
- **5-10 GB** - Para instalaci√≥n y datos b√°sicos

#### **Recomendado:**
- **20-50 GB** - Para proyectos m√∫ltiples y resultados
  - Instalaci√≥n de Python + librer√≠as: ~3-5 GB
  - Datos de entrada: ~100 MB - 1 GB por proyecto
  - Modelos guardados: ~50-200 MB por modelo
  - Resultados y gr√°ficos: ~500 MB - 2 GB por an√°lisis
  - Base de datos SQLite: ~10-100 MB

#### **√ìptimo:**
- **50-100 GB** - Para m√∫ltiples proyectos y backups
  - Historial de an√°lisis
  - Modelos entrenados
  - Visualizaciones de alta resoluci√≥n

---

### **GPU (Opcional)**

- **No requerida** - La aplicaci√≥n no usa GPU actualmente
- Los modelos (LightGBM, Random Forest) pueden usar GPU pero no est√° configurado
- Si se implementa soporte GPU:
  - **NVIDIA GPU con CUDA** (m√≠nimo 4 GB VRAM)
  - Acelerar√≠a LightGBM/XGBoost significativamente

---

## ‚öôÔ∏è Configuraci√≥n Actual (config.py)

Basado en la configuraci√≥n por defecto:

```python
N_TRIALS = 50              # Trials de Optuna
OUTER_SPLITS = 10          # Folds externos
INNER_SPLITS = 10          # Folds internos
MODELS_TO_USE = ['random_forest', 'lightgbm']  # 2 modelos
TARGET_COLUMNS = ['Êë©ËÄóÈáè', '‰∏äÈù¢„ÉÄ„É¨Èáè', 'ÂÅ¥Èù¢„ÉÄ„É¨Èáè']  # 3 targets
SHAP_MAX_SAMPLES = 200     # Muestras para SHAP
```

**C√°lculo de operaciones:**
- Total de entrenamientos: 50 trials √ó 10 outer √ó 10 inner √ó 2 modelos √ó 3 targets = **300,000 entrenamientos** (en el peor caso)
- En pr√°ctica, Optuna optimiza y reduce esto significativamente

---

## ‚òÅÔ∏è Recomendaciones por Proveedor Cloud

### **AWS (EC2 / SageMaker)**
- **M√≠nimo**: `t3.medium` (2 vCPU, 4 GB RAM) - ~$0.04/hora
- **Recomendado**: `t3.xlarge` (4 vCPU, 16 GB RAM) - ~$0.17/hora
- **√ìptimo**: `m5.2xlarge` (8 vCPU, 32 GB RAM) - ~$0.38/hora

### **Google Cloud (Compute Engine)**
- **M√≠nimo**: `e2-medium` (2 vCPU, 4 GB RAM) - ~$0.03/hora
- **Recomendado**: `e2-standard-4` (4 vCPU, 16 GB RAM) - ~$0.13/hora
- **√ìptimo**: `e2-standard-8` (8 vCPU, 32 GB RAM) - ~$0.26/hora

### **Azure (Virtual Machines)**
- **M√≠nimo**: `Standard_B2s` (2 vCPU, 4 GB RAM) - ~$0.04/hora
- **Recomendado**: `Standard_D4s_v3` (4 vCPU, 16 GB RAM) - ~$0.19/hora
- **√ìptimo**: `Standard_D8s_v3` (8 vCPU, 32 GB RAM) - ~$0.38/hora

### **Heroku / Railway / Render**
- **M√≠nimo**: 4 GB RAM - ~$25-50/mes
- **Recomendado**: 8-16 GB RAM - ~$50-100/mes
- **Nota**: Estas plataformas son m√°s caras pero m√°s f√°ciles de desplegar

---

## üîß Optimizaciones para Reducir Recursos

### **Reducir Memoria:**
1. Reducir `N_TRIALS` de 50 a 20-30
2. Reducir `OUTER_SPLITS` / `INNER_SPLITS` de 10 a 5
3. Usar solo 1 modelo en lugar de 2
4. Desactivar SHAP (`SHAP_MODE = 'none'`)
5. Procesar targets secuencialmente en lugar de paralelo

### **Reducir CPU:**
1. Limitar threads: `OMP_NUM_THREADS=2`
2. Usar modelos m√°s simples (Ridge/Lasso en lugar de Random Forest)
3. Reducir n√∫mero de trials

### **Reducir Almacenamiento:**
1. Limpiar modelos antiguos
2. Comprimir resultados
3. Usar almacenamiento externo (S3, GCS) para resultados

---

## üìù Variables de Entorno Recomendadas

Para optimizar el uso de recursos en la nube:

```bash
# Limitar threads de OpenMP
export OMP_NUM_THREADS=4

# Limitar threads de MKL (Intel Math Kernel Library)
export MKL_NUM_THREADS=4

# Limitar threads de OpenBLAS
export OPENBLAS_NUM_THREADS=4

# Backend de matplotlib sin GUI (importante para servidores)
export MPLBACKEND=Agg

# Backend de Qt sin GUI (para PySide6 en servidor)
export QT_QPA_PLATFORM=offscreen
# o
export QT_QPA_PLATFORM=vnc  # Si necesitas GUI remota
```

---

## ‚ö†Ô∏è Consideraciones Importantes

1. **GUI en la Nube**: PySide6 requiere un servidor X o VNC para mostrar la interfaz gr√°fica. Considera:
   - Usar modo headless (sin GUI) si es posible
   - Usar Xvfb para GUI virtual
   - Usar VNC para acceso remoto

2. **Tiempo de Ejecuci√≥n**: Los an√°lisis completos pueden tardar horas. Considera:
   - Usar instancias spot/preemptibles para ahorrar costos
   - Implementar checkpoints para reanudar an√°lisis
   - Usar colas de trabajo (Celery, RQ)

3. **Escalabilidad**: Para m√∫ltiples usuarios/proyectos:
   - Usar contenedores (Docker)
   - Orquestaci√≥n (Kubernetes)
   - Load balancing

4. **Costos**: 
   - An√°lisis completos pueden costar $5-20 por ejecuci√≥n en instancias recomendadas
   - Considera instancias reservadas para uso continuo (hasta 70% descuento)

---

## üìä Resumen Ejecutivo

| Recurso | M√≠nimo | Recomendado | √ìptimo |
|---------|--------|-------------|--------|
| **RAM** | 4 GB | 8-16 GB | 16-32 GB |
| **CPU** | 2 cores | 4-8 cores | 8-16 cores |
| **Disco** | 10 GB | 20-50 GB | 50-100 GB |
| **GPU** | No requerida | No requerida | Opcional (4+ GB VRAM) |
| **Costo/hora** | $0.03-0.04 | $0.13-0.19 | $0.26-0.38 |
| **Tiempo an√°lisis** | 2-4 horas | 30 min - 2 horas | 10-30 min |

**Recomendaci√≥n final**: Comienza con **8 GB RAM y 4 cores** para evaluar el rendimiento real con tus datos, luego ajusta seg√∫n necesidad.



