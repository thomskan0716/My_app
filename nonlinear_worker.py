"""
ES: Worker para ejecutar anÃ¡lisis no lineal en un thread separado.
EN: Worker to run the non-linear analysis in a separate thread.
JA: éç·šå½¢è§£æã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼ã€‚

ES: Ejecuta los scripts 01_model_builder.py, 02_prediction.py, 03_pareto_analyzer.py.
EN: Runs the scripts 01_model_builder.py, 02_prediction.py, 03_pareto_analyzer.py.
JA: 01_model_builder.py / 02_prediction.py / 03_pareto_analyzer.py ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
"""
import sys
import os
import subprocess
import pandas as pd
import json
import time
import threading
import re
from pathlib import Path
from PySide6.QtCore import QThread, Signal
from nonlinear_folder_manager import NonlinearFolderManager


class NonlinearWorker(QThread):
    """ES: Worker que ejecuta el anÃ¡lisis no lineal en un thread separado
    EN: Worker that runs the non-linear analysis in a separate thread
    JA: éç·šå½¢è§£æã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼
    """
    
    # ES: SeÃ±ales para comunicaciÃ³n con la GUI | EN: Signals for GUI communication | JA: GUIé€šä¿¡ç”¨ã‚·ã‚°ãƒŠãƒ«
    progress_updated = Signal(int, str)  # (value, message)
    progress_detailed = Signal(int, int, int, int, int, int, str, bool, bool, bool, int, int)  # (trial_current, trial_total, fold_current, fold_total, pass_current, pass_total, current_task, data_analysis_completed, final_model_training, shap_analysis, model_current, model_total)
    status_updated = Signal(str)  # message
    finished = Signal(dict)  # results dict
    error = Signal(str)  # error message
    console_output = Signal(str)  # console output (for IDE/terminal)
    
    def __init__(self, filtered_df, project_folder, parent=None, config_values=None):
        """
        ES: Inicializa el worker.
        EN: Initialize the worker.
        JA: ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚
        
        Parameters
        ----------
        filtered_df : pd.DataFrame
            ES: DataFrame con los datos filtrados
            EN: DataFrame containing filtered data
            JA: ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        project_folder : str
            ES: Carpeta base del proyecto
            EN: Project base folder
            JA: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ™ãƒ¼ã‚¹ãƒ•ã‚©ãƒ«ãƒ€
        parent : QWidget, optional
            ES: Widget padre
            EN: Parent widget
            JA: è¦ªã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        config_values : dict, optional
            ES: Valores de configuraciÃ³n del diÃ¡logo
            EN: Configuration values from the dialog
            JA: ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‹ã‚‰ã®è¨­å®šå€¤
        """
        super().__init__(parent)
        self.filtered_df = filtered_df
        self.project_folder = project_folder
        self.config_values = config_values or {}
        self.output_folder = None
        self.current_stage = None
        self._json_reader_stop = threading.Event()  # Stop flag for the JSON reader
        self._cancelled = False  # Cancel flag
        self._current_process = None  # Current subprocess reference
        self._stop_reading = None  # Stop flag for output reading
        self._cached_script_base_dir = None  # Cache script_base_dir to avoid repeated checks
        self._cached_python_code_folder = None  # Cache python_code_folder
        
        # ES: Estado del progreso para parsing | EN: Parsing progress state | JA: ãƒ‘ãƒ¼ã‚¹é€²æ—çŠ¶æ…‹
        self.current_fold = 0
        self.total_folds = self.config_values.get('outer_splits', self.config_values.get('OUTER_SPLITS', 10))
        self.current_trial = 0  # Completed-trial counter in current fold (incremental: 1, 2, 3...)
        # ES: Normalizar nombre: puede venir como 'n_trials' o 'N_TRIALS' | EN: Normalize key name: it may be 'n_trials' or 'N_TRIALS' | JA: ã‚­ãƒ¼åã‚’æ­£è¦åŒ–ï¼ˆn_trials / N_TRIALS ã®å¯èƒ½æ€§ï¼‰
        self.total_trials = self.config_values.get('N_TRIALS', self.config_values.get('n_trials', 50))
        self.current_model = 0
        self.total_models = len(self.config_values.get('MODELS_TO_USE', ['random_forest', 'lightgbm']))
        self.current_pass = 0  # Current pass (current target)
        self.total_passes = len(self.config_values.get('TARGET_COLUMNS', []))  # Total passes (targets)
        # ES: Si no hay TARGET_COLUMNS en config, usar un valor por defecto (normalmente 3) | EN: If TARGET_COLUMNS is missing, use a default (usually 3) | JA: TARGET_COLUMNS ãŒç„¡ã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆé€šå¸¸3ï¼‰ã‚’ä½¿ç”¨
        if self.total_passes == 0:
            self.total_passes = 3  # Default value
        self.last_detected_target = None  # Avoid detecting the same target twice
        
        # ES: âœ… Variables para progreso acumulado (para cÃ¡lculo lineal de porcentaje) | EN: âœ… Accumulated progress variables (for linear percent computation) | JA: âœ… ç´¯ç©é€²æ—å¤‰æ•°ï¼ˆå‰²åˆã‚’ç·šå½¢è¨ˆç®—ã™ã‚‹ãŸã‚ï¼‰
        self.accumulated_trial_current = 0  # Total accumulated completed trials (across passes/folds/models)
        self.accumulated_trial_total = 0  # Total accumulated trials (passes * folds * trials_per_fold * models)
        
        # ES: âœ… Set para rastrear quÃ© trials ya fueron contados (evitar contar el mismo trial dos veces)
        # EN: âœ… Set to track which trials were already counted (avoid double-counting)
        # JA: âœ… æ—¢ã«ã‚«ã‚¦ãƒ³ãƒˆæ¸ˆã¿trialã‚’è¿½è·¡ï¼ˆé‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆé˜²æ­¢ï¼‰
        self.completed_trials_in_current_fold = set()  # IDs of trials completed in the current fold
        
        # ES: Estados adicionales para tareas dentro de 01_model_builder
        # EN: Additional state for tasks inside 01_model_builder
        # JA: 01_model_builder å†…ã‚¿ã‚¹ã‚¯ç”¨ã®è¿½åŠ çŠ¶æ…‹
        self.data_analysis_completed = False  # Data analysis completed
        self.current_task = 'initialization'  # Current task: initialization, data_analysis, dcv, final_model, shap, saving
        self.final_model_training = False  # Final model training
        self.shap_analysis = False  # SHAP analysis
        self.saving_completed = False  # Saving completed
        
    def run(self):
        """ES: Ejecuta el anÃ¡lisis no lineal
        EN: Run the non-linear analysis
        JA: éç·šå½¢è§£æã‚’å®Ÿè¡Œ
        """
        import time
        start_time = time.time()  # Record start time
        self.analysis_start_time = start_time
        
        try:
            # ES: Verificar si es carga de carpeta existente | EN: Check if loading an existing folder | JA: æ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€èª­ã¿è¾¼ã¿ã‹ç¢ºèª
            load_existing = self.config_values.get('load_existing', False)
            selected_folder_path = self.config_values.get('selected_folder_path', '')
            
            if load_existing and selected_folder_path:
                # ES: Cargar carpeta existente sin ejecutar anÃ¡lisis | EN: Load existing folder without running analysis | JA: è§£æã›ãšæ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’èª­ã¿è¾¼ã¿
                self.status_updated.emit("ğŸ“ æ—¢å­˜çµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")
                self.progress_updated.emit(50, "æ—¢å­˜çµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")
                
                # ES: Usar la carpeta seleccionada como output_folder | EN: Use selected folder as output_folder | JA: é¸æŠãƒ•ã‚©ãƒ«ãƒ€ã‚’ output_folder ã«è¨­å®š
                self.output_folder = selected_folder_path
                
                # ES: Buscar grÃ¡ficos generados | EN: Find generated graphs | JA: ç”Ÿæˆã‚°ãƒ©ãƒ•ã‚’æ¢ç´¢
                graph_paths = self._find_graphs(self.output_folder)
                
                # ES: Buscar carpeta de resultados para obtener subfolders | EN: Locate results folder to collect subfolders | JA: ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å–å¾—ã®ãŸã‚çµæœãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ç´¢
                result_folder = os.path.join(self.output_folder, '03_å­¦ç¿’çµæœ')
                subfolders = {}
                if os.path.exists(result_folder):
                    subfolders['03_å­¦ç¿’çµæœ'] = result_folder
                
                # ES: Emitir resultados como carga existente | EN: Emit results as an existing-load run | JA: æ—¢å­˜èª­ã¿è¾¼ã¿ã¨ã—ã¦çµæœã‚’é€ä¿¡
                results_existing = {
                    'stage': 'completed',
                    'output_folder': self.output_folder,
                    'graph_paths': graph_paths,
                    'subfolders': subfolders,
                    'all_stages_completed': False,  # Puede que no tenga stages 2 y 3
                    'load_existing': True,
                    'existing_folder_path': selected_folder_path
                }
                
                self.progress_updated.emit(100, "æ—¢å­˜çµæœèª­ã¿è¾¼ã¿å®Œäº†")
                self.status_updated.emit("âœ… æ—¢å­˜çµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                
                # ES: Emitir finished para que la GUI muestre los resultados existentes | EN: Emit finished so the GUI can show existing results | JA: GUIè¡¨ç¤ºã®ãŸã‚ finished ã‚’é€ä¿¡
                self.finished.emit(results_existing)
                return
            
            # ES: Si no es carga existente, ejecutar anÃ¡lisis normal | EN: If not loading existing, run normal analysis | JA: æ—¢å­˜èª­ã¿è¾¼ã¿ã§ãªã‘ã‚Œã°é€šå¸¸è§£æã‚’å®Ÿè¡Œ
            # ES: Crear carpeta de salida | EN: Create output folder | JA: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
            self.status_updated.emit("ğŸ“ Creando carpeta de salida...")
            
            # ES: Verificar cancelaciÃ³n antes de crear carpetas | EN: Check cancellation before creating folders | JA: ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆå‰ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ä½œæˆå‰ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            folder_manager = NonlinearFolderManager(self.project_folder)
            self.output_folder = folder_manager.create_output_folder()
            subfolders = folder_manager.create_subfolder_structure(self.output_folder)
            
            # ES: Verificar cancelaciÃ³n despuÃ©s de crear carpetas | EN: Check cancellation after creating folders | JA: ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆå¾Œã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ä½œæˆå¾Œã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            # ES: Guardar datos filtrados | EN: Save filtered data | JA: ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            self.status_updated.emit("ğŸ’¾ Guardando datos filtrados...")
            data_folder = os.path.join(self.output_folder, "01_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
            os.makedirs(data_folder, exist_ok=True)
            
            input_file = os.path.join(data_folder, "filtered_data.xlsx")
            df_to_save = self.filtered_df.copy()
            # ES: Mantener el comportamiento actual de guardado de filtered_data.xlsx
            # EN: Keep the current behavior for saving filtered_data.xlsx
            # JA: filtered_data.xlsx ã®ä¿å­˜æŒ™å‹•ã¯ç¾çŠ¶ç¶­æŒ
            df_to_save.to_excel(input_file, index=False)
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {input_file}")

            # ES: Crear un segundo archivo para el anÃ¡lisis del modelo: analysis_df.xlsx | EN: Create a second file for model analysis: analysis_df.xlsx | JA: ãƒ¢ãƒ‡ãƒ«è§£æç”¨ã« analysis_df.xlsx ã‚’ä½œæˆ
            # ES: A partir de filtered_data, eliminar columnas no deseadas como 'ææ–™' y 'å®Ÿé¨“æ—¥' | EN: From filtered_data, drop unwanted columns like 'ææ–™' and 'å®Ÿé¨“æ—¥' | JA: filtered_data ã‹ã‚‰ä¸è¦åˆ—ï¼ˆææ–™/å®Ÿé¨“æ—¥ãªã©ï¼‰ã‚’å‰Šé™¤
            analysis_df = df_to_save.copy()
            cols_to_drop = ['ææ–™', 'å®Ÿé¨“æ—¥']
            try:
                drop_cols = [c for c in cols_to_drop if c in analysis_df.columns]
                if drop_cols:
                    analysis_df = analysis_df.drop(columns=drop_cols)
                    print(f"â„¹ï¸ analysis_df.xlsx ã§å‰Šé™¤ã—ãŸåˆ—: {drop_cols}")
                # ES: Forzar que columnas enteras no sean int64 al leerlas en Stage 01 | EN: Force integer cols to be read as float64 in Stage 01 | JA: Stage01ã§intåˆ—ãŒfloat64ã¨ã—ã¦èª­ã¾ã‚Œã‚‹ã‚ˆã†ã«èª¿æ•´
                # ES: Convertir columnas int a float para que pd.read_excel las infiera como float64 | EN: Convert int columns to float so pd.read_excel infers float64 | JA: intåˆ—ã‚’floatã¸å¤‰æ›ã— pd.read_excel ã®æ¨è«–ã‚’float64ã«ã™ã‚‹
                int_cols_analysis = analysis_df.select_dtypes(include=["int64", "int32", "int"]).columns
                if len(int_cols_analysis) > 0:
                    analysis_df[int_cols_analysis] = analysis_df[int_cols_analysis].astype("float64")
                    print(f"â„¹ï¸ analysis_df.xlsx ã®æ•´æ•°åˆ—ã‚’ float ã«å¤‰æ›ã—ã¾ã—ãŸ: {list(int_cols_analysis)}")
            except Exception as e:
                print(f"âš ï¸ analysis_df.xlsx ã®åˆ—æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

            analysis_file = os.path.join(data_folder, "analysis_df.xlsx")
            analysis_df.to_excel(analysis_file, index=False)
            print(f"âœ… è§£æç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {analysis_file}")
            
            # ES: Verificar cancelaciÃ³n despuÃ©s de guardar datos | EN: Check cancellation after saving data | JA: ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¾Œã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¾Œã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            # ES: Guardar configuraciÃ³n personalizada directamente como config.py | EN: Save custom config directly as config.py | JA: ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’ config.py ã¨ã—ã¦ä¿å­˜
            # ES: (En esta carpeta solo existirÃ¡ este config.py, modificado) | EN: (Only this modified config.py will exist in this folder) | JA: ï¼ˆã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯å¤‰æ›´æ¸ˆã¿ã® config.py ã®ã¿ç½®ãï¼‰
            config_file = os.path.join(self.output_folder, "config.py")
            self._save_config_file(config_file)
            
            # ES: Verificar cancelaciÃ³n despuÃ©s de guardar configuraciÃ³n | EN: Check cancellation after saving config | JA: è¨­å®šä¿å­˜å¾Œã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ è¨­å®šä¿å­˜å¾Œã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            # ES: Copiar scripts necesarios a la carpeta de salida | EN: Copy required scripts to the output folder | JA: å¿…è¦ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã¸ã‚³ãƒ”ãƒ¼
            self.status_updated.emit("ğŸ“‹ Copiando scripts...")
            # ES: Ya no copiamos el config.py genÃ©rico; usamos el config.py generado arriba | EN: We no longer copy the generic config.py; we use the generated one above | JA: æ±ç”¨config.pyã¯ã‚³ãƒ”ãƒ¼ã›ãšã€ä¸Šã§ç”Ÿæˆã—ãŸconfig.pyã‚’ä½¿ç”¨
            scripts_to_copy = ["01_model_builder.py", "02_prediction.py", "03_pareto_analyzer.py"]
            
            # ES: âœ… Buscar scripts en el directorio donde estÃ¡ 0sec.py (directorio del proyecto) | EN: âœ… Locate scripts in the directory containing 0sec.py | JA: âœ… 0sec.py ãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ¢ç´¢
            # ES: project_folder es la carpeta base, pero los scripts estÃ¡n en el directorio padre | EN: project_folder is the project base; scripts live in the parent directory | JA: project_folder ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç‚¹ã ãŒã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            script_base_dir = None
            if self.project_folder:
                # ES: project_folder es algo como "Archivos_de_salida/Proyecto_79"
                # EN: project_folder looks like "Archivos_de_salida/Proyecto_79"
                # JA: project_folder ã¯ä¾‹ï¼š"Archivos_de_salida/Proyecto_79"
                # ES: Los scripts estÃ¡n en el directorio padre (donde estÃ¡ 0sec.py)
                # EN: Scripts live in the parent directory (where 0sec.py is)
                # JA: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆ0sec.py ãŒã‚ã‚‹å ´æ‰€ï¼‰ã«ã‚ã‚‹
                potential_base = Path(self.project_folder).parent.parent
                if (potential_base / "0sec.py").exists():
                    script_base_dir = potential_base
                else:
                    # ES: Intentar buscar desde el directorio actual
                    # EN: Try searching from the current directory
                    # JP: ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¢ã™
                    current_dir = Path.cwd()
                    if (current_dir / "0sec.py").exists():
                        script_base_dir = current_dir
                    elif (current_dir / "01_model_builder.py").exists():
                        script_base_dir = current_dir
            
            if script_base_dir is None:
                script_base_dir = Path.cwd()  # Fallback al directorio actual
            
            for script in scripts_to_copy:
                # ES: Verificar cancelaciÃ³n durante copia de scripts
                # EN: Check cancellation during script copy
                # JP: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚³ãƒ”ãƒ¼ä¸­ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’ç¢ºèª
                if self._cancelled:
                    print("ğŸ›‘ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚³ãƒ”ãƒ¼ä¸­ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                    return
                
                script_path = script_base_dir / script
                if script_path.exists():
                    import shutil
                    dest = os.path.join(self.output_folder, script)
                    shutil.copy2(str(script_path), dest)
                    print(f"âœ… ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ: {script_path} â†’ {dest}")
                else:
                    print(f"âš ï¸ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {script_path}")
            
            # ES: Verificar cancelaciÃ³n antes de ejecutar Stage 01
            # EN: Check cancellation before running Stage 01
            # JP: Stage 01å®Ÿè¡Œå‰ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ Stage 01 å®Ÿè¡Œå‰ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            # Ejecutar Stage 01: Model Builder
            self.current_stage = '01_model_builder'
            self.status_updated.emit("ğŸ”§ ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...")
            self.progress_updated.emit(10, "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...")
            
            # ES: Verificar cancelaciÃ³n antes de ejecutar
            # EN: Check cancellation before running
            # JP: å®Ÿè¡Œå‰ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ Stage 01 å®Ÿè¡Œå‰ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            success_01 = self._run_script("01_model_builder.py", self.output_folder)
            
            # Si fue cancelado, no emitir error
            if self._cancelled:
                print("ğŸ›‘ Stage 01 å®Ÿè¡Œä¸­ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            if not success_01:
                self.error.emit("âŒ Error en Stage 01: Model Builder")
                return
            
            # ES: Calcular tiempo total de anÃ¡lisis
            # EN: Compute total analysis time
            # JP: è§£æã®ç·æ™‚é–“ã‚’è¨ˆç®—
            end_time = time.time()
            analysis_duration = end_time - start_time
            self.analysis_duration = analysis_duration
            
            # ES: Guardar resultados en JSON antes de mostrar la pantalla de resumen
            # EN: Save results to JSON before showing the summary screen
            # JP: ã‚µãƒãƒªãƒ¼ç”»é¢è¡¨ç¤ºå‰ã«çµæœã‚’JSONã«ä¿å­˜
            self._save_analysis_results_json()
            
            # ES: Buscar grÃ¡ficos generados (para referencia, pero no se mostrarÃ¡n)
            # EN: Find generated charts (for reference, but they won't be shown)
            # JP: ç”Ÿæˆã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã‚’æ¢ã™ï¼ˆå‚ç…§ç”¨ã€è¡¨ç¤ºã¯ã—ãªã„ï¼‰
            graph_paths = self._find_graphs(self.output_folder)
            
            # Emitir resultados del Stage 01 como 'completed' para ir directamente a la pantalla de resumen
            results_01 = {
                'stage': 'completed',  # Cambiar a 'completed' para que vaya directamente a _show_final_results
                'output_folder': self.output_folder,
                'graph_paths': graph_paths,
                'subfolders': subfolders,
                'all_stages_completed': False,  # Indicar que solo se completÃ³ el stage 01
                'load_existing': False  # Not an existing-load; it's a new analysis
            }
            
            self.progress_updated.emit(100, "Stage 01 å®Œäº†")
            self.status_updated.emit("âœ… Stage 01 å®Œäº†ã€‚çµæœã‚’è¡¨ç¤ºã—ã¾ã™...")
            
            # Emitir finished para que la GUI muestre directamente la pantalla de resumen
            self.finished.emit(results_01)
            
        except Exception as e:
            import traceback
            error_msg = f"âŒ éç·šå½¢è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}"
            print(error_msg)
            self.error.emit(error_msg)
    
    def run_stage2_and_3(self):
        """
        ContinÃºa con los stages 02 y 03 despuÃ©s de que el usuario confirme
        Este mÃ©todo se llama desde la GUI cuando el usuario hace OK en el visor de grÃ¡ficos
        """
        print("ğŸ” ãƒ‡ãƒãƒƒã‚° run_stage2_and_3: ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—", flush=True)
        print(f"ğŸ” DEBUG run_stage2_and_3: output_folder = {self.output_folder}", flush=True)
        try:
            # ES: Verificar cancelaciÃ³n antes de continuar
            # EN: Check cancellation before continuing
            # JP: ç¶šè¡Œå‰ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ Stage 02 å®Ÿè¡Œå‰ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            # Ejecutar Stage 02: Prediction
            self.current_stage = '02_prediction'
            self.status_updated.emit("ğŸ”§ Ejecutando Stage 02: Prediction...")
            self.progress_updated.emit(60, "Stage 02: Prediction")
            
            success_02 = self._run_script("02_prediction.py", self.output_folder)
            print(f"ğŸ” DEBUG run_stage2_and_3: success_02 = {success_02}")
            
            # Si fue cancelado, no emitir error
            if self._cancelled:
                print("ğŸ›‘ Stage 02 å®Ÿè¡Œä¸­ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            if not success_02:
                print("ğŸ” ãƒ‡ãƒãƒƒã‚° run_stage2_and_3: Stage 02 ã«å¤±æ•—ã€‚error ã‚’é€ä¿¡ã—ã¾ã™")
                self.error.emit("âŒ Error en Stage 02: Prediction")
                return
            
            # ES: Verificar cancelaciÃ³n antes de Stage 03
            # EN: Check cancellation before Stage 03
            # JP: Stage 03å‰ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’ç¢ºèª
            if self._cancelled:
                print("ğŸ›‘ Stage 03 å®Ÿè¡Œå‰ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            # Ejecutar Stage 03: Pareto Analyzer
            self.current_stage = '03_pareto_analyzer'
            self.status_updated.emit("ğŸ”§ Ejecutando Stage 03: Pareto Analyzer...")
            self.progress_updated.emit(90, "Stage 03: Pareto Analyzer")
            
            success_03 = self._run_script("03_pareto_analyzer.py", self.output_folder)
            print(f"ğŸ” DEBUG run_stage2_and_3: success_03 = {success_03}")
            
            # Si fue cancelado, no emitir error
            if self._cancelled:
                print("ğŸ›‘ Stage 03 å®Ÿè¡Œä¸­ã«è§£æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                return
            
            if not success_03:
                print("ğŸ” ãƒ‡ãƒãƒƒã‚° run_stage2_and_3: Stage 03 ã«å¤±æ•—ã€‚error ã‚’é€ä¿¡ã—ã¾ã™")
                self.error.emit("âŒ Error en Stage 03: Pareto Analyzer")
                return
            
            # ES: AnÃ¡lisis completado | EN: Analysis completed | JA: è§£æå®Œäº†
            self.progress_updated.emit(100, "AnÃ¡lisis completado")
            self.status_updated.emit("âœ… AnÃ¡lisis no lineal completado exitosamente")
            
            # ES: Guardar datos de resultados en JSON
            # EN: Save results data to JSON
            # JP: çµæœãƒ‡ãƒ¼ã‚¿ã‚’JSONã«ä¿å­˜
            self._save_analysis_results_json()
            
            # ES: Buscar grÃ¡ficos de Pareto
            # EN: Find Pareto charts
            # JP: ãƒ‘ãƒ¬ãƒ¼ãƒˆã®ã‚°ãƒ©ãƒ•ã‚’æ¢ã™
            pareto_plots_folder = os.path.join(self.output_folder, "05_ãƒ‘ãƒ¬ãƒ¼ãƒˆè§£", "pareto_plots")
            prediction_output_file = os.path.join(self.output_folder, "04_äºˆæ¸¬", "Prediction_output.xlsx")
            
            # ES: DEBUG: Verificar rutas
            # EN: DEBUG: Check paths
            # JP: DEBUG: ãƒ‘ã‚¹ã‚’ç¢ºèª
            print(f"ğŸ” DEBUG nonlinear_worker: output_folder = {self.output_folder}", flush=True)
            print(f"ğŸ” DEBUG nonlinear_worker: pareto_plots_folder = {pareto_plots_folder}", flush=True)
            print(f"ğŸ” DEBUG nonlinear_worker: prediction_output_file = {prediction_output_file}", flush=True)
            print(f"ğŸ” DEBUG nonlinear_worker: pareto_plots_folder exists = {os.path.exists(pareto_plots_folder)}", flush=True)
            print(f"ğŸ” DEBUG nonlinear_worker: prediction_output_file exists = {os.path.exists(prediction_output_file)}", flush=True)
            
            # ES: Verificar si existen archivos en la carpeta de grÃ¡ficos
            # EN: Check whether there are files in the charts folder
            # JP: ã‚°ãƒ©ãƒ•ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª
            if os.path.exists(pareto_plots_folder):
                graph_files = [f for f in os.listdir(pareto_plots_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]
                print(f"ğŸ” ãƒ‡ãƒãƒƒã‚° nonlinear_worker: æ¤œå‡ºã—ãŸã‚°ãƒ©ãƒ•æ•° = {len(graph_files)}", flush=True)
                if graph_files:
                    print(f"ğŸ” ãƒ‡ãƒãƒƒã‚° nonlinear_worker: å…ˆé ­ã®ã‚°ãƒ©ãƒ• = {graph_files[:3]}", flush=True)
            
            results_final = {
                'stage': 'completed',
                'output_folder': self.output_folder,
                'all_stages_completed': True,
                'pareto_plots_folder': pareto_plots_folder,
                'prediction_output_file': prediction_output_file
            }
            
            print("ğŸ” ãƒ‡ãƒãƒƒã‚° run_stage2_and_3: finished ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡ä¸­", flush=True)
            print(f"ğŸ” DEBUG run_stage2_and_3: results_final = {results_final}", flush=True)
            self.finished.emit(results_final)
            print("ğŸ” ãƒ‡ãƒãƒƒã‚° run_stage2_and_3: finished ã‚·ã‚°ãƒŠãƒ«é€ä¿¡å®Œäº†", flush=True)
            
        except Exception as e:
            import traceback
            error_msg = f"âŒ è§£æã®ç¶šè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}"
            print("ğŸ” ãƒ‡ãƒãƒƒã‚° run_stage2_and_3: ä¾‹å¤–ã‚’æ•æ‰")
            print(error_msg)
            print(f"ğŸ” ãƒ‡ãƒãƒƒã‚° run_stage2_and_3: error ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡ä¸­")
            self.error.emit(error_msg)
    
    def _get_json_log_path(self, working_dir):
        """
        Obtiene la ruta del archivo JSON de log basÃ¡ndose en la estructura de carpetas
        
        Parameters
        ----------
        working_dir : str
            Directorio de trabajo (output_folder)
        
        Returns
        -------
        str
            Ruta completa al archivo console_output.jsonl
        """
        # El JSON se guarda en RESULT_FOLDER (03_å­¦ç¿’çµæœ)
        # SegÃºn config_custom.py, RESULT_FOLDER = '03_å­¦ç¿’çµæœ'
        result_folder = os.path.join(working_dir, '03_å­¦ç¿’çµæœ')
        json_path = os.path.join(result_folder, 'console_output.jsonl')
        return json_path
    
    def _read_json_log(self, json_path):
        """
        Lee el archivo JSON de log en tiempo real y emite mensajes a consola
        
        Parameters
        ----------
        json_path : str
            Ruta al archivo console_output.jsonl
        """
        last_position = 0
        max_wait_time = 300  # Max 5 minutes waiting for the file to appear
        wait_interval = 0.5  # Check every 0.5 seconds
        elapsed_time = 0
        
        # ES: Esperar a que el archivo exista
        # EN: Wait for the file to exist
        # JP: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¾ã§å¾…ã¤
        while not os.path.exists(json_path) and elapsed_time < max_wait_time:
            time.sleep(wait_interval)
            elapsed_time += wait_interval
        
        if not os.path.exists(json_path):
            self.console_output.emit(f"âš ï¸ Archivo JSON no encontrado: {json_path}")
            return
        
        # ES: Leer el archivo en tiempo real (reabriendo cada vez para evitar problemas de bloqueo)
        # EN: Read the file in real time (reopen each time to avoid file-lock issues)
        # JP: ãƒ­ãƒƒã‚¯å•é¡Œå›é¿ã®ãŸã‚æ¯å›é–‹ãç›´ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§èª­ã‚€
        try:
            # ES: Primero, leer todo el contenido existente
            # EN: First, read all existing content
            # JP: ã¾ãšæ—¢å­˜å†…å®¹ã‚’ã™ã¹ã¦èª­ã‚€
            if os.path.exists(json_path):
                with open(json_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            entry = json.loads(line.strip())
                            if 'message' in entry:
                                self.console_output.emit(entry['message'])
                        except json.JSONDecodeError:
                            continue
                # ES: Obtener el tamaÃ±o actual del archivo despuÃ©s de leerlo
                # EN: Get the current file size after reading it
                # JP: èª­ã¿è¾¼ã¿å¾Œã«ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å–å¾—
                last_position = os.path.getsize(json_path)
            
            # ES: Leer nuevas lÃ­neas mientras el proceso estÃ¡ corriendo
            # EN: Read new lines while the process is running
            # JP: ãƒ—ãƒ­ã‚»ã‚¹ç¨¼åƒä¸­ã«æ–°ã—ã„è¡Œã‚’èª­ã‚€
            while not self._json_reader_stop.is_set():
                time.sleep(0.1)  # Polling cada 100ms
                
                # ES: Verificar si el archivo creciÃ³
                # EN: Check whether the file grew
                # JP: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¢—ãˆãŸã‹ç¢ºèª
                if os.path.exists(json_path):
                    current_size = os.path.getsize(json_path)
                    if current_size > last_position:
                        # ES: Reabrir el archivo y leer solo las nuevas lÃ­neas
                        # EN: Reopen the file and read only the new lines
                        # JP: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãç›´ã—ã€æ–°ã—ã„è¡Œã ã‘èª­ã‚€
                        with open(json_path, 'r', encoding='utf-8') as f:
                            f.seek(last_position)
                            new_content = f.read(current_size - last_position)
                            last_position = current_size
                            
                            # Procesar nuevas lÃ­neas
                            for line in new_content.split('\n'):
                                line = line.strip()
                                if line:
                                    try:
                                        entry = json.loads(line)
                                        if 'message' in entry:
                                            self.console_output.emit(entry['message'])
                                    except json.JSONDecodeError:
                                        # Si no es JSON vÃ¡lido, puede ser contenido parcial
                                        continue
        except Exception as e:
            self.console_output.emit(f"âš ï¸ JSON èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.console_output.emit(f"Traceback: {traceback.format_exc()}")
    
    def _run_script(self, script_name, working_dir):
        """
        Ejecuta un script Python en un subproceso y lee el JSON de log en tiempo real
        
        Parameters
        ----------
        script_name : str
            Nombre del script a ejecutar
        working_dir : str
            Directorio de trabajo
        
        Returns
        -------
        bool
            True si el script se ejecutÃ³ exitosamente, False en caso contrario
        """
        script_path = os.path.join(working_dir, script_name)
        
        # ES: Si el script no estÃ¡ en la carpeta de salida, usar el del directorio actual
        # EN: If the script is not in the output folder, use the one in the current directory
        # JP: å‡ºåŠ›å…ˆã«ç„¡ã‘ã‚Œã°ã€ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚‚ã®ã‚’ä½¿ç”¨ã™ã‚‹
        if not os.path.exists(script_path):
            script_path = script_name
            if not os.path.exists(script_path):
                print(f"âŒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {script_name}")
                self.console_output.emit(f"âŒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {script_name}")
                return False
        
        try:
            # Configurar variables de entorno para evitar conflictos de DLLs
            env = os.environ.copy()
            env["OMP_NUM_THREADS"] = "1"
            env["MKL_NUM_THREADS"] = "1"
            env["OPENBLAS_NUM_THREADS"] = "1"
            env["NUMEXPR_NUM_THREADS"] = "1"
            env["MPLBACKEND"] = "Agg"
            env["QT_QPA_PLATFORM"] = "offscreen"
            # Permitir mÃºltiples DLLs OpenMP si es necesario (evita conflictos)
            env["KMP_DUPLICATE_LIB_OK"] = "TRUE"
            
            # Configurar PYTHONPATH para que encuentre los mÃ³dulos
            # âœ… Usar la misma lÃ³gica que para script_base_dir (donde estÃ¡ 0sec.py)
            # Esto asegura que encontremos el directorio raÃ­z donde estÃ¡ 00_Pythonã‚³ãƒ¼ãƒ‰
            if self._cached_script_base_dir is None:
                # Calcular script_base_dir si no estÃ¡ cacheado (solo la primera vez)
                script_base_dir = None
                if self.project_folder:
                    potential_base = Path(self.project_folder).parent.parent
                    if (potential_base / "0sec.py").exists():
                        script_base_dir = potential_base
                    else:
                        current_dir = Path.cwd()
                        if (current_dir / "0sec.py").exists():
                            script_base_dir = current_dir
                        elif (current_dir / "01_model_builder.py").exists():
                            script_base_dir = current_dir
                
                if script_base_dir is None:
                    script_base_dir = Path.cwd()  # Fallback al directorio actual
                
                self._cached_script_base_dir = script_base_dir
            else:
                script_base_dir = self._cached_script_base_dir
            
            # Cachear python_code_folder tambiÃ©n
            if self._cached_python_code_folder is None:
                python_code_folder = script_base_dir / "00_Pythonã‚³ãƒ¼ãƒ‰"
                self._cached_python_code_folder = python_code_folder
            else:
                python_code_folder = self._cached_python_code_folder
            
            # Incluir site-packages del venv para que encuentre librerÃ­as como xlsxwriter
            import site
            site_packages_paths = []
            try:
                # Obtener todos los site-packages del venv actual
                for site_pkg in site.getsitepackages():
                    if os.path.exists(site_pkg):
                        site_packages_paths.append(site_pkg)
            except:
                # ES: Fallback: buscar site-packages manualmente
                # EN: Fallback: search site-packages manually
                # JP: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: site-packagesã‚’æ‰‹å‹•ã§æ¢ã™
                venv_lib = Path(sys.executable).parent.parent / "Lib" / "site-packages"
                if venv_lib.exists():
                    site_packages_paths.append(str(venv_lib))
            
            # Construir PYTHONPATH
            pythonpath_parts = [str(python_code_folder)]
            pythonpath_parts.extend(site_packages_paths)
            
            # ES: Agregar PYTHONPATH existente si hay
            # EN: Add existing PYTHONPATH if present
            # JP: æ—¢å­˜ã®PYTHONPATHãŒã‚ã‚Œã°è¿½åŠ 
            existing_pythonpath = env.get("PYTHONPATH", "")
            if existing_pythonpath:
                pythonpath_parts.append(existing_pythonpath)
            
            # Usar separador correcto segÃºn el sistema operativo
            separator = ";" if sys.platform == "win32" else ":"
            pythonpath = separator.join(pythonpath_parts)
            
            env["PYTHONPATH"] = pythonpath
            
            # ES: Obtener ruta del JSON de log
            # EN: Get JSON log path
            # JP: JSONãƒ­ã‚°ã®ãƒ‘ã‚¹ã‚’å–å¾—
            json_log_path = self._get_json_log_path(working_dir)
            
            # ES: Ejecutar script
            # EN: Run the script
            # JP: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            self.console_output.emit(f"ğŸ”§ Ejecutando: {script_path}")
            self.console_output.emit(f"ğŸ“ Working directory: {working_dir}")
            self.console_output.emit(f"ğŸ“ PYTHONPATH: {pythonpath}")
            self.console_output.emit(f"ğŸ“ JSON log: {json_log_path}")
            
            # Reiniciar el evento de parada del lector JSON
            self._json_reader_stop.clear()
            
            # ES: Iniciar hilo para leer JSON en tiempo real
            # EN: Start a thread to read JSON in real time
            # JP: JSONã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§èª­ã‚€ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
            json_reader_thread = threading.Thread(
                target=self._read_json_log,
                args=(json_log_path,),
                daemon=True
            )
            json_reader_thread.start()
            
            # ES: Ejecutar script con Popen para poder leer salida en tiempo real
            # EN: Run the script with Popen so we can read output in real time
            # JP: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å‡ºåŠ›ã‚’èª­ã‚€ãŸã‚Popenã§å®Ÿè¡Œ
            process = subprocess.Popen(
                [sys.executable, script_path],
                cwd=working_dir,
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8',
                errors='replace',
                bufsize=1  # Line buffered
            )
            
            # ES: Guardar referencia al proceso para poder cancelarlo
            # EN: Store a reference to the process so we can cancel it
            # JP: ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã§ãã‚‹ã‚ˆã†ãƒ—ãƒ­ã‚»ã‚¹å‚ç…§ã‚’ä¿æŒ
            self._current_process = process
            
            # Event para detener los threads de lectura de forma segura
            stop_reading = threading.Event()
            self._stop_reading = stop_reading
            
            # ES: Leer stdout y stderr en tiempo real (el script original no genera JSON)
            # EN: Read stdout and stderr in real time (the original script does not generate JSON)
            # JP: stdout/stderrã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§èª­ã‚€ï¼ˆå…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯JSONã‚’ç”Ÿæˆã—ãªã„ï¼‰
            # âœ… ACTIVADO: El script original imprime directamente a stdout/stderr
            def read_output(pipe, is_stderr=False):
                try:
                    while not stop_reading.is_set():
                        line = pipe.readline()
                        if not line:  # EOF o pipe cerrado
                            break
                        # âœ… Emitir directamente a consola (sin depender de JSON)
                        line_clean = line.rstrip('\n\r')
                        if line_clean:
                            self.console_output.emit(line_clean)
                            # âœ… Parsear progreso para extraer fold y trial
                            self._parse_progress(line_clean)
                except (ValueError, OSError):
                    # Pipe ya cerrado â€” salir silenciosamente
                    pass
                except Exception:
                    # Cualquier otro error â€” ignorar
                    pass
            
            stdout_thread = threading.Thread(target=read_output, args=(process.stdout, False), daemon=True)
            stderr_thread = threading.Thread(target=read_output, args=(process.stderr, True), daemon=True)
            stdout_thread.start()
            stderr_thread.start()
            
            # Esperar a que termine el proceso o sea cancelado
            # Usar polling para poder cancelar
            while process.poll() is None:
                if self._cancelled:
                    print("ğŸ›‘ ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸­...")
                    self.console_output.emit("ğŸ›‘ ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸­...")
                    try:
                        process.terminate()  # Intentar terminar suavemente
                        # Esperar un poco para que termine (polling)
                        for _ in range(20):  # Esperar hasta 2 segundos (20 * 0.1)
                            if process.poll() is not None:
                                break
                            time.sleep(0.1)
                        
                        # Si aÃºn no terminÃ³, forzar kill
                        if process.poll() is None:
                            print("âš ï¸ ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ã¾ã›ã‚“ã€‚å¼·åˆ¶çµ‚äº†ã—ã¾ã™...")
                            self.console_output.emit("âš ï¸ ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ã¾ã›ã‚“ã€‚å¼·åˆ¶çµ‚äº†ã—ã¾ã™...")
                            process.kill()
                            process.wait()
                    except Exception as e:
                        print(f"âš ï¸ Error al cancelar proceso: {e}")
                        try:
                            if process.poll() is None:
                                process.kill()
                                process.wait()
                        except:
                            pass
                    return False
                time.sleep(0.1)  # Wait a bit before checking again
            
            returncode = process.returncode
            
            # ES: Detener los threads de lectura antes de cerrar pipes
            # EN: Stop reader threads before closing pipes
            # JP: ãƒ‘ã‚¤ãƒ—ã‚’é–‰ã˜ã‚‹å‰ã«èª­å–ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢
            stop_reading.set()
            stdout_thread.join(timeout=1.0)  # Esperar mÃ¡ximo 1 segundo
            stderr_thread.join(timeout=1.0)  # Esperar mÃ¡ximo 1 segundo
            
            # ES: Limpiar referencia al proceso
            # EN: Clear process references
            # JP: ãƒ—ãƒ­ã‚»ã‚¹å‚ç…§ã‚’ã‚¯ãƒªã‚¢
            self._current_process = None
            self._stop_reading = None
            
            # Detener el lector JSON
            self._json_reader_stop.set()
            json_reader_thread.join(timeout=1.0)  # Esperar mÃ¡ximo 1 segundo
            
            # ES: Cerrar pipes de forma segura (ya no hay threads leyendo)
            # EN: Close pipes safely (no threads are reading anymore)
            # JP: ãƒ‘ã‚¤ãƒ—ã‚’å®‰å…¨ã«é–‰ã˜ã‚‹ï¼ˆèª­å–ã‚¹ãƒ¬ãƒƒãƒ‰ã¯åœæ­¢æ¸ˆã¿ï¼‰
            try:
                if process.stdout:
                    process.stdout.close()
                if process.stderr:
                    process.stderr.close()
            except:
                pass
            
            if returncode == 0:
                self.console_output.emit(f"âœ… Script ejecutado exitosamente: {script_name}")
                return True
            else:
                self.console_output.emit(f"âŒ Script fallÃ³ con cÃ³digo {returncode}: {script_name}")
                # ES: âœ… Intentar leer cualquier salida restante de stderr para ver el error
                # EN: âœ… Try to read any remaining stderr output to see the error
                # JP: âœ… ã‚¨ãƒ©ãƒ¼ç¢ºèªã®ãŸã‚stderrã®æ®‹ã‚Šå‡ºåŠ›ã‚’èª­ã‚“ã§ã¿ã‚‹
                try:
                    if process.stderr:
                        remaining_stderr = process.stderr.read()
                        if remaining_stderr:
                            for line in remaining_stderr.decode('utf-8', errors='replace').split('\n'):
                                line_clean = line.rstrip('\n\r')
                                if line_clean:
                                    self.console_output.emit(f"[STDERR] {line_clean}")
                except:
                    pass
                return False
                
        except Exception as e:
            self.console_output.emit(f"âŒ Error ejecutando script {script_name}: {e}")
            import traceback
            error_trace = traceback.format_exc()
            self.console_output.emit(error_trace)
            self._json_reader_stop.set()  # Asegurar que el lector se detenga
            return False
    
    def _parse_progress(self, line):
        """
        Parsea el output del script para extraer informaciÃ³n de progreso (fold y trial)
        y emite la seÃ±al progress_detailed
        """
        try:
            # ES: Solo parsear si estamos en el stage 01 (model_builder)
            # EN: Only parse when we are in stage 01 (model_builder)
            # JP: Stage 01ï¼ˆmodel_builderï¼‰ã®ã¨ãã®ã¿è§£æã™ã‚‹
            if self.current_stage != '01_model_builder':
                return
            
            # ES: Detectar anÃ¡lisis de datos completado
            # EN: Detect completed data analysis
            # JP: ãƒ‡ãƒ¼ã‚¿åˆ†æå®Œäº†ã‚’æ¤œå‡º
            if 'ãƒ‡ãƒ¼ã‚¿åˆ†æå®Œäº†' in line or 'ãƒ‡ãƒ¼ã‚¿åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ' in line:
                self.data_analysis_completed = True
                self.current_task = 'dcv'
                # ES: Emitir progreso actualizado
                # EN: Emit updated progress
                # JP: æ›´æ–°ã—ãŸé€²æ—ã‚’é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: Detectar inicio de anÃ¡lisis de datos
            # EN: Detect start of data analysis
            # JP: ãƒ‡ãƒ¼ã‚¿åˆ†æé–‹å§‹ã‚’æ¤œå‡º
            if 'ãƒ‡ãƒ¼ã‚¿åˆ†æé–‹å§‹' in line:
                self.current_task = 'data_analysis'
                # ES: Emitir progreso actualizado
                # EN: Emit updated progress
                # JP: æ›´æ–°ã—ãŸé€²æ—ã‚’é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: Detectar entrenamiento del modelo final
            # EN: Detect final model training
            # JP: æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’æ¤œå‡º
            if 'æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´' in line or 'æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿' in line:
                self.final_model_training = True
                self.current_task = 'final_model'
                # ES: Emitir progreso actualizado
                # EN: Emit updated progress
                # JP: æ›´æ–°ã—ãŸé€²æ—ã‚’é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: Detectar anÃ¡lisis SHAP
            # EN: Detect SHAP analysis
            # JP: SHAPè§£æã‚’æ¤œå‡º
            if 'SHAP' in line and ('åˆ†æ' in line or 'analyze' in line.lower()):
                self.shap_analysis = True
                self.current_task = 'shap'
                # ES: Emitir progreso actualizado
                # EN: Emit updated progress
                # JP: æ›´æ–°ã—ãŸé€²æ—ã‚’é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: Detectar guardado completado
            # EN: Detect completed saving
            # JP: ä¿å­˜å®Œäº†ã‚’æ¤œå‡º
            if 'æ¨è«–ç”¨ãƒãƒ³ãƒ‰ãƒ«ä¿å­˜' in line or 'âœ… æ¨è«–ç”¨ãƒãƒ³ãƒ‰ãƒ«ä¿å­˜' in line:
                self.saving_completed = True
                self.current_task = 'saving'
                # ES: Emitir progreso actualizado
                # EN: Emit updated progress
                # JP: æ›´æ–°ã—ãŸé€²æ—ã‚’é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: Detectar inicio de nueva pasada (target): "Double Cross-Validation: {target_name}" o "å‡¦ç†ä¸­: {target}"
            # EN: Detect the start of a new pass (target): "Double Cross-Validation: {target_name}" or "å‡¦ç†ä¸­: {target}"
            # JP: æ–°ã—ã„ãƒ‘ã‚¹ï¼ˆç›®çš„å¤‰æ•°ï¼‰ã®é–‹å§‹ã‚’æ¤œå‡º: "Double Cross-Validation: {target_name}" ã¾ãŸã¯ "å‡¦ç†ä¸­: {target}"
            # ES: Priorizar "Double Cross-Validation" porque aparece despuÃ©s de "å‡¦ç†ä¸­"
            # EN: Prefer "Double Cross-Validation" because it appears after "å‡¦ç†ä¸­"
            # JP: "å‡¦ç†ä¸­"ã®å¾Œã«å‡ºã‚‹ãŸã‚ "Double Cross-Validation" ã‚’å„ªå…ˆ
            pass_match = re.search(r'Double\s+Cross-Validation:\s+(\w+)', line, re.IGNORECASE)
            target_name = None
            if pass_match:
                target_name = pass_match.group(1)
            else:
                # ES: Si no se encuentra "Double Cross-Validation", buscar "å‡¦ç†ä¸­"
                # EN: If "Double Cross-Validation" is not found, look for "å‡¦ç†ä¸­"
                # JP: "Double Cross-Validation"ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯"å‡¦ç†ä¸­"ã‚’æ¢ã™
                pass_match = re.search(r'å‡¦ç†ä¸­:\s+(\w+)', line)
                if pass_match:
                    target_name = pass_match.group(1)
            
            if target_name and target_name != self.last_detected_target:
                # ES: Nuevo target detectado: incrementar pasada
                # EN: New target detected: increment pass counter
                # JP: æ–°ã—ã„ç›®çš„å¤‰æ•°ã‚’æ¤œå‡º: ãƒ‘ã‚¹æ•°ã‚’å¢—ã‚„ã™
                self.last_detected_target = target_name
                self.current_pass += 1
                self.current_fold = 0  # Reset fold when the pass changes
                self.current_trial = 0  # âœ… Reset completed-trials counter when the pass changes
                self.current_model = 0  # Reset model when the pass changes
                self.completed_trials_in_current_fold = set()  # âœ… Reset the set of completed trials
                self.final_model_training = False  # Reset for a new pass
                self.shap_analysis = False  # Reset for a new pass
                self.saving_completed = False  # Reset for a new pass
                self.current_task = 'dcv'  # Back to DCV for the new pass
                # ES: Emitir progreso actualizado con la pasada correcta
                # EN: Emit updated progress with the correct pass
                # JP: æ­£ã—ã„ãƒ‘ã‚¹ã§æ›´æ–°ã—ãŸé€²æ—ã‚’é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: Detectar Outer Fold: "--- Outer Fold X/Y ---"
            # EN: Detect Outer Fold: "--- Outer Fold X/Y ---"
            # JP: Outer Foldã‚’æ¤œå‡º: "--- Outer Fold X/Y ---"
            fold_match = re.search(r'---\s*Outer\s+Fold\s+(\d+)/(\d+)\s*---', line, re.IGNORECASE)
            if fold_match:
                self.current_fold = int(fold_match.group(1))
                self.total_folds = int(fold_match.group(2))
                self.current_trial = 0  # âœ… Reset completed-trials counter when the fold changes
                self.current_model = 0  # Reset model when the fold changes
                self.completed_trials_in_current_fold = set()  # âœ… Reset the set of completed trials
                # ES: Emitir progreso actualizado
                # EN: Emit updated progress
                # JP: æ›´æ–°ã—ãŸé€²æ—ã‚’é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: Detectar inicio de optimizaciÃ³n de modelo: "ğŸ” {model_name} æœ€é©åŒ–ä¸­..."
            # EN: Detect start of model optimization: "ğŸ” {model_name} æœ€é©åŒ–ä¸­..."
            # JP: ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–é–‹å§‹ã‚’æ¤œå‡º: "ğŸ” {model_name} æœ€é©åŒ–ä¸­..."
            model_match = re.search(r'ğŸ”\s+(\w+)\s+æœ€é©åŒ–ä¸­', line)
            if model_match:
                self.current_model += 1
                # ES: âœ… NO resetear contador de trials cuando cambia el modelo dentro del mismo fold
                # EN: âœ… Do NOT reset the trial counter when the model changes within the same fold
                # JP: âœ… åŒä¸€foldå†…ã§ãƒ¢ãƒ‡ãƒ«ãŒå¤‰ã‚ã£ã¦ã‚‚trialã‚«ã‚¦ãƒ³ã‚¿ã¯ãƒªã‚»ãƒƒãƒˆã—ãªã„
                # ES: El contador de trials debe continuar a travÃ©s de todos los modelos en el mismo fold
                # EN: The trial counter must continue across all models within the same fold
                # JP: trialã‚«ã‚¦ãƒ³ã‚¿ã¯åŒä¸€foldå†…ã®å…¨ãƒ¢ãƒ‡ãƒ«ã‚’é€šã—ã¦ç¶™ç¶šã™ã‚‹å¿…è¦ãŒã‚ã‚‹
                # ES: Solo se resetea cuando cambia el fold
                # EN: It is only reset when the fold changes
                # JP: foldãŒå¤‰ã‚ã‚‹ã¨ãã ã‘ãƒªã‚»ãƒƒãƒˆã™ã‚‹
                # ES: Emitir progreso actualizado para mostrar el cambio de modelo
                # EN: Emit updated progress to reflect the model change
                # JP: ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã‚’åæ˜ ã™ã‚‹ãŸã‚é€²æ—ã‚’æ›´æ–°ã—ã¦é€ä¿¡
                self.progress_detailed.emit(
                    self.current_trial,  # Mantener el contador actual (no resetear)
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # ES: âœ… Formato de barra de progreso de Optuna: buscar "X/Y" (prioritario porque muestra trials completados)
            # EN: âœ… Optuna progress-bar format: look for "X/Y" (preferred because it shows completed trials)
            # JP: âœ… Optunaé€²æ—ãƒãƒ¼å½¢å¼: "X/Y"ã‚’æ¢ã™ï¼ˆå®Œäº†trialæ•°ãŒåˆ†ã‹ã‚‹ãŸã‚å„ªå…ˆï¼‰
            # Ejemplo: "Best trial: 34. Best value: 4.04966: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [04:34<00:00,  2.34s/it]"
            # El formato "X/Y" muestra: X = trials completados, Y = total trials
            trial_progress_match = re.search(r'(\d+)/(\d+)\s*\[', line)
            if trial_progress_match:
                trials_completed = int(trial_progress_match.group(1))  # NÃºmero de trials completados (contador incremental)
                trial_total = int(trial_progress_match.group(2))  # Total trials
                
                # âœ… Usar el contador de trials completados (no el nÃºmero del trial)
                self.current_trial = trials_completed
                self.total_trials = trial_total
                
                # âœ… Calcular valores acumulados para porcentaje lineal
                if self.current_pass > 0 and self.total_folds > 0:
                    trials_per_fold = trial_total
                    # Trials completados en passes anteriores
                    trials_in_previous_passes = (self.current_pass - 1) * self.total_folds * trials_per_fold
                    # Trials completados en folds anteriores del pass actual
                    trials_in_previous_folds = (self.current_fold - 1) * trials_per_fold
                    # Trials completados en el fold actual
                    self.accumulated_trial_current = trials_in_previous_passes + trials_in_previous_folds + trials_completed
                    # ES: Total de trials acumulados | EN: Total accumulated trials | JA: ç´¯ç©trialç·æ•°
                    self.accumulated_trial_total = self.total_passes * self.total_folds * trials_per_fold
                else:
                    # Fallback: usar valores locales si no hay suficiente informaciÃ³n
                    self.accumulated_trial_current = trials_completed
                    self.accumulated_trial_total = trial_total
                
                # Emitir progreso actualizado
                self.progress_detailed.emit(
                    self.current_trial,  # Trials completados en fold actual (para mostrar: 1/50, 2/50, etc.)
                    self.total_trials,   # Total trials per fold
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # Detectar trial de Optuna: buscar patrones como "[I ...] Trial X finished" o "Trial X finished"
            # âœ… Estos mensajes indican que un trial se completÃ³, incrementar contador
            trial_finished_match = re.search(r'\[I\s+\d+:\d+:\d+\.\d+\]\s+Trial\s+(\d+)\s+finished', line)
            if trial_finished_match:
                trial_id = int(trial_finished_match.group(1))  # ID del trial completado (puede ser 8, 13, 2, etc.)
                
                # âœ… Solo incrementar contador si este trial no fue contado antes
                if trial_id not in self.completed_trials_in_current_fold:
                    self.completed_trials_in_current_fold.add(trial_id)
                    self.current_trial += 1  # Incrementar contador de trials completados
                    
                    # âœ… Actualizar valores acumulados
                    if self.current_pass > 0 and self.total_folds > 0 and self.total_trials > 0:
                        trials_per_fold = self.total_trials
                        trials_in_previous_passes = (self.current_pass - 1) * self.total_folds * trials_per_fold
                        trials_in_previous_folds = (self.current_fold - 1) * trials_per_fold
                        self.accumulated_trial_current = trials_in_previous_passes + trials_in_previous_folds + self.current_trial
                        self.accumulated_trial_total = self.total_passes * self.total_folds * trials_per_fold
                
                # Emitir progreso actualizado
                self.progress_detailed.emit(
                    self.current_trial,  # Contador incremental de trials completados
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
            
            # Otro formato: "Trial X finished with value..."
            trial_finished_match2 = re.search(r'Trial\s+(\d+)\s+finished', line, re.IGNORECASE)
            if trial_finished_match2:
                trial_id = int(trial_finished_match2.group(1))  # ID del trial completado
                
                # âœ… Solo incrementar contador si este trial no fue contado antes
                if trial_id not in self.completed_trials_in_current_fold:
                    self.completed_trials_in_current_fold.add(trial_id)
                    self.current_trial += 1  # Incrementar contador de trials completados
                    
                    # âœ… Actualizar valores acumulados
                    if self.current_pass > 0 and self.total_folds > 0 and self.total_trials > 0:
                        trials_per_fold = self.total_trials
                        trials_in_previous_passes = (self.current_pass - 1) * self.total_folds * trials_per_fold
                        trials_in_previous_folds = (self.current_fold - 1) * trials_per_fold
                        self.accumulated_trial_current = trials_in_previous_passes + trials_in_previous_folds + self.current_trial
                        self.accumulated_trial_total = self.total_passes * self.total_folds * trials_per_fold
                
                # Emitir progreso actualizado
                self.progress_detailed.emit(
                    self.current_trial,  # Contador incremental de trials completados
                    self.total_trials,
                    self.current_fold,
                    self.total_folds,
                    self.current_pass,
                    self.total_passes,
                    self.current_task,
                    self.data_analysis_completed,
                    self.final_model_training,
                    self.shap_analysis,
                    self.current_model,
                    self.total_models
                )
                return
                
        except Exception as e:
            # Silenciar errores de parsing para no interrumpir el flujo
            pass
    def cancel(self):
        """ES: Cancela la ejecuciÃ³n del anÃ¡lisis
        EN: Cancel the analysis execution
        JA: è§£æã®å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        print("ğŸ›‘ éç·šå½¢è§£æã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸­...")
        self._cancelled = True
        
        # Terminar proceso subprocess si estÃ¡ corriendo
        if self._current_process is not None:
            try:
                print("ğŸ›‘ Terminando proceso subprocess...")
                self._current_process.terminate()
                # Esperar un poco (polling)
                for _ in range(20):  # Esperar hasta 2 segundos
                    if self._current_process.poll() is not None:
                        break
                    time.sleep(0.1)
                
                # Si aÃºn no terminÃ³, forzar kill
                if self._current_process.poll() is None:
                    print("âš ï¸ ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ã¾ã›ã‚“ã€‚kill ã—ã¾ã™...")
                    self._current_process.kill()
                    self._current_process.wait()
                else:
                    print("âœ… Proceso subprocess terminado correctamente")
            except Exception as e:
                print(f"âš ï¸ Error al terminar proceso: {e}")
                try:
                    if self._current_process and self._current_process.poll() is None:
                        self._current_process.kill()
                        self._current_process.wait()
                except:
                    pass
        
        # Detener lectura de output
        if self._stop_reading is not None:
            self._stop_reading.set()
            print("âœ… Threads de lectura detenidos")
        
        # Detener lector JSON
        self._json_reader_stop.set()
        print("âœ… Lector JSON detenido")
        
        # Solicitar que el thread termine
        if self.isRunning():
            print("ğŸ›‘ worker ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’è¦æ±‚ä¸­...")
            self.quit()
        
        print("âœ… ã‚­ãƒ£ãƒ³ã‚»ãƒ«å®Œäº†")
    
    def _save_config_file(self, config_file_path):
        """
        Guarda el archivo de configuraciÃ³n personalizada.
        Copia config.py completo y reemplaza solo los valores modificados desde la UI.
        """
        # ES: Buscar config.py en el directorio actual o en el directorio del script
        # EN: Look for config.py in the current directory or the script directory
        # JP: ç¾åœ¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§config.pyã‚’æ¢ã™
        config_py_path = None
        possible_paths = [
            Path.cwd() / 'config.py',
            Path(__file__).parent / 'config.py',
            Path(self.output_folder).parent / 'config.py',
        ]
        
        for path in possible_paths:
            if path.exists():
                config_py_path = path
                break
        
        if not config_py_path:
            raise FileNotFoundError("No se encontrÃ³ config.py. AsegÃºrate de que existe en el directorio de trabajo.")
        
        # ES: Leer config.py completo
        # EN: Read the full config.py
        # JP: config.pyã‚’å…¨æ–‡èª­ã¿è¾¼ã‚€
        with open(config_py_path, 'r', encoding='utf-8') as f:
            config_content = f.read()
        
        # Mapa de normalizaciÃ³n de nombres de modelos
        model_name_map = {
            'random_forest': 'RandomForest',
            'lightgbm': 'LightGBM',
            'xgboost': 'XGBoost',
            'gradient_boost': 'GradientBoost',
            'ridge': 'Ridge',
            'lasso': 'Lasso',
            'elastic_net': 'ElasticNet'
        }
        
        # FunciÃ³n auxiliar para reemplazar valores en config.py
        def replace_config_value(content, pattern, new_value, is_string=True, is_list=False, is_dict=False, is_raw_string=False):
            """
            Reemplaza un valor en config.py usando regex.
            Mantiene la indentaciÃ³n original del archivo y preserva comentarios.
            Siempre agrega un espacio antes del comentario si existe.
            
            Args:
                is_raw_string: Si es True, usa r'...' en lugar de '...' para strings
            """
            pattern_clean = pattern.strip()
            
            if is_dict:
                # ES: Para diccionarios multilÃ­nea, buscar desde el patrÃ³n hasta el cierre de llaves
                # EN: For multi-line dicts, search from the pattern to the closing brace
                # JP: è¤‡æ•°è¡Œè¾æ›¸ã¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é–‰ã˜ã‚«ãƒƒã‚³ã¾ã§æ¤œç´¢
                # Capturar la indentaciÃ³n original y comentario si existe
                # El patrÃ³n debe capturar todo el diccionario, incluyendo las llaves
                dict_pattern = rf'^(\s*)({re.escape(pattern_clean)}\s*=\s*{{)(.*?)(^\s*}})(\s*#.*)?$'
                def dict_replacer(match):
                    indent = match.group(1)
                    comment = match.group(5) if match.group(5) else ''
                    if comment:
                        comment = ' ' + comment.strip()  # Asegurar espacio antes del comentario
                    # new_value ya contiene el diccionario completo con llaves {}
                    # ES: Solo necesitamos agregar la indentaciÃ³n a cada lÃ­nea
                    # EN: We only need to add the indentation to each line
                    # JP: å„è¡Œã«ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’ä»˜ã‘ã‚‹ã ã‘ã§ã‚ˆã„
                    dict_lines = new_value.split('\n')
                    formatted_dict = '\n'.join([f"{indent}    {line}" if line.strip() else line for line in dict_lines])
                    # Si new_value es un string simple como "{'key': 'value'}", formatearlo mejor
                    if new_value.startswith('{') and new_value.endswith('}') and '\n' not in new_value:
                        # Es un diccionario en una lÃ­nea, formatearlo en mÃºltiples lÃ­neas
                        try:
                            import ast
                            dict_obj = ast.literal_eval(new_value)
                            formatted_items = []
                            for k, v in dict_obj.items():
                                formatted_items.append(f"{indent}    '{k}': '{v}',")
                            formatted_dict = '\n'.join(formatted_items)
                        except:
                            # Si falla el parsing, usar el valor tal cual pero con indentaciÃ³n
                            formatted_dict = f"{indent}    {new_value}"
                    return f"{indent}{pattern_clean} = {{\n{formatted_dict}\n{indent}}}{comment}"
                content = re.sub(dict_pattern, dict_replacer, content, flags=re.MULTILINE | re.DOTALL)
            elif is_list:
                # ES: Para listas multilÃ­nea, buscar desde el patrÃ³n hasta el cierre de corchetes
                # EN: For multi-line lists, search from the pattern to the closing bracket
                # JP: è¤‡æ•°è¡Œãƒªã‚¹ãƒˆã¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é–‰ã˜ã‚«ãƒƒã‚³ã¾ã§æ¤œç´¢
                # Capturar la indentaciÃ³n original y comentario si existe
                list_pattern = rf'^(\s*)({re.escape(pattern_clean)}\s*=\s*\[)(.*?)(\])(\s*#.*)?$'
                def list_replacer(match):
                    indent = match.group(1)
                    comment = match.group(5) if match.group(5) else ''
                    if comment:
                        comment = ' ' + comment.strip()  # Asegurar espacio antes del comentario
                    return f"{indent}{pattern_clean} = {new_value}{comment}"
                content = re.sub(list_pattern, list_replacer, content, flags=re.MULTILINE | re.DOTALL)
            else:
                # Para valores simples
                if is_string:
                    # ES: String: buscar el patrÃ³n y reemplazar el valor entre comillas
                    # EN: String: find the pattern and replace the value inside quotes
                    # JP: æ–‡å­—åˆ—: ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã—ã¦å¼•ç”¨ç¬¦å†…ã®å€¤ã‚’ç½®æ›
                    # Capturar la indentaciÃ³n original, comillas y comentario si existe
                    # Manejar tambiÃ©n raw strings (r'...' o r"...")
                    pattern_regex = rf'^(\s*)({re.escape(pattern_clean)}\s*=\s*)(r?)([\'"])([^\'"]*)(\4)(\s*#.*)?$'
                    def string_replacer(match):
                        indent = match.group(1)
                        raw_prefix = match.group(3)  # 'r' o vacÃ­o
                        quote = match.group(4)
                        comment = match.group(7) if match.group(7) else ''
                        if comment:
                            comment = ' ' + comment.strip()  # Asegurar espacio antes del comentario
                        # Asegurar que new_value no tenga comillas dobles incorrectas ni prefijos r
                        clean_value = new_value.strip("'\"")
                        # Si new_value ya tiene r' o r", quitarlo
                        if clean_value.startswith("r'") or clean_value.startswith('r"'):
                            clean_value = clean_value[2:]
                        elif clean_value.startswith("r"):
                            clean_value = clean_value[1:]
                        # Usar raw string si se especificÃ³
                        if is_raw_string:
                            return f"{indent}{pattern_clean} = r{quote}{clean_value}{quote}{comment}"
                        else:
                            return f"{indent}{pattern_clean} = {quote}{clean_value}{quote}{comment}"
                    content = re.sub(pattern_regex, string_replacer, content, flags=re.MULTILINE)
                else:
                    # ES: NÃºmero o booleano: buscar el patrÃ³n y reemplazar el valor
                    # EN: Number/boolean: find the pattern and replace the value
                    # JP: æ•°å€¤/çœŸå½å€¤: ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã—ã¦å€¤ã‚’ç½®æ›
                    # Capturar la indentaciÃ³n original y comentario si existe
                    # Manejar casos como "50#" (sin espacio) o "50 # comentario" (con espacio)
                    pattern_regex = rf'^(\s*)({re.escape(pattern_clean)}\s*=\s*)([^\n]+)$'
                    def value_replacer(match):
                        indent = match.group(1)
                        full_line = match.group(3).strip()
                        
                        # Separar el valor del comentario
                        # ES: Buscar # que puede estar pegado o con espacio
                        # EN: Look for # which may be attached or separated by a space
                        # JP: #ãŒãã£ã¤ã„ã¦ã„ã‚‹/ç©ºç™½ã‚ã‚Šã®ä¸¡æ–¹ã‚’è€ƒæ…®ã—ã¦æ¢ã™
                        if '#' in full_line:
                            # Dividir por #, pero mantener el comentario
                            parts = full_line.split('#', 1)
                            old_value = parts[0].strip()
                            comment_text = parts[1].strip() if len(parts) > 1 else ''
                            
                            # Reconstruir con espacio antes del comentario
                            if comment_text:
                                comment = f" # {comment_text}"
                            else:
                                comment = ""
                        else:
                            # No hay comentario
                            comment = ""
                        
                        return f"{indent}{pattern_clean} = {new_value}{comment}"
                    content = re.sub(pattern_regex, value_replacer, content, flags=re.MULTILINE)
            
            return content
        
        # Reemplazar rutas (siempre se reemplazan)
        # Nota: En config.py estas son atributos de clase Config
        data_folder = os.path.join(self.output_folder, '01_ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ')
        result_folder = os.path.join(self.output_folder, '03_å­¦ç¿’çµæœ')
        model_folder = os.path.join(self.output_folder, '02_å­¦ç¿’ãƒ¢ãƒ‡ãƒ«')
        
        # Reemplazar atributos de clase Config
        # Para rutas, usar r'' para manejar correctamente las barras invertidas en Windows
        # Pasar solo el path sin comillas ni r, la funciÃ³n agregarÃ¡ r'...' correctamente
        config_content = replace_config_value(config_content, 'DATA_FOLDER', data_folder, is_string=True, is_raw_string=True)
        config_content = replace_config_value(config_content, 'RESULT_FOLDER', result_folder, is_string=True, is_raw_string=True)
        config_content = replace_config_value(config_content, 'MODEL_FOLDER', model_folder, is_string=True, is_raw_string=True)
        # ES: Usar analysis_df.xlsx como archivo de entrada para 01_model_builder
        # EN: Use analysis_df.xlsx as the input file for 01_model_builder
        # JP: 01_model_builderã®å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦analysis_df.xlsxã‚’ä½¿ç”¨
        config_content = replace_config_value(config_content, 'INPUT_FILE', 'analysis_df.xlsx', is_string=True)
        
        # Reemplazar MODELS_TO_USE si estÃ¡ en config_values
        if 'models_to_use' in self.config_values and self.config_values['models_to_use']:
            normalized_models = []
            for model in self.config_values['models_to_use']:
                # Mantener el formato original de config.py (nombres en minÃºsculas con guiones bajos)
                normalized_models.append(f"'{model}'")
            models_str = f"[{', '.join(normalized_models)}]"
            config_content = replace_config_value(config_content, 'MODELS_TO_USE', models_str, is_string=False, is_list=True)
        
        # Reemplazar N_TRIALS
        if 'N_TRIALS' in self.config_values or 'n_trials' in self.config_values:
            n_trials = self.config_values.get('N_TRIALS', self.config_values.get('n_trials', 50))
            print(f"ğŸ”§ Reemplazando N_TRIALS con valor: {n_trials}")
            config_content = replace_config_value(config_content, 'N_TRIALS', str(n_trials), is_string=False)
            # ES: Verificar que el reemplazo funcionÃ³
            # EN: Verify that the replacement worked
            # JP: ç½®æ›ãŒæˆåŠŸã—ãŸã‹ç¢ºèª
            if f"N_TRIALS = {n_trials}" in config_content or f"N_TRIALS = {n_trials} #" in config_content:
                print(f"âœ… N_TRIALS reemplazado correctamente en config_custom.py")
            else:
                print(f"âš ï¸ è­¦å‘Š: N_TRIALS ãŒæ­£ã—ãç½®æ›ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        # Reemplazar OUTER_SPLITS e INNER_SPLITS
        if 'outer_splits' in self.config_values or 'OUTER_SPLITS' in self.config_values:
            outer_splits = self.config_values.get('outer_splits', self.config_values.get('OUTER_SPLITS', 10))
            config_content = replace_config_value(config_content, 'OUTER_SPLITS', str(outer_splits), is_string=False)
        
        if 'inner_splits' in self.config_values or 'INNER_SPLITS' in self.config_values:
            inner_splits = self.config_values.get('inner_splits', self.config_values.get('INNER_SPLITS', 10))
            config_content = replace_config_value(config_content, 'INNER_SPLITS', str(inner_splits), is_string=False)
        
        # Reemplazar DEFAULT_TOP_K
        if 'top_k' in self.config_values:
            config_content = replace_config_value(config_content, 'DEFAULT_TOP_K', str(self.config_values['top_k']), is_string=False)
        
        # Reemplazar DEFAULT_CORR_THRESHOLD
        if 'corr_threshold' in self.config_values:
            config_content = replace_config_value(config_content, 'DEFAULT_CORR_THRESHOLD', str(self.config_values['corr_threshold']), is_string=False)
        
        # Reemplazar USE_CORRELATION_REMOVAL
        if 'use_correlation_removal' in self.config_values:
            use_corr = str(self.config_values['use_correlation_removal'])
            config_content = replace_config_value(config_content, 'USE_CORRELATION_REMOVAL', use_corr, is_string=False)
        
        # Reemplazar TRANSFORM_METHOD
        if 'transform_method' in self.config_values:
            config_content = replace_config_value(config_content, 'TRANSFORM_METHOD', self.config_values['transform_method'], is_string=True)
        
        # Reemplazar SHAP_MODE
        if 'shap_mode' in self.config_values:
            config_content = replace_config_value(config_content, 'SHAP_MODE', self.config_values['shap_mode'], is_string=True)
        
        # Reemplazar SHAP_MAX_SAMPLES
        if 'shap_max_samples' in self.config_values:
            config_content = replace_config_value(config_content, 'SHAP_MAX_SAMPLES', str(self.config_values['shap_max_samples']), is_string=False)
        
        # Reemplazar DEFAULT_MODEL
        if 'default_model' in self.config_values:
            default_model = self.config_values['default_model']
            # Mantener el formato original (minÃºsculas con guiones bajos)
            # Pasar solo el valor sin comillas, la funciÃ³n agregarÃ¡ las comillas correctas
            config_content = replace_config_value(config_content, 'DEFAULT_MODEL', default_model, is_string=True)
        
        # Reemplazar SHOW_OPTUNA_PROGRESS
        if 'show_optuna_progress' in self.config_values:
            show_progress = str(self.config_values['show_optuna_progress'])
            config_content = replace_config_value(config_content, 'SHOW_OPTUNA_PROGRESS', show_progress, is_string=False)
        
        # Reemplazar VERBOSE_LOGGING
        if 'verbose_logging' in self.config_values:
            verbose = str(self.config_values['verbose_logging'])
            config_content = replace_config_value(config_content, 'VERBOSE_LOGGING', verbose, is_string=False)
        
        # Reemplazar SHOW_DATA_ANALYSIS_DETAILS
        if 'show_data_analysis' in self.config_values:
            show_details = str(self.config_values['show_data_analysis'])
            config_content = replace_config_value(config_content, 'SHOW_DATA_ANALYSIS_DETAILS', show_details, is_string=False)
        
        # Reemplazar FEATURE_COLUMNS (selected_features)
        if 'selected_features' in self.config_values and self.config_values['selected_features']:
            features_list = self.config_values['selected_features']
            features_str = '[' + ', '.join([f"'{f}'" for f in features_list]) + ']'
            config_content = replace_config_value(config_content, 'FEATURE_COLUMNS', features_str, is_string=False, is_list=True)
            
            # TambiÃ©n actualizar las listas de tipos de caracterÃ­sticas para que solo contengan las seleccionadas
            # Esto es necesario para que la validaciÃ³n de Config.validate() pase
            # ES: Leer las listas originales de config.py para determinar el tipo de cada caracterÃ­stica
            # EN: Read the original lists from config.py to determine each feature's type
            # JP: å„ç‰¹å¾´é‡ã®ã‚¿ã‚¤ãƒ—åˆ¤å®šã®ãŸã‚ã€å…ƒã®config.pyã®ãƒªã‚¹ãƒˆã‚’èª­ã‚€
            from config import Config as OriginalConfig
            
            # Filtrar cada lista de tipos para que solo contenga caracterÃ­sticas seleccionadas
            continuous_selected = [f for f in OriginalConfig.CONTINUOUS_FEATURES if f in features_list]
            discrete_selected = [f for f in OriginalConfig.DISCRETE_FEATURES if f in features_list]
            binary_selected = [f for f in OriginalConfig.BINARY_FEATURES if f in features_list]
            integer_selected = [f for f in OriginalConfig.INTEGER_FEATURES if f in features_list]
            
            print(f"ğŸ” é¸æŠã—ãŸç‰¹å¾´é‡: {features_list}")
            print(f"ğŸ” CONTINUOUS_FEATURES filtradas: {continuous_selected}")
            print(f"ğŸ” DISCRETE_FEATURES filtradas: {discrete_selected}")
            print(f"ğŸ” BINARY_FEATURES filtradas: {binary_selected}")
            print(f"ğŸ” INTEGER_FEATURES filtradas: {integer_selected}")
            
            # Reemplazar las listas de tipos
            if continuous_selected:
                continuous_str = '[' + ', '.join([f"'{f}'" for f in continuous_selected]) + ']'
                config_content = replace_config_value(config_content, 'CONTINUOUS_FEATURES', continuous_str, is_string=False, is_list=True)
            else:
                continuous_str = '[]'
                config_content = replace_config_value(config_content, 'CONTINUOUS_FEATURES', continuous_str, is_string=False, is_list=True)
            
            if discrete_selected:
                discrete_str = '[' + ', '.join([f"'{f}'" for f in discrete_selected]) + ']'
                config_content = replace_config_value(config_content, 'DISCRETE_FEATURES', discrete_str, is_string=False, is_list=True)
            else:
                discrete_str = '[]'
                config_content = replace_config_value(config_content, 'DISCRETE_FEATURES', discrete_str, is_string=False, is_list=True)
            
            if binary_selected:
                binary_str = '[' + ', '.join([f"'{f}'" for f in binary_selected]) + ']'
                config_content = replace_config_value(config_content, 'BINARY_FEATURES', binary_str, is_string=False, is_list=True)
            else:
                binary_str = '[]'
                config_content = replace_config_value(config_content, 'BINARY_FEATURES', binary_str, is_string=False, is_list=True)
            
            if integer_selected:
                integer_str = '[' + ', '.join([f"'{f}'" for f in integer_selected]) + ']'
                config_content = replace_config_value(config_content, 'INTEGER_FEATURES', integer_str, is_string=False, is_list=True)
            else:
                integer_str = '[]'
                config_content = replace_config_value(config_content, 'INTEGER_FEATURES', integer_str, is_string=False, is_list=True)
        
        # Reemplazar TARGET_COLUMNS si estÃ¡ en config_values
        if 'TARGET_COLUMNS' in self.config_values and self.config_values['TARGET_COLUMNS']:
            targets_list = self.config_values['TARGET_COLUMNS']
            if isinstance(targets_list, list):
                targets_str = '[' + ', '.join([f"'{t}'" for t in targets_list]) + ']'
                config_content = replace_config_value(config_content, 'TARGET_COLUMNS', targets_str, is_string=False, is_list=True)
        
        # Reemplazar MANDATORY_FEATURES
        # Si hay caracterÃ­sticas seleccionadas, filtrar MANDATORY_FEATURES para que solo contenga las seleccionadas
        if 'selected_features' in self.config_values and self.config_values['selected_features']:
            features_list = self.config_values['selected_features']
            # ES: Leer MANDATORY_FEATURES original de config.py
            # EN: Read the original MANDATORY_FEATURES from config.py
            # JP: å…ƒã®config.pyã®MANDATORY_FEATURESã‚’èª­ã‚€
            from config import Config as OriginalConfig
            # Filtrar MANDATORY_FEATURES para que solo contenga caracterÃ­sticas seleccionadas
            mandatory_filtered = [f for f in OriginalConfig.MANDATORY_FEATURES if f in features_list]
            if mandatory_filtered:
                mandatory_str = '[' + ', '.join([f"'{m}'" for m in mandatory_filtered]) + ']'
                config_content = replace_config_value(config_content, 'MANDATORY_FEATURES', mandatory_str, is_string=False, is_list=True)
                print(f"ğŸ” MANDATORY_FEATURES filtradas: {mandatory_filtered}")
            else:
                # Si no hay caracterÃ­sticas obligatorias seleccionadas, dejar la lista vacÃ­a
                mandatory_str = '[]'
                config_content = replace_config_value(config_content, 'MANDATORY_FEATURES', mandatory_str, is_string=False, is_list=True)
                print(f"ğŸ” MANDATORY_FEATURES ãŒç©ºã§ã™ï¼ˆå¿…é ˆç‰¹å¾´é‡ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼‰")
        elif 'MANDATORY_FEATURES' in self.config_values and self.config_values['MANDATORY_FEATURES']:
            # Si se proporciona explÃ­citamente en config_values, usarlo
            mandatory_list = self.config_values['MANDATORY_FEATURES']
            if isinstance(mandatory_list, list):
                mandatory_str = '[' + ', '.join([f"'{m}'" for m in mandatory_list]) + ']'
                config_content = replace_config_value(config_content, 'MANDATORY_FEATURES', mandatory_str, is_string=False, is_list=True)
        
        # Reemplazar PARETO_OBJECTIVES si estÃ¡ en config_values
        if 'pareto_objectives' in self.config_values and self.config_values['pareto_objectives']:
            pareto_dict = self.config_values['pareto_objectives']
            if isinstance(pareto_dict, dict):
                # Formatear como diccionario Python vÃ¡lido, una lÃ­nea por item
                pareto_lines = [f"'{k}': '{v}'," for k, v in pareto_dict.items()]
                pareto_str = '\n'.join(pareto_lines)
                config_content = replace_config_value(config_content, 'PARETO_OBJECTIVES', pareto_str, is_string=False, is_dict=True)
        
        # ES: Agregar comentario al inicio indicando que es un archivo generado
        # EN: Add a header comment indicating this file is generated
        # JP: ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ãƒ˜ãƒƒãƒ€ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
        header_comment = "# ConfiguraciÃ³n personalizada para anÃ¡lisis no lineal\n# Generado automÃ¡ticamente - Basado en config.py\n# Solo se modifican los valores configurados desde la UI\n\n"
        
        # ES: Verificar si ya tiene el comentario
        # EN: Check whether it already has the header comment
        # JP: æ—¢ã«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹ã‹ç¢ºèª
        if not config_content.startswith("# ConfiguraciÃ³n personalizada"):
            config_content = header_comment + config_content
        
        # ES: Escribir archivo
        # EN: Write file
        # JP: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€
        with open(config_file_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        print(f"âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {config_file_path}")
        
        # ES: Debug: Verificar que N_TRIALS estÃ¡ en el archivo guardado
        # EN: Debug: Verify N_TRIALS is present in the saved file
        # JP: Debug: ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã«N_TRIALSãŒå«ã¾ã‚Œã‚‹ã‹ç¢ºèª
        if 'N_TRIALS' in config_content:
            # ES: Buscar la lÃ­nea de N_TRIALS
            # EN: Find the N_TRIALS line
            # JP: N_TRIALSã®è¡Œã‚’æ¢ã™
            for line in config_content.split('\n'):
                if 'N_TRIALS' in line and '=' in line:
                    print(f"ğŸ” config_custom.py ã® N_TRIALS è¡Œ: {line.strip()}")
                    break
        else:
            print(f"âš ï¸ è­¦å‘Š: ä¿å­˜å¾Œã® config_custom.py ã« N_TRIALS ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    def _find_graphs(self, output_folder):
        """ES: Busca grÃ¡ficos generados en la carpeta de salida
        EN: Search for generated graphs in the output folder
        JA: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”Ÿæˆã‚°ãƒ©ãƒ•ã‚’æ¤œç´¢"""
        graph_paths = []
        
        # ES: Buscar en subcarpetas comunes
        # EN: Search in common subfolders
        # JP: ã‚ˆãã‚ã‚‹ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã‚’æ¤œç´¢
        search_folders = [
            os.path.join(output_folder, "03_å­¦ç¿’çµæœ"),
            output_folder
        ]
        
        image_extensions = ['.png', '.jpg', '.jpeg', '.svg', '.pdf']
        
        for folder in search_folders:
            if os.path.exists(folder):
                for root, dirs, files in os.walk(folder):
                    for file in files:
                        if any(file.lower().endswith(ext) for ext in image_extensions):
                            full_path = os.path.join(root, file)
                            graph_paths.append(full_path)
        
        # Ordenar por nombre
        graph_paths.sort()
        
        print(f"ğŸ“Š ã‚°ãƒ©ãƒ•ã‚’ {len(graph_paths)} ä»¶æ¤œå‡º")
        return graph_paths
    
    def _save_analysis_results_json(self):
        """
        Guarda los datos de resultados del anÃ¡lisis en un archivo JSON
        para facilitar la lectura posterior
        """
        try:
            # ES: Ruta donde guardar el JSON (directamente en la carpeta de resultados)
            # EN: Path to save the JSON (directly in the results folder)
            # JP: JSONä¿å­˜å…ˆï¼ˆçµæœãƒ•ã‚©ãƒ«ãƒ€ç›´ä¸‹ï¼‰
            result_folder = os.path.join(self.output_folder, '03_å­¦ç¿’çµæœ')
            
            if not os.path.exists(result_folder):
                print(f"âš ï¸ çµæœãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result_folder}")
                return
            
            json_path = os.path.join(result_folder, 'analysis_results.json')
            
            # Extraer datos del DataFrame filtrado
            data_count = len(self.filtered_df) if self.filtered_df is not None else 0
            
            # Calcular data_range (min y max de columnas numÃ©ricas)
            data_range = "N/A"
            if self.filtered_df is not None and len(self.filtered_df) > 0:
                numeric_cols = self.filtered_df.select_dtypes(include=['number']).columns
                if len(numeric_cols) > 0:
                    df_numeric = self.filtered_df[numeric_cols]
                    min_vals = df_numeric.min()
                    max_vals = df_numeric.max()
                    # ES: Crear string con rango de algunas columnas principales
                    # EN: Build a range string for some main columns
                    # JP: ä¸»ãªåˆ—ã®ç¯„å›²æ–‡å­—åˆ—ã‚’ä½œã‚‹
                    range_parts = []
                    for col in numeric_cols[:5]:  # Primeras 5 columnas numÃ©ricas
                        range_parts.append(f"{col}: [{min_vals[col]:.2f}, {max_vals[col]:.2f}]")
                    data_range = "; ".join(range_parts)
                    if len(numeric_cols) > 5:
                        data_range += f" ... (+{len(numeric_cols) - 5} mÃ¡s)"
            
            # Obtener filters_applied desde config_values
            # ES: Guardar como lista para que pueda ser leÃ­da despuÃ©s
            # EN: Save as a list so it can be read later
            # JP: å¾Œã§èª­ã‚ã‚‹ã‚ˆã†ãƒªã‚¹ãƒˆã¨ã—ã¦ä¿å­˜
            filters_applied = self.config_values.get('filters_applied', [])
            if not filters_applied or filters_applied == []:
                filters_applied = []
            
            # ES: Extraer informaciÃ³n de modelos y mÃ©tricas CV desde dcv_results.pkl
            # EN: Extract model info and CV metrics from dcv_results.pkl
            # JP: dcv_results.pklã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã¨CVæŒ‡æ¨™ã‚’æŠ½å‡º
            # dcv_results.pkl estÃ¡ directamente en 03_å­¦ç¿’çµæœ (sin subcarpeta)
            models_trained = 0
            models = {}
            pickle_path = os.path.join(result_folder, 'dcv_results.pkl')
            
            if os.path.exists(pickle_path):
                try:
                    import pickle
                    import numpy as np
                    with open(pickle_path, 'rb') as f:
                        pickle_data = pickle.load(f)
                    
                    # La estructura de dcv_results.pkl es un diccionario donde las claves son los nombres de los targets
                    # Cada valor es un diccionario con los resultados del DCV para ese target
                    if isinstance(pickle_data, dict):
                        # Iterar sobre cada target (æ‘©è€—é‡, ä¸Šé¢ãƒ€ãƒ¬é‡, å´é¢ãƒ€ãƒ¬é‡)
                        for target_name, result_data in pickle_data.items():
                            if isinstance(result_data, dict):
                                # ES: Extraer informaciÃ³n del modelo
                                # EN: Extract model information
                                # JP: ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’æŠ½å‡º
                                model_entry = {
                                    'model_name': result_data.get('final_model_name', 'Unknown'),
                                    'target_name': target_name
                                }
                                
                                # Extraer mÃ©tricas CV (estas son las mÃ©tricas principales)
                                cv_mae = result_data.get('cv_mae')
                                cv_rmse = result_data.get('cv_rmse')
                                cv_r2 = result_data.get('cv_r2')
                                
                                # Convertir a float si es necesario (puede ser numpy scalar o None)
                                def safe_float(value):
                                    if value is None:
                                        return None
                                    if isinstance(value, (int, float)):
                                        return float(value)
                                    if hasattr(value, 'item'):
                                        try:
                                            return float(value.item())
                                        except:
                                            return None
                                    try:
                                        return float(value)
                                    except:
                                        return None
                                
                                model_entry['cv_mae'] = safe_float(cv_mae)
                                model_entry['cv_rmse'] = safe_float(cv_rmse)
                                model_entry['cv_r2'] = safe_float(cv_r2)
                                
                                # ES: Extraer parÃ¡metros del modelo
                                # EN: Extract model parameters
                                # JP: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                                best_params = result_data.get('best_params', {})
                                if best_params:
                                    # Convertir parÃ¡metros a tipos bÃ¡sicos
                                    clean_params = {}
                                    for param_name, param_value in best_params.items():
                                        if isinstance(param_value, (int, float, str, bool, type(None))):
                                            clean_params[param_name] = param_value
                                        elif hasattr(param_value, 'item'):
                                            try:
                                                clean_params[param_name] = float(param_value.item())
                                            except:
                                                clean_params[param_name] = str(param_value)
                                        else:
                                            clean_params[param_name] = str(param_value)
                                    model_entry['best_params'] = clean_params
                                
                                # ES: Extraer informaciÃ³n de fold_results si estÃ¡ disponible
                                # EN: Extract fold_results information if available
                                # JP: fold_resultsãŒã‚ã‚Œã°æƒ…å ±ã‚’æŠ½å‡º
                                fold_results = result_data.get('fold_results', [])
                                if fold_results:
                                    # Calcular estadÃ­sticas de los folds
                                    fold_maes = [fr.get('mae') for fr in fold_results if fr.get('mae') is not None]
                                    fold_rmses = [fr.get('rmse') for fr in fold_results if fr.get('rmse') is not None]
                                    fold_r2s = [fr.get('r2') for fr in fold_results if fr.get('r2') is not None]
                                    
                                    if fold_maes:
                                        model_entry['fold_mae_mean'] = safe_float(np.mean(fold_maes))
                                        model_entry['fold_mae_std'] = safe_float(np.std(fold_maes))
                                    if fold_rmses:
                                        model_entry['fold_rmse_mean'] = safe_float(np.mean(fold_rmses))
                                        model_entry['fold_rmse_std'] = safe_float(np.std(fold_rmses))
                                    if fold_r2s:
                                        model_entry['fold_r2_mean'] = safe_float(np.mean(fold_r2s))
                                        model_entry['fold_r2_std'] = safe_float(np.std(fold_r2s))
                                
                                models[target_name] = model_entry
                                models_trained += 1
                                
                        print(f"âœ… dcv_results.pkl ã‹ã‚‰ CV æŒ‡æ¨™ä»˜ããƒ¢ãƒ‡ãƒ«ã‚’ {models_trained} ä»¶æŠ½å‡ºã—ã¾ã—ãŸ")
                except Exception as e:
                    print(f"âš ï¸ dcv_results.pkl ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¢ãƒ‡ãƒ«æŠ½å‡ºï¼‰: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ES: Calcular tiempo de anÃ¡lisis (si estÃ¡ disponible)
            # EN: Compute analysis duration (if available)
            # JP: è§£ææ™‚é–“ã‚’è¨ˆç®—ï¼ˆåˆ©ç”¨å¯èƒ½ãªã‚‰ï¼‰
            analysis_duration = getattr(self, 'analysis_duration', None)
            if analysis_duration is not None:
                # Convertir a formato legible (horas:minutos:segundos)
                hours = int(analysis_duration // 3600)
                minutes = int((analysis_duration % 3600) // 60)
                seconds = int(analysis_duration % 60)
                milliseconds = int((analysis_duration % 1) * 1000)
                
                if hours > 0:
                    duration_str = f"{hours}æ™‚é–“{minutes}åˆ†{seconds}ç§’"
                elif minutes > 0:
                    duration_str = f"{minutes}åˆ†{seconds}ç§’"
                else:
                    duration_str = f"{seconds}.{milliseconds:03d}ç§’"
                
                analysis_duration_seconds = round(analysis_duration, 3)
            else:
                duration_str = "N/A"
                analysis_duration_seconds = None
            
            # ES: Crear diccionario con los datos
            # EN: Build a dictionary with the data
            # JP: ãƒ‡ãƒ¼ã‚¿è¾æ›¸ã‚’ä½œæˆ
            results_data = {
                'data_count': data_count,
                'models_trained': models_trained,
                'filters_applied': filters_applied if filters_applied else [],
                'data_range': data_range,
                'output_folder': self.output_folder,
                'models': models if models else {},
                'analysis_duration_seconds': analysis_duration_seconds,
                'analysis_duration_formatted': duration_str
            }
            
            # ES: Guardar en JSON
            # EN: Save as JSON
            # JP: JSONã¨ã—ã¦ä¿å­˜
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"âœ… è§£æãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {json_path}")
            
        except Exception as e:
            print(f"âš ï¸ è§£æãƒ‡ãƒ¼ã‚¿ã®JSONä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
