"""
Script de diagn√≥stico para verificar si los modelos se entrenaron correctamente
"""
import os
import sys
from pathlib import Path
import pandas as pd
import glob

# Agregar rutas al path
PROJECT_ROOT = Path.cwd()
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

PYTHON_CODE_FOLDER = PROJECT_ROOT / "00_Python„Ç≥„Éº„Éâ"
if str(PYTHON_CODE_FOLDER) not in sys.path:
    sys.path.insert(0, str(PYTHON_CODE_FOLDER))

from config import Config

def find_prediction_files():
    """
    Busca archivos Prediction_output.xlsx en la estructura de an√°lisis no lineal.
    La estructura es: output_folder/ÂõûÂ∏∞_0817_DCV_shap/ (donde est√°n los gr√°ficos)
    y el archivo de predicci√≥n est√° en: output_folder/03_‰∫àÊ∏¨/Prediction_output.xlsx
    """
    prediction_files = []
    current_dir = Path.cwd()
    
    print(f"   üîç Buscando desde: {current_dir}", flush=True)
    
    # Buscar todas las carpetas que contengan ÂõûÂ∏∞_0817_DCV_shap
    # Esta es la carpeta donde est√°n los gr√°ficos del an√°lisis no lineal
    regression_folders = []
    
    # Buscar en el directorio actual y subdirectorios
    for pattern in ["**/ÂõûÂ∏∞_0817_DCV_shap", "ÂõûÂ∏∞_0817_DCV_shap"]:
        found = list(current_dir.glob(pattern))
        regression_folders.extend(found)
    
    # Tambi√©n buscar en subdirectorios comunes
    common_bases = [
        current_dir,
        current_dir / "Archivos_de_salida",
        current_dir.parent / "Archivos_de_salida",
    ]
    
    for base in common_bases:
        if base.exists():
            for pattern in ["**/ÂõûÂ∏∞_0817_DCV_shap", "**/04_ÈùûÁ∑öÂΩ¢ÂõûÂ∏∞/**/ÂõûÂ∏∞_0817_DCV_shap"]:
                found = list(base.glob(pattern))
                regression_folders.extend(found)
    
    # Eliminar duplicados
    regression_folders = list(set(regression_folders))
    
    print(f"   üìÅ Carpetas ÂõûÂ∏∞_0817_DCV_shap encontradas: {len(regression_folders)}", flush=True)
    
    for reg_folder in regression_folders:
        reg_path = Path(reg_folder)
        # El working_dir es el padre de ÂõûÂ∏∞_0817_DCV_shap
        working_dir = reg_path.parent
        # El archivo de predicci√≥n est√° en working_dir/03_‰∫àÊ∏¨/Prediction_output.xlsx
        prediction_path = working_dir / "03_‰∫àÊ∏¨" / "Prediction_output.xlsx"
        if prediction_path.exists():
            prediction_files.append(str(prediction_path))
            print(f"      ‚úÖ Encontrado: {prediction_path}", flush=True)
        else:
            print(f"      ‚ö†Ô∏è No encontrado en: {prediction_path}", flush=True)
    
    # Tambi√©n buscar directamente
    search_patterns = [
        "**/03_‰∫àÊ∏¨/Prediction_output.xlsx"
    ]
    
    for pattern in search_patterns:
        files = list(current_dir.glob(pattern))
        for f in files:
            if str(f) not in prediction_files:
                prediction_files.append(str(f))
                print(f"      ‚úÖ Encontrado (b√∫squeda directa): {f}", flush=True)
    
    # Eliminar duplicados y ordenar
    return sorted(set(prediction_files))

def check_models(prediction_path=None):
    """Verifica si los modelos est√°n entrenados y disponibles"""
    print("=" * 80, flush=True)
    print("üîç DIAGN√ìSTICO DE MODELOS", flush=True)
    print("=" * 80, flush=True)
    
    # 1. Verificar configuraci√≥n
    print("\nüìã CONFIGURACI√ìN:")
    print(f"   TARGET_COLUMNS: {Config.TARGET_COLUMNS}")
    print(f"   MODEL_FOLDER: {Config.MODEL_FOLDER}")
    print(f"   FINAL_MODEL_PREFIX: {Config.FINAL_MODEL_PREFIX}")
    print(f"   PREDICTION_COLUMN_PREFIX: {Config.PREDICTION_COLUMN_PREFIX}")
    
    # 2. Verificar archivos de modelo
    print("\nüì¶ ARCHIVOS DE MODELO:")
    
    # Si tenemos una ruta de predicci√≥n, buscar modelos en la misma estructura
    model_search_paths = []
    if prediction_path:
        pred_path = Path(prediction_path)
        # El working_dir es el padre de 03_‰∫àÊ∏¨
        working_dir = pred_path.parent.parent
        model_folder_in_working = working_dir / Config.MODEL_FOLDER
        if model_folder_in_working.exists():
            model_search_paths.append(model_folder_in_working)
    
    # Tambi√©n buscar en la ruta por defecto
    default_model_folder = Path(Config.MODEL_FOLDER)
    if default_model_folder.exists():
        model_search_paths.append(default_model_folder)
    
    # Si no hay rutas, usar la ruta por defecto aunque no exista
    if not model_search_paths:
        model_search_paths.append(default_model_folder)
    
    model_files = {}
    for target in Config.TARGET_COLUMNS:
        model_filename = f"{Config.FINAL_MODEL_PREFIX}_{target}.pkl"
        found = False
        
        for model_folder_path in model_search_paths:
            model_path = model_folder_path / model_filename
            if model_path.exists():
                model_files[target] = {
                    'exists': True,
                    'path': str(model_path)
                }
                found = True
                status = "‚úÖ"
                print(f"   {status} {target}: {model_path}")
                size = model_path.stat().st_size / (1024 * 1024)  # MB
                print(f"      Tama√±o: {size:.2f} MB")
                break
        
        if not found:
            model_files[target] = {
                'exists': False,
                'path': str(model_search_paths[0] / model_filename)
            }
            status = "‚ùå"
            print(f"   {status} {target}: {model_search_paths[0] / model_filename}")
    
    # 3. Verificar archivo de predicci√≥n
    print("\nüìä ARCHIVO DE PREDICCI√ìN:")
    
    # Si no se proporciona una ruta, buscar archivos
    if prediction_path is None:
        print(f"   üîç Buscando archivos de predicci√≥n en estructura de an√°lisis no lineal...")
        prediction_files = find_prediction_files()
        if prediction_files:
            print(f"   ‚úÖ Se encontraron {len(prediction_files)} archivo(s) de predicci√≥n:")
            for i, pf in enumerate(prediction_files, 1):
                # Mostrar tambi√©n la carpeta de gr√°ficos asociada
                pf_path = Path(pf)
                graphics_folder = pf_path.parent.parent / "ÂõûÂ∏∞_0817_DCV_shap"
                if graphics_folder.exists():
                    print(f"      {i}. {pf}")
                    print(f"         üìÅ Carpeta de gr√°ficos: {graphics_folder}")
                else:
                    print(f"      {i}. {pf}")
            prediction_path = prediction_files[0]  # Usar el primero
            print(f"\n   üìÅ Analizando: {prediction_path}")
        else:
            # Intentar con la ruta por defecto
            prediction_folder = Config.PREDICTION_FOLDER
            prediction_file = Config.PREDICTION_OUTPUT_FILE
            prediction_path = os.path.join(prediction_folder, prediction_file)
            print(f"   ‚ö†Ô∏è No se encontraron archivos en estructura de an√°lisis no lineal")
            print(f"   üîç Intentando ruta por defecto: {prediction_path}")
    
    if os.path.exists(prediction_path):
        print(f"   ‚úÖ Archivo encontrado: {prediction_path}")
        
        try:
            df = pd.read_excel(prediction_path)
            print(f"   üìê Dimensiones: {df.shape[0]} filas √ó {df.shape[1]} columnas")
            
            print(f"\n   üìã COLUMNAS ENCONTRADAS:")
            for col in df.columns:
                print(f"      - {col}")
            
            # Verificar columnas de predicci√≥n
            print(f"\n   üéØ COLUMNAS DE PREDICCI√ìN ESPERADAS:")
            expected_cols = []
            for target in Config.TARGET_COLUMNS:
                pred_col = f"{Config.PREDICTION_COLUMN_PREFIX}_{target}"
                expected_cols.append(pred_col)
                exists = pred_col in df.columns
                status = "‚úÖ" if exists else "‚ùå"
                print(f"      {status} {pred_col}")
            
            # Verificar ÂàáÂâäÊôÇÈñì
            cutting_time_col = Config.CUTTING_TIME_COLUMN_NAME
            print(f"\n   ‚è±Ô∏è COLUMNA DE TIEMPO DE CORTE:")
            exists = cutting_time_col in df.columns
            status = "‚úÖ" if exists else "‚ùå"
            print(f"      {status} {cutting_time_col}")
            
            # Resumen
            print(f"\n   üìä RESUMEN:")
            found_pred_cols = sum(1 for col in expected_cols if col in df.columns)
            print(f"      Columnas de predicci√≥n encontradas: {found_pred_cols}/{len(expected_cols)}")
            print(f"      Columna ÂàáÂâäÊôÇÈñì encontrada: {'S√≠' if cutting_time_col in df.columns else 'No'}")
            
            # Verificar para Pareto
            print(f"\n   üéØ VERIFICACI√ìN PARA PARETO:")
            pareto_objectives = Config.PARETO_OBJECTIVES
            print(f"      Objetivos de Pareto configurados: {list(pareto_objectives.keys())}")
            
            pareto_found = []
            pareto_missing = []
            
            for obj_name in pareto_objectives.keys():
                # Para ÂàáÂâäÊôÇÈñì, buscar directamente
                if obj_name == Config.CUTTING_TIME_COLUMN_NAME:
                    if obj_name in df.columns:
                        pareto_found.append(obj_name)
                    else:
                        pareto_missing.append(obj_name)
                else:
                    # Para otros, buscar con prefijo prediction_
                    pred_col = f"{Config.PREDICTION_COLUMN_PREFIX}_{obj_name}"
                    if pred_col in df.columns:
                        pareto_found.append(obj_name)
                    elif obj_name in df.columns:
                        pareto_found.append(obj_name)
                    else:
                        pareto_missing.append(obj_name)
            
            print(f"      ‚úÖ Objetivos encontrados ({len(pareto_found)}): {pareto_found}")
            if pareto_missing:
                print(f"      ‚ùå Objetivos faltantes ({len(pareto_missing)}): {pareto_missing}")
            
            if len(pareto_found) < 2:
                print(f"\n   ‚ö†Ô∏è ADVERTENCIA: Solo se encontraron {len(pareto_found)} objetivos de Pareto.")
                print(f"      Se necesitan al menos 2 para el an√°lisis de Pareto.")
            else:
                print(f"\n   ‚úÖ OK: Se encontraron {len(pareto_found)} objetivos de Pareto (suficiente para an√°lisis)")
                
        except Exception as e:
            print(f"   ‚ùå Error leyendo el archivo: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"   ‚ùå Archivo NO encontrado: {prediction_path}")
    
    # 4. Resumen final
    print("\n" + "=" * 80)
    print("üìä RESUMEN FINAL")
    print("=" * 80)
    
    models_ok = sum(1 for info in model_files.values() if info['exists'])
    print(f"   Modelos encontrados: {models_ok}/{len(Config.TARGET_COLUMNS)}")
    
    if models_ok == len(Config.TARGET_COLUMNS):
        print("   ‚úÖ Todos los modelos est√°n disponibles")
    else:
        print("   ‚ö†Ô∏è Faltan algunos modelos")
        for target, info in model_files.items():
            if not info['exists']:
                print(f"      ‚ùå Falta: {target}")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    try:
        import argparse
        parser = argparse.ArgumentParser(description='Verificar modelos entrenados')
        parser.add_argument('--prediction-file', type=str, help='Ruta al archivo Prediction_output.xlsx')
        args = parser.parse_args()
        
        check_models(prediction_path=args.prediction_file)
    except Exception as e:
        print(f"‚ùå Error ejecutando script: {e}")
        import traceback
        traceback.print_exc()

