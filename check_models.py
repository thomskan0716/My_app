"""
Script de diagnÃ³stico para verificar si los modelos se entrenaron correctamente
"""
import os
import sys
from pathlib import Path
import pandas as pd
import glob

# ES: Agregar rutas al path | EN: Add paths to sys.path | JA: sys.path ã«ãƒ‘ã‚¹ã‚’è¿½åŠ 
PROJECT_ROOT = Path.cwd()
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

PYTHON_CODE_FOLDER = PROJECT_ROOT / "00_Pythonã‚³ãƒ¼ãƒ‰"
if str(PYTHON_CODE_FOLDER) not in sys.path:
    sys.path.insert(0, str(PYTHON_CODE_FOLDER))

from config import Config

def find_prediction_files():
    """
    Busca archivos Prediction_output.xlsx en la estructura de anÃ¡lisis no lineal.
    La estructura es: output_folder/å›å¸°_0817_DCV_shap/ (donde estÃ¡n los grÃ¡ficos)
    y el archivo de predicciÃ³n estÃ¡ en: output_folder/03_äºˆæ¸¬/Prediction_output.xlsx
    """
    prediction_files = []
    current_dir = Path.cwd()
    
    print(f"   ğŸ” æ¤œç´¢é–‹å§‹: {current_dir}", flush=True)
    
    # ES: Buscar todas las carpetas que contengan å›å¸°_0817_DCV_shap
    # EN: Find all folders containing å›å¸°_0817_DCV_shap
    # JA: å›å¸°_0817_DCV_shap ã‚’å«ã‚€ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ç´¢
    # ES: Esta es la carpeta donde estÃ¡n los grÃ¡ficos del anÃ¡lisis no lineal
    # EN: This is the folder where non-linear analysis graphs are stored
    # JA: éç·šå½¢è§£æã®ã‚°ãƒ©ãƒ•ãŒä¿å­˜ã•ã‚Œã‚‹ãƒ•ã‚©ãƒ«ãƒ€
    regression_folders = []
    
    # ES: Buscar en el directorio actual y subdirectorios | EN: Search current directory and subdirectories | JA: ç¾åœ¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
    for pattern in ["**/å›å¸°_0817_DCV_shap", "å›å¸°_0817_DCV_shap"]:
        found = list(current_dir.glob(pattern))
        regression_folders.extend(found)
    
    # ES: TambiÃ©n buscar en subdirectorios comunes | EN: Also search common base directories | JA: ã‚ˆãã‚ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚æ¢ç´¢
    common_bases = [
        current_dir,
        current_dir / "Archivos_de_salida",
        current_dir.parent / "Archivos_de_salida",
    ]
    
    for base in common_bases:
        if base.exists():
            for pattern in ["**/å›å¸°_0817_DCV_shap", "**/04_éç·šå½¢å›å¸°/**/å›å¸°_0817_DCV_shap"]:
                found = list(base.glob(pattern))
                regression_folders.extend(found)
    
    # ES: Eliminar duplicados | EN: Remove duplicates | JA: é‡è¤‡ã‚’é™¤å»
    regression_folders = list(set(regression_folders))
    
    print(f"   ğŸ“ å›å¸°_0817_DCV_shap ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼æ•°: {len(regression_folders)}", flush=True)
    
    for reg_folder in regression_folders:
        reg_path = Path(reg_folder)
        # ES: El working_dir es el padre de å›å¸°_0817_DCV_shap
        # EN: working_dir is the parent folder of å›å¸°_0817_DCV_shap
        # JA: working_dir ã¯ å›å¸°_0817_DCV_shap ã®è¦ªãƒ•ã‚©ãƒ«ãƒ€
        working_dir = reg_path.parent
        # ES: El archivo de predicciÃ³n estÃ¡ en working_dir/03_äºˆæ¸¬/Prediction_output.xlsx
        # EN: The prediction file is at working_dir/03_äºˆæ¸¬/Prediction_output.xlsx
        # JA: äºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«ã¯ working_dir/03_äºˆæ¸¬/Prediction_output.xlsx
        prediction_path = working_dir / "03_äºˆæ¸¬" / "Prediction_output.xlsx"
        if prediction_path.exists():
            prediction_files.append(str(prediction_path))
            print(f"      âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {prediction_path}", flush=True)
        else:
            print(f"      âš ï¸ è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prediction_path}", flush=True)
    
    # ES: TambiÃ©n buscar directamente | EN: Also search directly | JA: ç›´æ¥æ¢ç´¢ã‚‚è¡Œã†
    search_patterns = [
        "**/03_äºˆæ¸¬/Prediction_output.xlsx"
    ]
    
    for pattern in search_patterns:
        files = list(current_dir.glob(pattern))
        for f in files:
            if str(f) not in prediction_files:
                prediction_files.append(str(f))
                print(f"      âœ… è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆç›´æ¥æ¤œç´¢ï¼‰: {f}", flush=True)
    
    # ES: Eliminar duplicados y ordenar | EN: De-duplicate and sort | JA: é‡è¤‡æ’é™¤ã—ã¦ã‚½ãƒ¼ãƒˆ
    return sorted(set(prediction_files))

def check_models(prediction_path=None):
    """ES: Verifica si los modelos estÃ¡n entrenados y disponibles
    EN: Check if models are trained and available
    JA: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æ¸ˆã¿ã§åˆ©ç”¨å¯èƒ½ã‹ç¢ºèª"""
    print("=" * 80, flush=True)
    print("ğŸ” ãƒ¢ãƒ‡ãƒ«è¨ºæ–­", flush=True)
    print("=" * 80, flush=True)
    
    # ES: 1. Verificar configuraciÃ³n | EN: 1) Check configuration | JA: 1) è¨­å®šã‚’ç¢ºèª
    print("\nğŸ“‹ è¨­å®š:")
    print(f"   TARGET_COLUMNS: {Config.TARGET_COLUMNS}")
    print(f"   MODEL_FOLDER: {Config.MODEL_FOLDER}")
    print(f"   FINAL_MODEL_PREFIX: {Config.FINAL_MODEL_PREFIX}")
    print(f"   PREDICTION_COLUMN_PREFIX: {Config.PREDICTION_COLUMN_PREFIX}")
    
    # ES: 2. Verificar archivos de modelo | EN: 2) Check model files | JA: 2) ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
    print("\nğŸ“¦ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«:")
    
    # ES: Si tenemos una ruta de predicciÃ³n, buscar modelos en la misma estructura
    # EN: If a prediction path is provided, search models in the same structure
    # JA: äºˆæ¸¬ãƒ‘ã‚¹ãŒã‚ã‚Œã°åŒã˜æ§‹é€ å†…ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ç´¢
    model_search_paths = []
    if prediction_path:
        pred_path = Path(prediction_path)
        # ES: El working_dir es el padre de 03_äºˆæ¸¬ | EN: working_dir is the parent of 03_äºˆæ¸¬ | JA: working_dir ã¯ 03_äºˆæ¸¬ ã®è¦ª
        working_dir = pred_path.parent.parent
        model_folder_in_working = working_dir / Config.MODEL_FOLDER
        if model_folder_in_working.exists():
            model_search_paths.append(model_folder_in_working)
    
    # ES: TambiÃ©n buscar en la ruta por defecto | EN: Also search the default path | JA: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚‚æ¢ç´¢
    default_model_folder = Path(Config.MODEL_FOLDER)
    if default_model_folder.exists():
        model_search_paths.append(default_model_folder)
    
    # ES: Si no hay rutas, usar la ruta por defecto aunque no exista
    # EN: If no paths were found, fall back to the default path even if it doesn't exist
    # JA: ãƒ‘ã‚¹ãŒç„¡ã‘ã‚Œã°å­˜åœ¨ã—ãªãã¦ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨
    if not model_search_paths:
        model_search_paths.append(default_model_folder)
    
    model_files = {}
    for target in Config.TARGET_COLUMNS:
        model_filename = f"{Config.FINAL_MODEL_PREFIX}_{target}.pkl"
        found = False
        
        for model_folder_path in model_search_paths:
            model_path = model_folder_path / model_filename
            if model_path.exists():
                model_files[target] = {
                    'exists': True,
                    'path': str(model_path)
                }
                found = True
                status = "âœ…"
                print(f"   {status} {target}: {model_path}")
                size = model_path.stat().st_size / (1024 * 1024)  # MB
                print(f"      ã‚µã‚¤ã‚º: {size:.2f} MB")
                break
        
        if not found:
            model_files[target] = {
                'exists': False,
                'path': str(model_search_paths[0] / model_filename)
            }
            status = "âŒ"
            print(f"   {status} {target}: {model_search_paths[0] / model_filename}")
    
    # ES: 3. Verificar archivo de predicciÃ³n
    # EN: 3. Verify prediction file
    # JP: 3. äºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
    print("\nğŸ“Š äºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«:")
    
    # ES: Si no se proporciona una ruta, buscar archivos
    # EN: If no path is provided, search for files
    # JP: ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã™ã‚‹
    if prediction_path is None:
        print(f"   ğŸ” éç·šå½¢è§£ææ§‹é€ å†…ã®äºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
        prediction_files = find_prediction_files()
        if prediction_files:
            print(f"   âœ… äºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {len(prediction_files)} ä»¶è¦‹ã¤ã‘ã¾ã—ãŸ:")
            for i, pf in enumerate(prediction_files, 1):
                # ES: Mostrar tambiÃ©n la carpeta de grÃ¡ficos asociada
                # EN: Also show the associated charts folder
                # JP: é–¢é€£ã™ã‚‹ã‚°ãƒ©ãƒ•ãƒ•ã‚©ãƒ«ãƒ€ã‚‚è¡¨ç¤ºã™ã‚‹
                pf_path = Path(pf)
                graphics_folder = pf_path.parent.parent / "å›å¸°_0817_DCV_shap"
                if graphics_folder.exists():
                    print(f"      {i}. {pf}")
                    print(f"         ğŸ“ ã‚°ãƒ©ãƒ•ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼: {graphics_folder}")
                else:
                    print(f"      {i}. {pf}")
            prediction_path = prediction_files[0]  # Usar el primero
            print(f"\n   ğŸ“ è§£æå¯¾è±¡: {prediction_path}")
        else:
            # ES: Intentar con la ruta por defecto
            # EN: Try the default path
            # JP: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ã‚¹ã‚’è©¦ã™
            prediction_folder = Config.PREDICTION_FOLDER
            prediction_file = Config.PREDICTION_OUTPUT_FILE
            prediction_path = os.path.join(prediction_folder, prediction_file)
            print(f"   âš ï¸ éç·šå½¢è§£ææ§‹é€ å†…ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            print(f"   ğŸ” ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’è©¦è¡Œ: {prediction_path}")
    
    if os.path.exists(prediction_path):
        print(f"   âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ: {prediction_path}")
        
        try:
            df = pd.read_excel(prediction_path)
            print(f"   ğŸ“ å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
            
            print(f"\n   ğŸ“‹ æ¤œå‡ºã—ãŸåˆ—:")
            for col in df.columns:
                print(f"      - {col}")
            
            # ES: Verificar columnas de predicciÃ³n
            # EN: Verify prediction columns
            # JP: äºˆæ¸¬åˆ—ã‚’ç¢ºèªã™ã‚‹
            print(f"\n   ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹äºˆæ¸¬åˆ—:")
            expected_cols = []
            for target in Config.TARGET_COLUMNS:
                pred_col = f"{Config.PREDICTION_COLUMN_PREFIX}_{target}"
                expected_cols.append(pred_col)
                exists = pred_col in df.columns
                status = "âœ…" if exists else "âŒ"
                print(f"      {status} {pred_col}")
            
            # Verificar åˆ‡å‰Šæ™‚é–“
            cutting_time_col = Config.CUTTING_TIME_COLUMN_NAME
            print(f"\n   â±ï¸ åˆ‡å‰Šæ™‚é–“åˆ—:")
            exists = cutting_time_col in df.columns
            status = "âœ…" if exists else "âŒ"
            print(f"      {status} {cutting_time_col}")
            
            # Resumen
            print(f"\n   ğŸ“Š è¦ç´„:")
            found_pred_cols = sum(1 for col in expected_cols if col in df.columns)
            print(f"      äºˆæ¸¬åˆ—ã®æ¤œå‡ºæ•°: {found_pred_cols}/{len(expected_cols)}")
            print(f"      åˆ‡å‰Šæ™‚é–“ åˆ—: {'ã‚ã‚Š' if cutting_time_col in df.columns else 'ãªã—'}")
            
            # ES: Verificar para Pareto
            # EN: Check compatibility for Pareto
            # JP: Paretoç”¨ã®æ•´åˆæ€§ã‚’ç¢ºèªã™ã‚‹
            print(f"\n   ğŸ¯ Pareto ç”¨ã®æ¤œè¨¼:")
            pareto_objectives = Config.PARETO_OBJECTIVES
            print(f"      è¨­å®šã•ã‚ŒãŸ Pareto ç›®çš„: {list(pareto_objectives.keys())}")
            
            pareto_found = []
            pareto_missing = []
            
            for obj_name in pareto_objectives.keys():
                # Para åˆ‡å‰Šæ™‚é–“, buscar directamente
                if obj_name == Config.CUTTING_TIME_COLUMN_NAME:
                    if obj_name in df.columns:
                        pareto_found.append(obj_name)
                    else:
                        pareto_missing.append(obj_name)
                else:
                    # ES: Para otros, buscar con prefijo prediction_
                    # EN: For other objectives, look for the prediction_ prefix
                    # JP: ä»–ã®ç›®çš„å¤‰æ•°ã¯ prediction_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§æ¢ã™
                    pred_col = f"{Config.PREDICTION_COLUMN_PREFIX}_{obj_name}"
                    if pred_col in df.columns:
                        pareto_found.append(obj_name)
                    elif obj_name in df.columns:
                        pareto_found.append(obj_name)
                    else:
                        pareto_missing.append(obj_name)
            
            print(f"      âœ… è¦‹ã¤ã‹ã£ãŸç›®çš„ï¼ˆ{len(pareto_found)}ä»¶ï¼‰: {pareto_found}")
            if pareto_missing:
                print(f"      âŒ è¦‹ã¤ã‹ã‚‰ãªã„ç›®çš„ï¼ˆ{len(pareto_missing)}ä»¶ï¼‰: {pareto_missing}")
            
            if len(pareto_found) < 2:
                print(f"\n   âš ï¸ è­¦å‘Š: Pareto ç›®çš„ãŒ {len(pareto_found)} ä»¶ã—ã‹è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                print(f"      Pareto è§£æã«ã¯å°‘ãªãã¨ã‚‚ 2 ä»¶å¿…è¦ã§ã™ã€‚")
            else:
                print(f"\n   âœ… OK: Pareto ç›®çš„ã‚’ {len(pareto_found)} ä»¶è¦‹ã¤ã‘ã¾ã—ãŸï¼ˆè§£æã«ååˆ†ï¼‰")
                
        except Exception as e:
            print(f"   âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"   âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prediction_path}")
    
    # 4. Resumen final
    print("\n" + "=" * 80)
    print("ğŸ“Š æœ€çµ‚è¦ç´„")
    print("=" * 80)
    
    models_ok = sum(1 for info in model_files.values() if info['exists'])
    print(f"   è¦‹ã¤ã‹ã£ãŸãƒ¢ãƒ‡ãƒ«: {models_ok}/{len(Config.TARGET_COLUMNS)}")
    
    if models_ok == len(Config.TARGET_COLUMNS):
        print("   âœ… ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    else:
        print("   âš ï¸ ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        for target, info in model_files.items():
            if not info['exists']:
                print(f"      âŒ ä¸è¶³: {target}")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    try:
        import argparse
        parser = argparse.ArgumentParser(description='å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª')
        parser.add_argument('--prediction-file', type=str, help='Prediction_output.xlsx ã®ãƒ‘ã‚¹')
        args = parser.parse_args()
        
        check_models(prediction_path=args.prediction_file)
    except Exception as e:
        print(f"âŒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

