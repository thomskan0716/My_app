"""
ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»å¯è¦–åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆã€å‹æƒ…å ±ã€æ¬ æå€¤ã€å¤–ã‚Œå€¤ã€åˆ†å¸ƒã‚’åŒ…æ‹¬çš„ã«åˆ†æãƒ»å¯è¦–åŒ–
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
try:
    import seaborn as sns
    _HAS_SEABORN = True
except Exception:
    _HAS_SEABORN = False

import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆä»–ã§æ—¢ã«è¨­å®šæ¸ˆã¿ãªã‚‰å°Šé‡ï¼‰
if not plt.rcParams.get('font.family'):
    plt.rcParams['font.family'] = ['Yu Gothic']
if 'axes.unicode_minus' not in plt.rcParams or plt.rcParams['axes.unicode_minus'] is None:
    plt.rcParams['axes.unicode_minus'] = False

class DataAnalyzer:
    """ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_folder='./analysis_results'):
        """
        Parameters
        ----------
        output_folder : str
            åˆ†æçµæœã®ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€
        """
        self.output_folder = output_folder
        import os
        os.makedirs(output_folder, exist_ok=True)
    
    def analyze_dataframe(self, df, target_columns=None, feature_columns=None, 
                          show_plots=True, save_plots=True):
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å…¨ä½“ã®åŒ…æ‹¬çš„åˆ†æ
        
        Parameters
        ----------
        df : pd.DataFrame
            åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
        target_columns : list
            ç›®çš„å¤‰æ•°ã®ã‚«ãƒ©ãƒ åãƒªã‚¹ãƒˆ
        feature_columns : list
            èª¬æ˜å¤‰æ•°ã®ã‚«ãƒ©ãƒ åãƒªã‚¹ãƒˆ
        show_plots : bool
            ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ã‹
        save_plots : bool
            ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã‹
            
        Returns
        -------
        dict
            åˆ†æçµæœã®è¾æ›¸
        """
        print("\n" + "="*80)
        print("ãƒ‡ãƒ¼ã‚¿åˆ†æé–‹å§‹")
        print("="*80)
        
        results = {}
        
        # åŸºæœ¬æƒ…å ±
        results['basic_info'] = self._get_basic_info(df)
        self._print_basic_info(results['basic_info'])
        
        # ãƒ‡ãƒ¼ã‚¿å‹åˆ†æ
        results['dtype_info'] = self._analyze_dtypes(df)
        self._print_dtype_info(results['dtype_info'])
        
        # æ¬ æå€¤åˆ†æ
        results['missing_info'] = self._analyze_missing_values(df)
        self._print_missing_info(results['missing_info'])
        
        # çµ±è¨ˆæƒ…å ±
        results['stats_info'] = self._get_statistics(df)
        
        # å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆé€£ç¶šå¤‰æ•°ã®ã¿ï¼‰
        results['outlier_info'] = self._detect_outliers(df)
        self._print_outlier_info(results['outlier_info'])
        
        # å¯è¦–åŒ–
        if show_plots or save_plots:
            self._visualize_overview(df, results, show_plots, save_plots)
            
            # ç›®çš„å¤‰æ•°ã®è©³ç´°åˆ†æ
            if target_columns:
                for target in target_columns:
                    if target in df.columns:
                        self._analyze_target_variable(df[target], target, show_plots, save_plots)
            
            # èª¬æ˜å¤‰æ•°ã®è©³ç´°åˆ†æ
            if feature_columns:
                self._analyze_features(df[feature_columns], show_plots, save_plots)
        
        # ç›¸é–¢åˆ†æï¼ˆæ•°å€¤å¤‰æ•°ã®ã¿ï¼‰
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) > 1:
            results['correlation'] = self._analyze_correlation(df[numeric_cols], show_plots, save_plots)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self._save_report(results)
        
        return results
    
    def _get_basic_info(self, df):
        """åŸºæœ¬æƒ…å ±ã®å–å¾—"""
        return {
            'shape': df.shape,
            'columns': df.columns.tolist(),
            'memory_usage': df.memory_usage(deep=True).sum() / 1024**2,  # MB
            'duplicated_rows': df.duplicated().sum()
        }
    
    def _print_basic_info(self, info):
        """åŸºæœ¬æƒ…å ±ã®è¡¨ç¤º"""
        print(f"\nğŸ“Š åŸºæœ¬æƒ…å ±:")
        print(f"  - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {info['shape'][0]} è¡Œ Ã— {info['shape'][1]} åˆ—")
        print(f"  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {info['memory_usage']:.2f} MB")
        print(f"  - é‡è¤‡è¡Œæ•°: {info['duplicated_rows']}")
    
    def _analyze_dtypes(self, df):
        """ãƒ‡ãƒ¼ã‚¿å‹ã®åˆ†æ"""
        dtype_counts = df.dtypes.value_counts()
        # dtypeå‹ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        dtype_summary = {str(k): int(v) for k, v in dtype_counts.items()}
        
        dtype_details = {}
        
        for col in df.columns:
            dtype_details[col] = {
                'dtype': str(df[col].dtype),
                'unique_values': int(df[col].nunique()),
                'unique_ratio': float(df[col].nunique() / len(df)) if len(df) > 0 else 0
            }
        
        return {
            'summary': dtype_summary,
            'details': dtype_details
        }
    
    def _print_dtype_info(self, info):
        """ãƒ‡ãƒ¼ã‚¿å‹æƒ…å ±ã®è¡¨ç¤º"""
        print(f"\nğŸ”¤ ãƒ‡ãƒ¼ã‚¿å‹åˆ†å¸ƒ:")
        for dtype, count in info['summary'].items():
            print(f"  - {dtype}: {count} åˆ—")
    
    def _analyze_missing_values(self, df):
        """æ¬ æå€¤ã®åˆ†æ"""
        missing_counts = df.isnull().sum()
        missing_ratio = (missing_counts / len(df)) * 100
        
        missing_info = pd.DataFrame({
            'missing_count': missing_counts,
            'missing_ratio': missing_ratio
        })
        missing_info = missing_info[missing_info['missing_count'] > 0].sort_values('missing_count', ascending=False)
        
        return missing_info
    
    def _print_missing_info(self, info):
        """æ¬ æå€¤æƒ…å ±ã®è¡¨ç¤º"""
        if len(info) > 0:
            print(f"\nâš ï¸ æ¬ æå€¤æƒ…å ±:")
            for col, row in info.iterrows():
                print(f"  - {col}: {row['missing_count']:.0f} ({row['missing_ratio']:.1f}%)")
        else:
            print(f"\nâœ… æ¬ æå€¤ãªã—")
    
    def _get_statistics(self, df):
        """çµ±è¨ˆæƒ…å ±ã®å–å¾—"""
        numeric_df = df.select_dtypes(include=[np.number])
        if len(numeric_df.columns) > 0:
            stats = numeric_df.describe()
            # è¿½åŠ çµ±è¨ˆé‡
            stats.loc['skewness'] = numeric_df.skew()
            stats.loc['kurtosis'] = numeric_df.kurtosis()
            return stats
        return pd.DataFrame()
    
    def _detect_outliers(self, df, method='iqr', threshold=1.5):
        """
        å¤–ã‚Œå€¤ã®æ¤œå‡ºï¼ˆé€£ç¶šå¤‰æ•°ã®ã¿å¯¾è±¡ï¼‰
        ãƒã‚¤ãƒŠãƒªå¤‰æ•°ã‚„é›¢æ•£å¤‰æ•°ã¯é™¤å¤–
        """
        outlier_info = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            data = df[col].dropna()
            if len(data) == 0:
                continue
            
            # ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã®æ•°ã‚’ç¢ºèª
            unique_values = data.nunique()
            
            # 10å€¤ä»¥ä¸‹ã®å¤‰æ•°ã¯å¤–ã‚Œå€¤æ¤œå‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒã‚¤ãƒŠãƒªãƒ»é›¢æ•£å¤‰æ•°ï¼‰
            if unique_values <= 10:
                continue
                
            # é€£ç¶šå¤‰æ•°ã®ã¿å¤–ã‚Œå€¤æ¤œå‡ºã‚’å®Ÿè¡Œ
            if method == 'iqr':
                Q1 = data.quantile(0.25)
                Q3 = data.quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - threshold * IQR
                upper_bound = Q3 + threshold * IQR
                outliers = data[(data < lower_bound) | (data > upper_bound)]
            else:  # zscore
                z_scores = np.abs(stats.zscore(data))
                outliers = data[z_scores > threshold]
            
            if len(outliers) > 0:
                outlier_info[col] = {
                    'count': len(outliers),
                    'ratio': len(outliers) / len(data),
                    'values': outliers.tolist() if len(outliers) < 10 else outliers.head(10).tolist(),
                    'method': method,
                    'bounds': (lower_bound, upper_bound) if method == 'iqr' else None
                }
        
        return outlier_info
    
    def _print_outlier_info(self, info):
        """å¤–ã‚Œå€¤æƒ…å ±ã®è¡¨ç¤º"""
        if info:
            print(f"\nğŸ” å¤–ã‚Œå€¤æ¤œå‡º (IQRæ³•ã€é€£ç¶šå¤‰æ•°ã®ã¿):")
            for col, data in info.items():
                print(f"  - {col}: {data['count']} å€‹ ({data['ratio']*100:.1f}%)")
                if data['bounds']:
                    print(f"    ç¯„å›²: [{data['bounds'][0]:.2f}, {data['bounds'][1]:.2f}]")
        else:
            print(f"\nâœ… å¤–ã‚Œå€¤ãªã—ï¼ˆé€£ç¶šå¤‰æ•°ã«ãŠã„ã¦ï¼‰")
    
    def _visualize_overview(self, df, results, show=True, save=True):
        """å…¨ä½“çš„ãªå¯è¦–åŒ–"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. ãƒ‡ãƒ¼ã‚¿å‹åˆ†å¸ƒ
        ax = axes[0, 0]
        dtype_summary = results['dtype_info']['summary']
        if dtype_summary:
            ax.bar(range(len(dtype_summary)), list(dtype_summary.values()))
            ax.set_xticks(range(len(dtype_summary)))
            ax.set_xticklabels([str(k) for k in dtype_summary.keys()], rotation=45)
            ax.set_title('ãƒ‡ãƒ¼ã‚¿å‹ã®åˆ†å¸ƒ')
            ax.set_ylabel('åˆ—æ•°')
            ax.grid(True, alpha=0.3)
        
        # 2. æ¬ æå€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆä¸Šä½20åˆ—ï¼‰
        ax = axes[0, 1]
        missing_info = results['missing_info']
        if len(missing_info) > 0:
            top_missing = missing_info.head(20)
            ax.barh(range(len(top_missing)), top_missing['missing_ratio'])
            ax.set_yticks(range(len(top_missing)))
            ax.set_yticklabels(top_missing.index)
            ax.set_xlabel('æ¬ æç‡ (%)')
            ax.set_title('æ¬ æå€¤ã®å¤šã„å¤‰æ•° (Top 20)')
            ax.grid(True, alpha=0.3)
        else:
            ax.text(0.5, 0.5, 'æ¬ æå€¤ãªã—', ha='center', va='center', fontsize=14)
            ax.set_title('æ¬ æå€¤åˆ†æ')
        
        # 3. å¤–ã‚Œå€¤ã‚µãƒãƒªãƒ¼
        ax = axes[1, 0]
        outlier_info = results['outlier_info']
        if outlier_info:
            cols = list(outlier_info.keys())[:10]  # ä¸Šä½10åˆ—
            counts = [outlier_info[c]['count'] for c in cols]
            ax.bar(range(len(cols)), counts)
            ax.set_xticks(range(len(cols)))
            ax.set_xticklabels(cols, rotation=45, ha='right')
            ax.set_title('å¤–ã‚Œå€¤ã®æ•° (Top 10ã€é€£ç¶šå¤‰æ•°ã®ã¿)')
            ax.set_ylabel('å¤–ã‚Œå€¤æ•°')
            ax.grid(True, alpha=0.3)
        else:
            ax.text(0.5, 0.5, 'å¤–ã‚Œå€¤ãªã—', ha='center', va='center', fontsize=14)
            ax.set_title('å¤–ã‚Œå€¤åˆ†æ')
        
        # 4. ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®æ­ªåº¦
        ax = axes[1, 1]
        stats_info = results.get('stats_info', pd.DataFrame())
        if 'skewness' in stats_info.index:
            skewness = stats_info.loc['skewness'].sort_values()
            ax.barh(range(len(skewness)), skewness.values)
            ax.set_yticks(range(len(skewness)))
            ax.set_yticklabels(skewness.index, fontsize=8)
            ax.axvline(x=0, color='red', linestyle='--', alpha=0.5)
            ax.set_xlabel('æ­ªåº¦')
            ax.set_title('å¤‰æ•°ã®æ­ªåº¦')
            ax.grid(True, alpha=0.3)
        
        plt.suptitle('ãƒ‡ãƒ¼ã‚¿æ¦‚è¦åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        if save:
            save_path = f"{self.output_folder}/data_overview.png"
            plt.savefig(save_path, dpi=100, bbox_inches='tight')
            print(f"\nğŸ’¾ æ¦‚è¦å›³ã‚’ä¿å­˜: {save_path}")
        
        if show:
            plt.show()
        else:
            plt.close()
    
    def _analyze_target_variable(self, series, name, show=True, save=True):
        """ç›®çš„å¤‰æ•°ã®è©³ç´°åˆ†æ"""
        if series.dtype == 'object':
            return  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¯ã‚¹ã‚­ãƒƒãƒ—
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 8))
        
        # 1. ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        ax = axes[0, 0]
        ax.hist(series.dropna(), bins=30, edgecolor='black', alpha=0.7)
        ax.set_title(f'{name}: ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ')
        ax.set_xlabel('å€¤')
        ax.set_ylabel('é »åº¦')
        ax.grid(True, alpha=0.3)
        
        # 2. ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        ax = axes[0, 1]
        ax.boxplot(series.dropna())
        ax.set_title(f'{name}: ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ')
        ax.set_ylabel('å€¤')
        ax.grid(True, alpha=0.3)
        
        # 3. Q-Qãƒ—ãƒ­ãƒƒãƒˆ
        ax = axes[0, 2]
        stats.probplot(series.dropna(), dist="norm", plot=ax)
        ax.set_title(f'{name}: Q-Qãƒ—ãƒ­ãƒƒãƒˆ')
        ax.grid(True, alpha=0.3)
        
        # 4. å¯†åº¦ãƒ—ãƒ­ãƒƒãƒˆ
        ax = axes[1, 0]
        series.dropna().plot(kind='density', ax=ax)
        ax.set_title(f'{name}: ç¢ºç‡å¯†åº¦')
        ax.set_xlabel('å€¤')
        ax.grid(True, alpha=0.3)
        
        # 5. ç´¯ç©åˆ†å¸ƒ
        ax = axes[1, 1]
        sorted_data = np.sort(series.dropna())
        ax.plot(sorted_data, np.linspace(0, 1, len(sorted_data)))
        ax.set_title(f'{name}: ç´¯ç©åˆ†å¸ƒ')
        ax.set_xlabel('å€¤')
        ax.set_ylabel('ç´¯ç©ç¢ºç‡')
        ax.grid(True, alpha=0.3)
        
        # 6. çµ±è¨ˆæƒ…å ±ãƒ†ã‚­ã‚¹ãƒˆ
        ax = axes[1, 2]
        ax.axis('off')
        
        # çµ±è¨ˆå€¤ã®è¨ˆç®—
        mean_val = series.mean()
        median_val = series.median()
        std_val = series.std()
        skew_val = series.skew()
        kurt_val = series.kurtosis()
        min_val = series.min()
        max_val = series.max()
        missing_count = series.isnull().sum()
        missing_ratio = missing_count / len(series) * 100
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
        stats_lines = [
            'ã€çµ±è¨ˆæƒ…å ±ã€‘',
            '',
            f'å¹³å‡å€¤ã€€ã€€: {mean_val:>10.3f}',
            f'ä¸­å¤®å€¤ã€€ã€€: {median_val:>10.3f}',
            f'æ¨™æº–åå·®ã€€: {std_val:>10.3f}',
            f'æ­ªåº¦ã€€ã€€ã€€: {skew_val:>10.3f}',
            f'å°–åº¦ã€€ã€€ã€€: {kurt_val:>10.3f}',
            f'æœ€å°å€¤ã€€ã€€: {min_val:>10.3f}',
            f'æœ€å¤§å€¤ã€€ã€€: {max_val:>10.3f}',
            '',
            f'æ¬ æå€¤ã€€ã€€: {missing_count:>5d} å€‹',
            f'æ¬ æç‡ã€€ã€€: {missing_ratio:>10.1f}%'
        ]
        
        stats_text = '\n'.join(stats_lines)
        
        # è¡¨ç¤º
        ax.text(0.05, 0.5, stats_text, transform=ax.transAxes, fontsize=9, 
                verticalalignment='center', 
                bbox=dict(boxstyle='round,pad=0.5', facecolor='wheat', alpha=0.3))
        
        plt.suptitle(f'ç›®çš„å¤‰æ•°åˆ†æ: {name}', fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        if save:
            save_path = f"{self.output_folder}/target_{name}.png"
            plt.savefig(save_path, dpi=100, bbox_inches='tight')
            print(f"ğŸ’¾ ç›®çš„å¤‰æ•°åˆ†æå›³ã‚’ä¿å­˜: {save_path}")
        
        if show:
            plt.show()
        else:
            plt.close()
    
    def _analyze_features(self, df, show=True, save=True):
        """èª¬æ˜å¤‰æ•°ã®åˆ†æ"""
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) > 0:
            # æ•°å€¤å¤‰æ•°ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            n_cols = min(len(numeric_cols), 20)  # æœ€å¤§20å¤‰æ•°
            n_rows = (n_cols + 3) // 4
            
            fig, axes = plt.subplots(n_rows, 4, figsize=(15, n_rows * 3))
            axes = axes.flatten() if n_rows > 1 else [axes]
            
            for i, col in enumerate(numeric_cols[:n_cols]):
                ax = axes[i]
                data = df[col].dropna()
                if data.nunique() <= 1:
                    ax.text(0.5, 0.5, 'å®šæ•°åˆ—', ha='center', va='center')
                    ax.set_axis_off()
                    continue
                
                # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¨å¤–ã‚Œå€¤ãƒãƒ¼ã‚«ãƒ¼
                ax.hist(data, bins=20, edgecolor='black', alpha=0.7)
                
                # IQRæ³•ã§å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆé€£ç¶šå¤‰æ•°ã®ã¿ï¼‰
                if data.nunique() > 10:  # é€£ç¶šå¤‰æ•°ã®å ´åˆã®ã¿
                    Q1 = data.quantile(0.25)
                    Q3 = data.quantile(0.75)
                    IQR = Q3 - Q1
                    lower = Q1 - 1.5 * IQR
                    upper = Q3 + 1.5 * IQR
                    
                    # å¤–ã‚Œå€¤ã®å¢ƒç•Œç·š
                    ax.axvline(lower, color='red', linestyle='--', alpha=0.5, label='å¤–ã‚Œå€¤å¢ƒç•Œ')
                    ax.axvline(upper, color='red', linestyle='--', alpha=0.5)
                
                ax.set_title(f'{col}', fontsize=10)
                ax.set_xlabel('å€¤', fontsize=8)
                ax.set_ylabel('é »åº¦', fontsize=8)
                ax.grid(True, alpha=0.3)
                ax.tick_params(labelsize=8)
            
            # ä½™åˆ†ãªè»¸ã‚’éè¡¨ç¤º
            for i in range(n_cols, len(axes)):
                axes[i].axis('off')
            
            plt.suptitle('èª¬æ˜å¤‰æ•°ã®åˆ†å¸ƒï¼ˆæ•°å€¤å¤‰æ•°ï¼‰', fontsize=14, fontweight='bold')
            plt.tight_layout()
            
            if save:
                save_path = f"{self.output_folder}/features_distribution.png"
                plt.savefig(save_path, dpi=100, bbox_inches='tight')
                print(f"ğŸ’¾ èª¬æ˜å¤‰æ•°åˆ†æå›³ã‚’ä¿å­˜: {save_path}")
            
            if show:
                plt.show()
            else:
                plt.close()
    
    def _analyze_correlation(self, df, show=True, save=True):
        """ç›¸é–¢åˆ†æ"""
        # è¿½åŠ : å®‰å…¨ãªæ•°å€¤åŒ–ï¼ˆæ•°å€¤ä»¥å¤–ã¯ NaN ã«ã—ã¦åˆ—ã”ã¨ã«è½ã¨ã™ï¼‰
        df = df.apply(pd.to_numeric, errors='coerce')
        df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=1, how='all')
        if df.shape[1] < 2:
            # ç›¸é–¢ãŒè¨ˆç®—ã§ããªã„å ´åˆã¯ç©ºã§è¿”ã™ï¼ˆæç”»ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            return {'correlation_matrix': pd.DataFrame(), 'high_correlations': []}

        corr_matrix = df.corr()
        
        # ç›¸é–¢ã®å¼·ã„å¤‰æ•°ãƒšã‚¢ã‚’æŠ½å‡º
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:  # é–¾å€¤0.7
                    high_corr_pairs.append({
                        'var1': corr_matrix.columns[i],
                        'var2': corr_matrix.columns[j],
                        'correlation': corr_val
                    })
        
        if show or save:
            # ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
            plt.figure(figsize=(12, 10))
            if _HAS_SEABORN:
                mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
                sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm',
                            center=0, square=True, linewidths=0.5,
                            cbar_kws={"shrink": 0.8})
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: matplotlib
                cm = corr_matrix.to_numpy(dtype=float)
                mask = np.triu(np.ones_like(cm, dtype=bool))
                cm_masked = cm.copy()
                cm_masked[mask] = np.nan
                im = plt.imshow(cm_masked, interpolation='nearest', aspect='auto')
                plt.colorbar(im, shrink=0.8)
                ticks = range(len(corr_matrix.columns))
                plt.xticks(ticks, corr_matrix.columns, rotation=90, fontsize=8)
                plt.yticks(ticks, corr_matrix.columns, fontsize=8)
        
            plt.title('ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', fontsize=14, fontweight='bold')
            plt.tight_layout()

            
            if save:
                save_path = f"{self.output_folder}/correlation_heatmap.png"
                plt.savefig(save_path, dpi=100, bbox_inches='tight')
                print(f"ğŸ’¾ ç›¸é–¢è¡Œåˆ—å›³ã‚’ä¿å­˜: {save_path}")
            
            if show:
                plt.show()
            else:
                plt.close()
        
        return {
            'correlation_matrix': corr_matrix,
            'high_correlations': high_corr_pairs
        }
    
    def _save_report(self, results):
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
        import json
        from datetime import datetime
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report = {
            'timestamp': datetime.now().isoformat(),
            'data_shape': {
                'rows': int(results['basic_info']['shape'][0]),
                'columns': int(results['basic_info']['shape'][1])
            },
            'memory_usage_mb': float(results['basic_info']['memory_usage']),
            'duplicated_rows': int(results['basic_info']['duplicated_rows']),
            'missing_columns': len(results['missing_info']),
            'outlier_columns': len(results['outlier_info'])
        }
        
        # æ¬ æå€¤ã®ãƒˆãƒƒãƒ—10
        if len(results['missing_info']) > 0:
            missing_top10 = {}
            for idx, (col, row) in enumerate(results['missing_info'].head(10).iterrows()):
                missing_top10[str(col)] = {
                    'count': int(row['missing_count']),
                    'ratio': float(row['missing_ratio'])
                }
            report['top_missing'] = missing_top10
        
        # å¤–ã‚Œå€¤æƒ…å ±
        if results['outlier_info']:
            outlier_summary = {}
            for col, info in results['outlier_info'].items():
                outlier_summary[str(col)] = {
                    'count': int(info['count']),
                    'ratio': float(info['ratio'])
                }
            report['outliers'] = outlier_summary
        
        # é«˜ç›¸é–¢ãƒšã‚¢
        if 'correlation' in results and results['correlation']:
            if 'high_correlations' in results['correlation']:
                high_corr_list = []
                for pair in results['correlation']['high_correlations']:
                    high_corr_list.append({
                        'var1': str(pair['var1']),
                        'var2': str(pair['var2']),
                        'correlation': float(pair['correlation'])
                    })
                report['high_correlations'] = high_corr_list
        
        # JSONä¿å­˜
        report_path = f"{self.output_folder}/analysis_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_path}")
        
        # çµ±è¨ˆæƒ…å ±ã‚’CSVã§ä¿å­˜
        if 'stats_info' in results and not results['stats_info'].empty:
            stats_path = f"{self.output_folder}/statistics.csv"
            results['stats_info'].to_csv(stats_path, encoding='utf-8-sig')
            print(f"ğŸ“Š çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜: {stats_path}")